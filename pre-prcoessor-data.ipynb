{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/batust/presidio-db-json/blob/main/pre-prcoessor-data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install presidio_analyzer\n",
        "!pip install presidio_anonymizer\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66gqyrXzCVCr",
        "outputId": "5a5f03b5-dd12-42a7-de3d-57bf078bc4ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting presidio_analyzer\n",
            "  Downloading presidio_analyzer-2.2.358-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting phonenumbers<9.0.0,>=8.12 (from presidio_analyzer)\n",
            "  Downloading phonenumbers-8.13.55-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (6.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (2024.11.6)\n",
            "Requirement already satisfied: spacy!=3.7.0,<4.0.0,>=3.4.4 in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (3.8.4)\n",
            "Collecting tldextract (from presidio_analyzer)\n",
            "  Downloading tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.5.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio_analyzer) (3.10)\n",
            "Collecting requests-file>=1.4 (from tldextract->presidio_analyzer)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio_analyzer) (3.17.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.1.2)\n",
            "Downloading presidio_analyzer-2.2.358-py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading phonenumbers-8.13.55-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: phonenumbers, requests-file, tldextract, presidio_analyzer\n",
            "Successfully installed phonenumbers-8.13.55 presidio_analyzer-2.2.358 requests-file-2.1.0 tldextract-5.1.3\n",
            "Collecting presidio_anonymizer\n",
            "  Downloading presidio_anonymizer-2.2.358-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: cryptography<44.1 in /usr/local/lib/python3.11/dist-packages (from presidio_anonymizer) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<44.1->presidio_anonymizer) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<44.1->presidio_anonymizer) (2.22)\n",
            "Downloading presidio_anonymizer-2.2.358-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: presidio_anonymizer\n",
            "Successfully installed presidio_anonymizer-2.2.358\n",
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying out batch processing\n",
        "from typing import List, Optional, Dict, Union, Iterator, Iterable\n",
        "import collections\n",
        "from dataclasses import dataclass\n",
        "import pprint\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from presidio_analyzer import AnalyzerEngine, BatchAnalyzerEngine, RecognizerResult, DictAnalyzerResult\n",
        "from presidio_anonymizer import AnonymizerEngine, BatchAnonymizerEngine\n",
        "from presidio_anonymizer.entities import EngineResult"
      ],
      "metadata": {
        "id": "lU-kcaaukxyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zObfcH0H1dqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenicating and accessing Llama\n",
        "from os import environ\n",
        "from huggingface_hub import login\n",
        "\n",
        "HUGGING_FACE_TOKEN = environ.get(\"HUGGING_FACE_TOKEN\")\n",
        "login(token=HUGGING_FACE_TOKEN)"
      ],
      "metadata": {
        "id": "EFHfzJX1HLWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keeps crashing session\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "llama_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "def classify_sensitive_columns(columns):\n",
        "    prompt = f\"Given the column names {columns}, identify which may contain sensitive information (e.g., names, IDs, financial data). Return only a list of sensitive column names.\"\n",
        "\n",
        "    response = llama_pipeline(prompt, max_length=100, do_sample=True)\n",
        "\n",
        "    return response[0]['generated_text']\n",
        "\n",
        "columns = [\"Account\", \"Project ID\", \"Program Name\", \"Employee\", \"Cost Category\",\n",
        "           \"Entity\", \"COA ID\", \"COA\", \"Day\", \"Rate\", \"QUANTITY\", \"Actuals\",\n",
        "           \"Posting Category\", \"Description\"]\n",
        "\n",
        "print(classify_sensitive_columns(columns))"
      ],
      "metadata": {
        "id": "mX1lqOjmGvYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flair\n",
        "!pip install presidio_analyzer\n",
        "!pip install presidio_anonymizer\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yntJ-G5HqrEl",
        "outputId": "4f14cf0f-42fb-4653-8d9f-4cac6580fd10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flair\n",
            "  Downloading flair-0.15.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting boto3>=1.20.27 (from flair)\n",
            "  Downloading boto3-1.37.16-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting conllu<5.0.0,>=4.0 (from flair)\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.11/dist-packages (from flair) (1.2.18)\n",
            "Collecting ftfy>=6.1.0 (from flair)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from flair) (5.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from flair) (0.28.1)\n",
            "Collecting langdetect>=1.0.9 (from flair)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from flair) (5.3.1)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from flair) (3.10.0)\n",
            "Requirement already satisfied: more-itertools>=8.13.0 in /usr/local/lib/python3.11/dist-packages (from flair) (10.6.0)\n",
            "Collecting mpld3>=0.3 (from flair)\n",
            "  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting pptree>=3.1 (from flair)\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from flair) (2.8.2)\n",
            "Collecting pytorch-revgrad>=0.2.0 (from flair)\n",
            "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from flair) (2024.11.6)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from flair) (1.6.1)\n",
            "Collecting segtok>=1.5.11 (from flair)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting sqlitedict>=2.0.0 (from flair)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.11/dist-packages (from flair) (0.9.0)\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from flair) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.63.0 in /usr/local/lib/python3.11/dist-packages (from flair) (4.67.1)\n",
            "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair)\n",
            "  Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.25.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (4.48.3)\n",
            "Collecting wikipedia-api>=0.5.7 (from flair)\n",
            "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bioc<3.0.0,>=2.0.0 (from flair)\n",
            "  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair)\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting docopt (from bioc<3.0.0,>=2.0.0->flair)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting botocore<1.38.0,>=1.37.16 (from boto3>=1.20.27->flair)\n",
            "  Downloading botocore-1.37.16-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3>=1.20.27->flair)\n",
            "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.13->flair) (1.17.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair) (3.17.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair) (2.32.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (4.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect>=1.0.9->flair) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mpld3>=0.3->flair) (3.1.6)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair) (3.6.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.1->flair) (1.3.0)\n",
            "Collecting numpy>=1.23 (from matplotlib>=2.2.3->flair)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (4.25.6)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.16->boto3>=1.20.27->flair) (2.3.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair) (25.3.0)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.6)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mpld3>=0.3->flair) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (1.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (5.9.5)\n",
            "Downloading flair-0.15.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bioc-2.1-py3-none-any.whl (33 kB)\n",
            "Downloading boto3-1.37.16-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.6/139.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
            "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading botocore-1.37.16-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect, pptree, sqlitedict, wikipedia-api, docopt, intervaltree\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=c01f04ed0bce1af80cb0f0270c9eb25af0cee672e3e6a8caee8359727e76acc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4608 sha256=b8385c99602b7d131326afe6536368f5341746f2f0187cf9d7860b7b4be69bd6\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/8a/eb/d683aa6d09dc68ebfde2f37566ddc8807837c4415b4fd2b04c\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=4b67fdfcbc6a89556c3030e08db53d15af0a6755e1b89e90b999bed77c27f155\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/63/89/7210274f9b7fb033b8f22671f64c0e0b55083d30c3c046a3ff\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15384 sha256=1694d5d894edb5455636d70fbe264c3f392e199e7c3013c1a9f700d705ecbc9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/0f/39/e8214ec038ccd5aeb8c82b957289f2f3ab2251febeae5c2860\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=65bdf316c2bdcd7f1f933fc4a33c4e765db769920fa8824d5531e4e66eeb6bfe\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26097 sha256=c9fe7409d7904b0ec07de943c1fc51c898b5bffdc5a0ee001b870166d5bd1277\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d7/d9/eec6891f78cac19a693bd40ecb8365d2f4613318c145ec9816\n",
            "Successfully built langdetect pptree sqlitedict wikipedia-api docopt intervaltree\n",
            "Installing collected packages: sqlitedict, pptree, docopt, segtok, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, langdetect, jsonlines, jmespath, intervaltree, ftfy, conllu, wikipedia-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, bioc, s3transfer, nvidia-cusolver-cu12, mpld3, boto3, pytorch-revgrad, transformer-smaller-training-vocab, flair\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bioc-2.1 boto3-1.37.16 botocore-1.37.16 conllu-4.5.3 docopt-0.6.2 flair-0.15.1 ftfy-6.3.1 intervaltree-3.1.0 jmespath-1.0.1 jsonlines-4.0.0 langdetect-1.0.9 mpld3-0.5.10 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pptree-3.1 pytorch-revgrad-0.2.0 s3transfer-0.11.4 segtok-1.5.11 sqlitedict-2.1.0 transformer-smaller-training-vocab-0.4.0 wikipedia-api-0.8.1\n",
            "Collecting presidio_analyzer\n",
            "  Downloading presidio_analyzer-2.2.358-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting phonenumbers<9.0.0,>=8.12 (from presidio_analyzer)\n",
            "  Downloading phonenumbers-8.13.55-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (6.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (2024.11.6)\n",
            "Requirement already satisfied: spacy!=3.7.0,<4.0.0,>=3.4.4 in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (3.8.4)\n",
            "Collecting tldextract (from presidio_analyzer)\n",
            "  Downloading tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.5.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio_analyzer) (3.10)\n",
            "Collecting requests-file>=1.4 (from tldextract->presidio_analyzer)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio_analyzer) (3.17.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.1.2)\n",
            "Downloading presidio_analyzer-2.2.358-py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading phonenumbers-8.13.55-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: phonenumbers, requests-file, tldextract, presidio_analyzer\n",
            "Successfully installed phonenumbers-8.13.55 presidio_analyzer-2.2.358 requests-file-2.1.0 tldextract-5.1.3\n",
            "Collecting presidio_anonymizer\n",
            "  Downloading presidio_anonymizer-2.2.358-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: cryptography<44.1 in /usr/local/lib/python3.11/dist-packages (from presidio_anonymizer) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<44.1->presidio_anonymizer) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<44.1->presidio_anonymizer) (2.22)\n",
            "Downloading presidio_anonymizer-2.2.358-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: presidio_anonymizer\n",
            "Successfully installed presidio_anonymizer-2.2.358\n",
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0].strip().replace(' ', '-')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "0Ry2jFMGtIfT",
        "outputId": "cba9d0af-e699-426a-cd81-9114a4d3afed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d833e594-5ff5-494e-bf02-54f764858cdc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d833e594-5ff5-494e-bf02-54f764858cdc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving testing-csv-ff.csv to testing-csv-ff.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "EXCLUDED_HEADERS = [\"description\", \"comment\", \"comments\", \"query\", \"notes\", \"email\"]\n",
        "\n",
        "# ner_tagger = SequenceTagger.load(\"flair/ner-english\")\n",
        "tagger = SequenceTagger.load('flair/pos-english')\n",
        "if file_name.endswith('.xlsx'):\n",
        "  df = pd.read_excel(file_name)\n",
        "elif file_name.endswith('.csv'):\n",
        "  df = pd.read_csv(file_name)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "id": "R4ljahrrrhGa",
        "outputId": "9bb980a1-ffa1-43be-f56d-7f2fd6e11726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-19 11:28:24,203 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
            "2025-03-19 11:28:25,113 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id                                        name  \\\n",
              "0      5872184                                         ibm   \n",
              "1      4425416                   tata consultancy services   \n",
              "2        21074                                   accenture   \n",
              "3      2309813                                     us army   \n",
              "4      1558607                                          ey   \n",
              "...        ...                                         ...   \n",
              "29995  1201877                                 hans anders   \n",
              "29996  2828041                    real canadian superstore   \n",
              "29997   835865              shumaker, loop & kendrick, llp   \n",
              "29998  1611480                               business wire   \n",
              "29999  1859249  helix technology solutions private limited   \n",
              "\n",
              "                       domain  year founded  \\\n",
              "0                     ibm.com        1911.0   \n",
              "1                     tcs.com        1968.0   \n",
              "2               accenture.com        1989.0   \n",
              "3                  goarmy.com        1800.0   \n",
              "4                      ey.com        1989.0   \n",
              "...                       ...           ...   \n",
              "29995           hansanders.nl        1982.0   \n",
              "29996           superstore.ca           NaN   \n",
              "29997             slk-law.com        1925.0   \n",
              "29998        businesswire.com        1961.0   \n",
              "29999  helixtechsolutions.com           NaN   \n",
              "\n",
              "                                  industry   size range  \\\n",
              "0      information technology and services       10001+   \n",
              "1      information technology and services       10001+   \n",
              "2      information technology and services       10001+   \n",
              "3                                 military       10001+   \n",
              "4                               accounting       10001+   \n",
              "...                                    ...          ...   \n",
              "29995                               retail  1001 - 5000   \n",
              "29996                               retail  1001 - 5000   \n",
              "29997                         law practice   501 - 1000   \n",
              "29998  public relations and communications   501 - 1000   \n",
              "29999                           e-learning  1001 - 5000   \n",
              "\n",
              "                                       locality         country  \\\n",
              "0             new york, new york, united states   united states   \n",
              "1                    bombay, maharashtra, india           india   \n",
              "2                       dublin, dublin, ireland         ireland   \n",
              "3           alexandria, virginia, united states   united states   \n",
              "4        london, greater london, united kingdom  united kingdom   \n",
              "...                                         ...             ...   \n",
              "29995        giethoorn, overijssel, netherlands     netherlands   \n",
              "29996                     madrid, madrid, spain           spain   \n",
              "29997               toledo, ohio, united states   united states   \n",
              "29998  san francisco, california, united states   united states   \n",
              "29999               hyderābād, telangana, india           india   \n",
              "\n",
              "                                            linkedin url  \\\n",
              "0                               linkedin.com/company/ibm   \n",
              "1         linkedin.com/company/tata-consultancy-services   \n",
              "2                         linkedin.com/company/accenture   \n",
              "3                           linkedin.com/company/us-army   \n",
              "4                     linkedin.com/company/ernstandyoung   \n",
              "...                                                  ...   \n",
              "29995                   linkedin.com/company/hans-anders   \n",
              "29996      linkedin.com/company/real-canadian-superstore   \n",
              "29997  linkedin.com/company/shumaker-loop-&-kendrick-llp   \n",
              "29998                 linkedin.com/company/business-wire   \n",
              "29999  linkedin.com/company/helix-technology-solution...   \n",
              "\n",
              "       current employee estimate  total employee estimate  \n",
              "0                         274047                   716906  \n",
              "1                         190771                   341369  \n",
              "2                         190689                   455768  \n",
              "3                         162163                   445958  \n",
              "4                         158363                   428960  \n",
              "...                          ...                      ...  \n",
              "29995                        390                      959  \n",
              "29996                        390                     1320  \n",
              "29997                        390                      688  \n",
              "29998                        390                      998  \n",
              "29999                        390                      501  \n",
              "\n",
              "[30000 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cadc802-30da-469c-b6c0-85268713b38e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>domain</th>\n",
              "      <th>year founded</th>\n",
              "      <th>industry</th>\n",
              "      <th>size range</th>\n",
              "      <th>locality</th>\n",
              "      <th>country</th>\n",
              "      <th>linkedin url</th>\n",
              "      <th>current employee estimate</th>\n",
              "      <th>total employee estimate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5872184</td>\n",
              "      <td>ibm</td>\n",
              "      <td>ibm.com</td>\n",
              "      <td>1911.0</td>\n",
              "      <td>information technology and services</td>\n",
              "      <td>10001+</td>\n",
              "      <td>new york, new york, united states</td>\n",
              "      <td>united states</td>\n",
              "      <td>linkedin.com/company/ibm</td>\n",
              "      <td>274047</td>\n",
              "      <td>716906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4425416</td>\n",
              "      <td>tata consultancy services</td>\n",
              "      <td>tcs.com</td>\n",
              "      <td>1968.0</td>\n",
              "      <td>information technology and services</td>\n",
              "      <td>10001+</td>\n",
              "      <td>bombay, maharashtra, india</td>\n",
              "      <td>india</td>\n",
              "      <td>linkedin.com/company/tata-consultancy-services</td>\n",
              "      <td>190771</td>\n",
              "      <td>341369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21074</td>\n",
              "      <td>accenture</td>\n",
              "      <td>accenture.com</td>\n",
              "      <td>1989.0</td>\n",
              "      <td>information technology and services</td>\n",
              "      <td>10001+</td>\n",
              "      <td>dublin, dublin, ireland</td>\n",
              "      <td>ireland</td>\n",
              "      <td>linkedin.com/company/accenture</td>\n",
              "      <td>190689</td>\n",
              "      <td>455768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2309813</td>\n",
              "      <td>us army</td>\n",
              "      <td>goarmy.com</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>military</td>\n",
              "      <td>10001+</td>\n",
              "      <td>alexandria, virginia, united states</td>\n",
              "      <td>united states</td>\n",
              "      <td>linkedin.com/company/us-army</td>\n",
              "      <td>162163</td>\n",
              "      <td>445958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1558607</td>\n",
              "      <td>ey</td>\n",
              "      <td>ey.com</td>\n",
              "      <td>1989.0</td>\n",
              "      <td>accounting</td>\n",
              "      <td>10001+</td>\n",
              "      <td>london, greater london, united kingdom</td>\n",
              "      <td>united kingdom</td>\n",
              "      <td>linkedin.com/company/ernstandyoung</td>\n",
              "      <td>158363</td>\n",
              "      <td>428960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>1201877</td>\n",
              "      <td>hans anders</td>\n",
              "      <td>hansanders.nl</td>\n",
              "      <td>1982.0</td>\n",
              "      <td>retail</td>\n",
              "      <td>1001 - 5000</td>\n",
              "      <td>giethoorn, overijssel, netherlands</td>\n",
              "      <td>netherlands</td>\n",
              "      <td>linkedin.com/company/hans-anders</td>\n",
              "      <td>390</td>\n",
              "      <td>959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>2828041</td>\n",
              "      <td>real canadian superstore</td>\n",
              "      <td>superstore.ca</td>\n",
              "      <td>NaN</td>\n",
              "      <td>retail</td>\n",
              "      <td>1001 - 5000</td>\n",
              "      <td>madrid, madrid, spain</td>\n",
              "      <td>spain</td>\n",
              "      <td>linkedin.com/company/real-canadian-superstore</td>\n",
              "      <td>390</td>\n",
              "      <td>1320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>835865</td>\n",
              "      <td>shumaker, loop &amp; kendrick, llp</td>\n",
              "      <td>slk-law.com</td>\n",
              "      <td>1925.0</td>\n",
              "      <td>law practice</td>\n",
              "      <td>501 - 1000</td>\n",
              "      <td>toledo, ohio, united states</td>\n",
              "      <td>united states</td>\n",
              "      <td>linkedin.com/company/shumaker-loop-&amp;-kendrick-llp</td>\n",
              "      <td>390</td>\n",
              "      <td>688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>1611480</td>\n",
              "      <td>business wire</td>\n",
              "      <td>businesswire.com</td>\n",
              "      <td>1961.0</td>\n",
              "      <td>public relations and communications</td>\n",
              "      <td>501 - 1000</td>\n",
              "      <td>san francisco, california, united states</td>\n",
              "      <td>united states</td>\n",
              "      <td>linkedin.com/company/business-wire</td>\n",
              "      <td>390</td>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>1859249</td>\n",
              "      <td>helix technology solutions private limited</td>\n",
              "      <td>helixtechsolutions.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>e-learning</td>\n",
              "      <td>1001 - 5000</td>\n",
              "      <td>hyderābād, telangana, india</td>\n",
              "      <td>india</td>\n",
              "      <td>linkedin.com/company/helix-technology-solution...</td>\n",
              "      <td>390</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows × 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cadc802-30da-469c-b6c0-85268713b38e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0cadc802-30da-469c-b6c0-85268713b38e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0cadc802-30da-469c-b6c0-85268713b38e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-94c8d719-4b6c-45a9-afae-005f29d29374\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94c8d719-4b6c-45a9-afae-005f29d29374')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-94c8d719-4b6c-45a9-afae-005f29d29374 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1d101736-8cd7-4856-ae8a-7fee5cad56b8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1d101736-8cd7-4856-ae8a-7fee5cad56b8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2065024,\n        \"min\": 83,\n        \"max\": 7172954,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          7101437,\n          2451549,\n          4790856\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29423,\n        \"samples\": [\n          \"positivo inform\\u00e1tica\",\n          \"cbi\",\n          \"orion group\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"domain\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26710,\n        \"samples\": [\n          \"ehhi.com\",\n          \"rcoe.us\",\n          \"altalink.ca\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year founded\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46.819743806326905,\n        \"min\": 1451.0,\n        \"max\": 2018.0,\n        \"num_unique_values\": 222,\n        \"samples\": [\n          2007.0,\n          1814.0,\n          1976.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"industry\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 148,\n        \"samples\": [\n          \"e-learning\",\n          \"food production\",\n          \"alternative medicine\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"size range\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"5001 - 10000\",\n          \"501 - 1000\",\n          \"10001+\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"locality\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5082,\n        \"samples\": [\n          \"westbury, new york, united states\",\n          \"jumeirah, dubai, united arab emirates\",\n          \"woking, surrey, united kingdom\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 148,\n        \"samples\": [\n          \"gibraltar\",\n          \"bermuda\",\n          \"bolivia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"linkedin url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          \"linkedin.com/company/defense-logistics-agency\",\n          \"linkedin.com/company/asd-healthcare\",\n          \"linkedin.com/company/bvg-india-ltd-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"current employee estimate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5177,\n        \"min\": 390,\n        \"max\": 274047,\n        \"num_unique_values\": 4989,\n        \"samples\": [\n          4196,\n          4886,\n          4599\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total employee estimate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12864,\n        \"min\": 396,\n        \"max\": 716906,\n        \"num_unique_values\": 8063,\n        \"samples\": [\n          16946,\n          7462,\n          6228\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not batch processing\n",
        "def classify_cell_as_noun(texts):\n",
        "    sentences = [Sentence(text) for text in texts]\n",
        "    tagger.predict(sentences)\n",
        "\n",
        "    results = []\n",
        "    noun_count = 0\n",
        "\n",
        "    for sentence, original_text in zip(sentences, texts):\n",
        "        all_nouns = any(\"NN\" in token.tag for token in sentence)\n",
        "        classification = \"Noun\" if all_nouns else \"Not a noun\"\n",
        "\n",
        "        results.append({\"Original Text\": original_text, \"Classification\": classification})\n",
        "        noun_count += all_nouns\n",
        "\n",
        "    is_noun_column = noun_count > (len(results) // 1.5)\n",
        "    return results, is_noun_column\n",
        "\n",
        "sensitive = set()\n",
        "\n",
        "for column in df.columns:\n",
        "    values = df[column].astype(str).tolist()\n",
        "    results, is_noun = classify_cell_as_noun(values)\n",
        "\n",
        "    if is_noun: sensitive.add(column)\n",
        "\n",
        "print(sensitive)\n"
      ],
      "metadata": {
        "id": "g1IS53-78T_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch processing\n",
        "import pandas as pd\n",
        "import concurrent.futures\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "tagger = SequenceTagger.load(\"flair/pos-english\")\n",
        "\n",
        "EXCLUDED_HEADERS = [\"description\", \"comment\", \"comments\", \"query\", \"notes\", \"email\"]\n",
        "FILE_NAME = \"companies_sorted.csv\"\n",
        "BATCH_SIZE = 10000\n",
        "FLAIR_BATCH_SIZE = 100\n",
        "MAX_THREADS = 4\n",
        "\n",
        "sensitive = set()\n",
        "\n",
        "def classify_cells_as_nouns(texts):\n",
        "    \"\"\"Batch processes text to check if columns are noun-heavy.\"\"\"\n",
        "    texts = ['' if pd.isna(text) else text for text in texts]\n",
        "\n",
        "    results = []\n",
        "    noun_count = 0\n",
        "\n",
        "    for i in range(0, len(texts), FLAIR_BATCH_SIZE):\n",
        "        batch_text = texts[i : i + FLAIR_BATCH_SIZE]\n",
        "        sentences = [Sentence(text) for text in batch_text]\n",
        "\n",
        "        tagger.predict(sentences)\n",
        "\n",
        "        for sentence, original_text in zip(sentences, batch_text):\n",
        "            all_nouns = any(\"NN\" in token.tag for token in sentence)\n",
        "            classification = \"Noun\" if all_nouns else \"Not a noun\"\n",
        "\n",
        "            results.append({\"Original Text\": original_text, \"Classification\": classification})\n",
        "\n",
        "            noun_count += all_nouns\n",
        "\n",
        "    is_noun_column = noun_count > (len(results) * 0.66)\n",
        "\n",
        "    return is_noun_column\n",
        "\n",
        "def process_column(col, chunk):\n",
        "    \"\"\"Runs noun classification on a single column.\"\"\"\n",
        "    values = chunk[col].astype(str).fillna(\"\").tolist()\n",
        "    return col if classify_cells_as_nouns(values) else None\n",
        "\n",
        "FILE_NAME = 'smaller_companies.csv'\n",
        "if FILE_NAME.endswith(\".xlsx\"):\n",
        "    df_iterator = pd.read_excel(FILE_NAME, chunksize=BATCH_SIZE)\n",
        "elif FILE_NAME.endswith(\".csv\"):\n",
        "    df_iterator = pd.read_csv(FILE_NAME, chunksize=BATCH_SIZE)\n",
        "\n",
        "for chunk in df_iterator:\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
        "        futures = {executor.submit(process_column, col, chunk): col for col in chunk.columns}\n",
        "\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            result = future.result()\n",
        "            if result:\n",
        "                sensitive.add(result)\n",
        "\n",
        "print(\"Sensitive Columns:\", sensitive)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHVCsND0MvVZ",
        "outputId": "c544cb31-f56f-4615-e4d9-cb16fb83bf4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-19 11:51:26,893 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:1124: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1412.)\n",
            "  result = _VF.lstm(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:1124: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1412.)\n",
            "  result = _VF.lstm(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:1124: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1412.)\n",
            "  result = _VF.lstm(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:1124: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1412.)\n",
            "  result = _VF.lstm(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:1124: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1412.)\n",
            "  result = _VF.lstm(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:1124: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1412.)\n",
            "  result = _VF.lstm(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:1124: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1412.)\n",
            "  result = _VF.lstm(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:1124: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1412.)\n",
            "  result = _VF.lstm(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:1124: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1412.)\n",
            "  result = _VF.lstm(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:1124: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1412.)\n",
            "  result = _VF.lstm(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sensitive Columns: {'linkedin url', 'name', 'country', 'industry', 'locality'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_df = df_iterator.copy()\n",
        "\n",
        "for col in masked_df:\n",
        "  if col in sensitive:\n",
        "    masked_df[col] = [f'{col}_{i}' for i in range(len(masked_df[col]))]\n",
        "\n",
        "masked_df"
      ],
      "metadata": {
        "id": "TXaqMb3adrPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying spacy and flair on large dataset using Threading\n",
        "import re\n",
        "import json\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from threading import Lock\n",
        "\n",
        "# Load models\n",
        "flair_tagger = SequenceTagger.load(\"flair/pos-english\")\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Constants\n",
        "BATCH_SIZE = 10000  # Process in chunks\n",
        "FLAIR_SAMPLE_SIZE = 10  # Sample size for noun detection\n",
        "THREADS = 4  # Number of parallel threads\n",
        "PHONE_REGEX = r\"\\b(\\+\\d{1,4}\\s?)?(\\(?\\d{1,4}\\)?[-.]?\\s?)?\\d{3,4}[-.]?\\d{3,4}[-.]?\\d{3,4}\\b\"\n",
        "\n",
        "DESCRIPTIVE_COLUMNS = {\"description\", \"comment\", \"comments\", \"query\", \"notes\"}\n",
        "SENSITIVE_COLUMNS = set()\n",
        "MAPPINGS = {}\n",
        "VALUE_TO_MASK = {}\n",
        "ENTITY_COUNTER = 1\n",
        "mask_lock = Lock()  # Thread-safe lock for dictionary updates\n",
        "\n",
        "def is_noun_column(texts):\n",
        "    \"\"\"Identify if a column contains mostly nouns based on a sample.\"\"\"\n",
        "    texts = [\"\" if pd.isna(text) else str(text) for text in texts[:FLAIR_SAMPLE_SIZE]]\n",
        "    sentences = [Sentence(text) for text in texts]\n",
        "    flair_tagger.predict(sentences)\n",
        "    noun_count = sum(any(\"NN\" in token.tag for token in sent) for sent in sentences)\n",
        "    return noun_count > (len(texts) * 0.6)\n",
        "\n",
        "def mask_text(text, col_name, row_idx):\n",
        "    \"\"\"Mask the input text and store the mapping, ensuring thread-safe access.\"\"\"\n",
        "    global ENTITY_COUNTER\n",
        "    if pd.isna(text) or str(text).strip() == \"\":\n",
        "        return text\n",
        "    with mask_lock:  # Thread-safe updates\n",
        "        if text in VALUE_TO_MASK:\n",
        "            return VALUE_TO_MASK[text]\n",
        "        masked_value = f\"{col_name}_{row_idx}\"\n",
        "        VALUE_TO_MASK[text] = masked_value\n",
        "        MAPPINGS[masked_value] = text\n",
        "        ENTITY_COUNTER += 1\n",
        "    return masked_value\n",
        "\n",
        "def process_chunk(chunk):\n",
        "    \"\"\"Process a chunk of the CSV, masking sensitive data, and return a new masked DataFrame.\"\"\"\n",
        "    new_chunk = chunk.copy()  # Ensure original DataFrame remains unchanged\n",
        "\n",
        "    for row_idx in new_chunk.index:\n",
        "        # Mask sensitive columns\n",
        "        for col in SENSITIVE_COLUMNS:\n",
        "            new_chunk.at[row_idx, col] = mask_text(new_chunk.at[row_idx, col], col, row_idx)\n",
        "\n",
        "        # Mask phone numbers across all columns\n",
        "        for col in new_chunk.columns:\n",
        "            new_chunk.at[row_idx, col] = re.sub(PHONE_REGEX, lambda m: mask_text(m.group(0), \"phone\", row_idx), str(new_chunk.at[row_idx, col]))\n",
        "\n",
        "        # Mask descriptive text columns\n",
        "        descriptive_cols = [col for col in new_chunk.columns if col.lower() in DESCRIPTIVE_COLUMNS]\n",
        "        for col in descriptive_cols:\n",
        "            doc = nlp(str(new_chunk.at[row_idx, col]))\n",
        "            for ent in doc.ents:\n",
        "                new_chunk.at[row_idx, col] = new_chunk.at[row_idx, col].replace(ent.text, mask_text(ent.text, col, row_idx))\n",
        "\n",
        "    return new_chunk  # Return masked DataFrame\n",
        "\n",
        "def main(file_path):\n",
        "    \"\"\"Process the entire CSV file in chunks and write masked data to a new file.\"\"\"\n",
        "    global SENSITIVE_COLUMNS\n",
        "\n",
        "    # Identify sensitive columns from a sample\n",
        "    df_sample = pd.read_csv(file_path, nrows=FLAIR_SAMPLE_SIZE)\n",
        "    SENSITIVE_COLUMNS = {col for col in df_sample.columns if is_noun_column(df_sample[col].astype(str).tolist())}\n",
        "\n",
        "    # Process CSV in chunks with threading\n",
        "    reader = pd.read_csv(file_path, chunksize=BATCH_SIZE)\n",
        "    first_chunk = True  # Ensure header is written only once\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=THREADS) as executor:\n",
        "        for masked_chunk in executor.map(process_chunk, reader):\n",
        "            # Append masked chunk to file (efficient memory usage)\n",
        "            masked_chunk.to_csv(\"masked_output.csv\", index=False, mode=\"a\", header=first_chunk)\n",
        "            first_chunk = False  # Disable header for subsequent chunks\n",
        "\n",
        "    # Save mappings separately for possible de-anonymization\n",
        "    with open(\"mappings.json\", \"w\") as f:\n",
        "        json.dump(MAPPINGS, f)\n",
        "\n",
        "    print(\"Processing complete. Masked data saved.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main('smaller_companies.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyvUoB4fDZxJ",
        "outputId": "71ea32ef-b36c-4079-c3b9-8a8b36f5332c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-20 08:47:18,085 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-72a88127c458>:61: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5872184' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  new_chunk.at[row_idx, col] = re.sub(PHONE_REGEX, lambda m: mask_text(m.group(0), \"phone\", row_idx), str(new_chunk.at[row_idx, col]))\n",
            "<ipython-input-24-72a88127c458>:61: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1911.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  new_chunk.at[row_idx, col] = re.sub(PHONE_REGEX, lambda m: mask_text(m.group(0), \"phone\", row_idx), str(new_chunk.at[row_idx, col]))\n",
            "<ipython-input-24-72a88127c458>:61: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '274047' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  new_chunk.at[row_idx, col] = re.sub(PHONE_REGEX, lambda m: mask_text(m.group(0), \"phone\", row_idx), str(new_chunk.at[row_idx, col]))\n",
            "<ipython-input-24-72a88127c458>:61: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '716906' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  new_chunk.at[row_idx, col] = re.sub(PHONE_REGEX, lambda m: mask_text(m.group(0), \"phone\", row_idx), str(new_chunk.at[row_idx, col]))\n",
            "<ipython-input-24-72a88127c458>:61: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3875354' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  new_chunk.at[row_idx, col] = re.sub(PHONE_REGEX, lambda m: mask_text(m.group(0), \"phone\", row_idx), str(new_chunk.at[row_idx, col]))\n",
            "<ipython-input-24-72a88127c458>:61: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1946.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  new_chunk.at[row_idx, col] = re.sub(PHONE_REGEX, lambda m: mask_text(m.group(0), \"phone\", row_idx), str(new_chunk.at[row_idx, col]))\n",
            "<ipython-input-24-72a88127c458>:61: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1117' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  new_chunk.at[row_idx, col] = re.sub(PHONE_REGEX, lambda m: mask_text(m.group(0), \"phone\", row_idx), str(new_chunk.at[row_idx, col]))\n",
            "<ipython-input-24-72a88127c458>:61: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4262' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  new_chunk.at[row_idx, col] = re.sub(PHONE_REGEX, lambda m: mask_text(m.group(0), \"phone\", row_idx), str(new_chunk.at[row_idx, col]))\n",
            "<ipython-input-24-72a88127c458>:61: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4982906' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  new_chunk.at[row_idx, col] = re.sub(PHONE_REGEX, lambda m: mask_text(m.group(0), \"phone\", row_idx), str(new_chunk.at[row_idx, col]))\n",
            "<ipython-input-24-72a88127c458>:61: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  new_chunk.at[row_idx, col] = re.sub(PHONE_REGEX, lambda m: mask_text(m.group(0), \"phone\", row_idx), str(new_chunk.at[row_idx, col]))\n",
            "<ipython-input-24-72a88127c458>:61: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '583' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  new_chunk.at[row_idx, col] = re.sub(PHONE_REGEX, lambda m: mask_text(m.group(0), \"phone\", row_idx), str(new_chunk.at[row_idx, col]))\n",
            "<ipython-input-24-72a88127c458>:61: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '787' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  new_chunk.at[row_idx, col] = re.sub(PHONE_REGEX, lambda m: mask_text(m.group(0), \"phone\", row_idx), str(new_chunk.at[row_idx, col]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complete. Masked data saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flair\n",
        "!pip install presidio_analyzer\n",
        "!pip install presidio_anonymizer\n",
        "# !python -m spacy download en_core_web_lg\n",
        "!pip install --upgrade --force-reinstall \"numpy==1.26.4\"\n",
        "!pip install --upgrade --force-reinstall \"Cython\" \"spacy\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qJ96uMjuFBlK",
        "outputId": "55d047e9-c613-4d4b-ea5f-83d42eee0adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flair\n",
            "  Downloading flair-0.15.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting boto3>=1.20.27 (from flair)\n",
            "  Downloading boto3-1.37.18-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting conllu<5.0.0,>=4.0 (from flair)\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.11/dist-packages (from flair) (1.2.18)\n",
            "Collecting ftfy>=6.1.0 (from flair)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from flair) (5.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from flair) (0.29.3)\n",
            "Collecting langdetect>=1.0.9 (from flair)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from flair) (5.3.1)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from flair) (3.10.0)\n",
            "Requirement already satisfied: more-itertools>=8.13.0 in /usr/local/lib/python3.11/dist-packages (from flair) (10.6.0)\n",
            "Collecting mpld3>=0.3 (from flair)\n",
            "  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting pptree>=3.1 (from flair)\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from flair) (2.8.2)\n",
            "Collecting pytorch-revgrad>=0.2.0 (from flair)\n",
            "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from flair) (2024.11.6)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from flair) (1.6.1)\n",
            "Collecting segtok>=1.5.11 (from flair)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting sqlitedict>=2.0.0 (from flair)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.11/dist-packages (from flair) (0.9.0)\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from flair) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.63.0 in /usr/local/lib/python3.11/dist-packages (from flair) (4.67.1)\n",
            "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair)\n",
            "  Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.25.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (4.49.0)\n",
            "Collecting wikipedia-api>=0.5.7 (from flair)\n",
            "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bioc<3.0.0,>=2.0.0 (from flair)\n",
            "  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair)\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting docopt (from bioc<3.0.0,>=2.0.0->flair)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting botocore<1.38.0,>=1.37.18 (from boto3>=1.20.27->flair)\n",
            "  Downloading botocore-1.37.18-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3>=1.20.27->flair)\n",
            "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.13->flair) (1.17.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair) (2.32.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (4.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect>=1.0.9->flair) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mpld3>=0.3->flair) (3.1.6)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair) (3.6.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.1->flair)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.1->flair) (1.3.0)\n",
            "Collecting numpy>=1.23 (from matplotlib>=2.2.3->flair)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (5.29.3)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.18->boto3>=1.20.27->flair) (2.3.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair) (25.3.0)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (1.5.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.6)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mpld3>=0.3->flair) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (1.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (5.9.5)\n",
            "Downloading flair-0.15.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bioc-2.1-py3-none-any.whl (33 kB)\n",
            "Downloading boto3-1.37.18-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.6/139.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
            "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m855.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading botocore-1.37.18-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect, pptree, sqlitedict, wikipedia-api, docopt, intervaltree\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=4a4a2ecaad8ec6e4d23ff7a4682a67c1b72a41bed0694b07161583e3db656bef\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4608 sha256=2d0ebd74a0f687946cbbdcb4969ce5a9f271399ab634baa7b78e92fc4a424542\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/8a/eb/d683aa6d09dc68ebfde2f37566ddc8807837c4415b4fd2b04c\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=a3fed7b591e1f3663bce6223e18ee18181489e32a984d749377f79fcbc706618\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/63/89/7210274f9b7fb033b8f22671f64c0e0b55083d30c3c046a3ff\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15384 sha256=6b718902f5a77685bad08d774005f55c82fa634a042d72f3feffea5d2ebeb99f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/0f/39/e8214ec038ccd5aeb8c82b957289f2f3ab2251febeae5c2860\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=0d46f787addfd65478a985d173d917ce60c0aab9d34651f065f32645566a2cfb\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26097 sha256=4fa4d68d68f21ad9f8192851eb40d6903957cd97329237174a70d55f78931f3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d7/d9/eec6891f78cac19a693bd40ecb8365d2f4613318c145ec9816\n",
            "Successfully built langdetect pptree sqlitedict wikipedia-api docopt intervaltree\n",
            "Installing collected packages: sqlitedict, pptree, docopt, segtok, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, langdetect, jsonlines, jmespath, intervaltree, ftfy, conllu, wikipedia-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, bioc, s3transfer, nvidia-cusolver-cu12, mpld3, boto3, pytorch-revgrad, transformer-smaller-training-vocab, flair\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bioc-2.1 boto3-1.37.18 botocore-1.37.18 conllu-4.5.3 docopt-0.6.2 flair-0.15.1 ftfy-6.3.1 intervaltree-3.1.0 jmespath-1.0.1 jsonlines-4.0.0 langdetect-1.0.9 mpld3-0.5.10 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pptree-3.1 pytorch-revgrad-0.2.0 s3transfer-0.11.4 segtok-1.5.11 sqlitedict-2.1.0 transformer-smaller-training-vocab-0.4.0 wikipedia-api-0.8.1\n",
            "Collecting presidio_analyzer\n",
            "  Downloading presidio_analyzer-2.2.358-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting phonenumbers<9.0.0,>=8.12 (from presidio_analyzer)\n",
            "  Downloading phonenumbers-8.13.55-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (6.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (2024.11.6)\n",
            "Requirement already satisfied: spacy!=3.7.0,<4.0.0,>=3.4.4 in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (3.8.4)\n",
            "Collecting tldextract (from presidio_analyzer)\n",
            "  Downloading tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.5.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio_analyzer) (3.10)\n",
            "Collecting requests-file>=1.4 (from tldextract->presidio_analyzer)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio_analyzer) (3.18.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.1.2)\n",
            "Downloading presidio_analyzer-2.2.358-py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading phonenumbers-8.13.55-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: phonenumbers, requests-file, tldextract, presidio_analyzer\n",
            "Successfully installed phonenumbers-8.13.55 presidio_analyzer-2.2.358 requests-file-2.1.0 tldextract-5.1.3\n",
            "Collecting presidio_anonymizer\n",
            "  Downloading presidio_anonymizer-2.2.358-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: cryptography<44.1 in /usr/local/lib/python3.11/dist-packages (from presidio_anonymizer) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<44.1->presidio_anonymizer) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<44.1->presidio_anonymizer) (2.22)\n",
            "Downloading presidio_anonymizer-2.2.358-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: presidio_anonymizer\n",
            "Successfully installed presidio_anonymizer-2.2.358\n",
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "Successfully installed numpy-1.26.4\n",
            "Collecting Cython\n",
            "  Downloading Cython-3.0.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
            "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
            "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
            "  Downloading murmurhash-1.0.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
            "  Downloading cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
            "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
            "  Downloading preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
            "  Downloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
            "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
            "  Downloading srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
            "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
            "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
            "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting tqdm<5.0.0,>=4.38.0 (from spacy)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.19.0 (from spacy)\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests<3.0.0,>=2.13.0 (from spacy)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting jinja2 (from spacy)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting setuptools (from spacy)\n",
            "  Downloading setuptools-77.0.3-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting packaging>=20.0 (from spacy)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
            "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
            "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
            "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting typing-extensions>=4.12.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3.0.0,>=2.13.0->spacy)\n",
            "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.13.0->spacy)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.13.0->spacy)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.13.0->spacy)\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
            "  Downloading blis-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
            "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting click>=8.0.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
            "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
            "  Downloading cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->spacy)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
            "  Downloading marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
            "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading Cython-3.0.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spacy-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
            "Downloading cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (218 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.9/218.9 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.0/183.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading murmurhash-1.0.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.2/157.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
            "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
            "Downloading srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
            "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-77.0.3-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading blis-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: cymem, wrapt, wasabi, urllib3, typing-extensions, tqdm, spacy-loggers, spacy-legacy, shellingham, setuptools, pygments, packaging, numpy, murmurhash, mdurl, MarkupSafe, idna, Cython, cloudpathlib, click, charset-normalizer, certifi, catalogue, annotated-types, srsly, smart-open, requests, pydantic-core, preshed, markdown-it-py, marisa-trie, jinja2, blis, rich, pydantic, language-data, typer, langcodes, confection, weasel, thinc, spacy\n",
            "  Attempting uninstall: cymem\n",
            "    Found existing installation: cymem 2.0.11\n",
            "    Uninstalling cymem-2.0.11:\n",
            "      Successfully uninstalled cymem-2.0.11\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.3\n",
            "    Uninstalling wasabi-1.1.3:\n",
            "      Successfully uninstalled wasabi-1.1.3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: spacy-loggers\n",
            "    Found existing installation: spacy-loggers 1.0.5\n",
            "    Uninstalling spacy-loggers-1.0.5:\n",
            "      Successfully uninstalled spacy-loggers-1.0.5\n",
            "  Attempting uninstall: spacy-legacy\n",
            "    Found existing installation: spacy-legacy 3.0.12\n",
            "    Uninstalling spacy-legacy-3.0.12:\n",
            "      Successfully uninstalled spacy-legacy-3.0.12\n",
            "  Attempting uninstall: shellingham\n",
            "    Found existing installation: shellingham 1.5.4\n",
            "    Uninstalling shellingham-1.5.4:\n",
            "      Successfully uninstalled shellingham-1.5.4\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.1.0\n",
            "    Uninstalling setuptools-75.1.0:\n",
            "      Successfully uninstalled setuptools-75.1.0\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.18.0\n",
            "    Uninstalling Pygments-2.18.0:\n",
            "      Successfully uninstalled Pygments-2.18.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: murmurhash\n",
            "    Found existing installation: murmurhash 1.0.12\n",
            "    Uninstalling murmurhash-1.0.12:\n",
            "      Successfully uninstalled murmurhash-1.0.12\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 3.0.12\n",
            "    Uninstalling Cython-3.0.12:\n",
            "      Successfully uninstalled Cython-3.0.12\n",
            "  Attempting uninstall: cloudpathlib\n",
            "    Found existing installation: cloudpathlib 0.21.0\n",
            "    Uninstalling cloudpathlib-0.21.0:\n",
            "      Successfully uninstalled cloudpathlib-0.21.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 2.0.10\n",
            "    Uninstalling catalogue-2.0.10:\n",
            "      Successfully uninstalled catalogue-2.0.10\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.5.1\n",
            "    Uninstalling srsly-2.5.1:\n",
            "      Successfully uninstalled srsly-2.5.1\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.27.2\n",
            "    Uninstalling pydantic_core-2.27.2:\n",
            "      Successfully uninstalled pydantic_core-2.27.2\n",
            "  Attempting uninstall: preshed\n",
            "    Found existing installation: preshed 3.0.9\n",
            "    Uninstalling preshed-3.0.9:\n",
            "      Successfully uninstalled preshed-3.0.9\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: marisa-trie\n",
            "    Found existing installation: marisa-trie 1.2.1\n",
            "    Uninstalling marisa-trie-1.2.1:\n",
            "      Successfully uninstalled marisa-trie-1.2.1\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 1.2.0\n",
            "    Uninstalling blis-1.2.0:\n",
            "      Successfully uninstalled blis-1.2.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.6\n",
            "    Uninstalling pydantic-2.10.6:\n",
            "      Successfully uninstalled pydantic-2.10.6\n",
            "  Attempting uninstall: language-data\n",
            "    Found existing installation: language_data 1.3.0\n",
            "    Uninstalling language_data-1.3.0:\n",
            "      Successfully uninstalled language_data-1.3.0\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.15.2\n",
            "    Uninstalling typer-0.15.2:\n",
            "      Successfully uninstalled typer-0.15.2\n",
            "  Attempting uninstall: langcodes\n",
            "    Found existing installation: langcodes 3.5.0\n",
            "    Uninstalling langcodes-3.5.0:\n",
            "      Successfully uninstalled langcodes-3.5.0\n",
            "  Attempting uninstall: confection\n",
            "    Found existing installation: confection 0.1.5\n",
            "    Uninstalling confection-0.1.5:\n",
            "      Successfully uninstalled confection-0.1.5\n",
            "  Attempting uninstall: weasel\n",
            "    Found existing installation: weasel 0.4.1\n",
            "    Uninstalling weasel-0.4.1:\n",
            "      Successfully uninstalled weasel-0.4.1\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.3.4\n",
            "    Uninstalling thinc-8.3.4:\n",
            "      Successfully uninstalled thinc-8.3.4\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.8.4\n",
            "    Uninstalling spacy-3.8.4:\n",
            "      Successfully uninstalled spacy-3.8.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "transformer-smaller-training-vocab 0.4.0 requires numpy<2.0.0,>=1.21.0; python_version >= \"3.9\", but you have numpy 2.2.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Cython-3.0.12 MarkupSafe-3.0.2 annotated-types-0.7.0 blis-1.2.0 catalogue-2.0.10 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 cloudpathlib-0.21.0 confection-0.1.5 cymem-2.0.11 idna-3.10 jinja2-3.1.6 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.12 numpy-2.2.4 packaging-24.2 preshed-3.0.9 pydantic-2.10.6 pydantic-core-2.27.2 pygments-2.19.1 requests-2.32.3 rich-13.9.4 setuptools-77.0.3 shellingham-1.5.4 smart-open-7.1.0 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 tqdm-4.67.1 typer-0.15.2 typing-extensions-4.12.2 urllib3-2.3.0 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "certifi"
                ]
              },
              "id": "f2d68674a30945eabc457eb62fccf1ba"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing on smaller dataset\n",
        "import re\n",
        "import json\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "from threading import Lock\n",
        "\n",
        "# Load models\n",
        "flair_tagger = SequenceTagger.load(\"flair/pos-english\")\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Constants\n",
        "PHONE_REGEX = r\"\\b(\\+\\d{1,4}\\s?)?(\\(?\\d{1,4}\\)?[-.]?\\s?)?\\d{3,4}[-.]?\\d{3,4}[-.]?\\d{3,4}\\b\"\n",
        "DESCRIPTIVE_COLUMNS = {\"description\", \"comment\", \"comments\", \"query\", \"notes\"}\n",
        "SENSITIVE_COLUMNS = set()\n",
        "MAPPINGS = {}\n",
        "VALUE_TO_MASK = {}\n",
        "mask_lock = Lock()\n",
        "\n",
        "def is_noun_column(texts):\n",
        "    \"\"\"Identify if a column contains mostly nouns based on a sample.\"\"\"\n",
        "    texts = [\"\" if pd.isna(text) else str(text) for text in texts]\n",
        "    sentences = [Sentence(text) for text in texts]\n",
        "    flair_tagger.predict(sentences)\n",
        "    noun_count = sum(any(\"NN\" in token.tag for token in sent) for sent in sentences)\n",
        "    return noun_count > (len(texts) * 0.6)\n",
        "\n",
        "def mask_text(text, col_name, row_idx):\n",
        "    \"\"\"Mask the input text and store the mapping.\"\"\"\n",
        "    if pd.isna(text) or str(text).strip() == \"\":\n",
        "        return text\n",
        "    with mask_lock:\n",
        "        if text in VALUE_TO_MASK:\n",
        "            return VALUE_TO_MASK[text]\n",
        "        masked_value = f\"{col_name}_{row_idx}\"\n",
        "        VALUE_TO_MASK[text] = masked_value\n",
        "        MAPPINGS[masked_value] = text\n",
        "    return masked_value\n",
        "\n",
        "def process_chunk(chunk):\n",
        "    \"\"\"Process a dataframe chunk (30 rows) for masking and return a new masked DataFrame.\"\"\"\n",
        "    # Create a copy of the DataFrame to avoid modifying the original\n",
        "    new_chunk = chunk.copy()\n",
        "\n",
        "    for row_idx in new_chunk.index:\n",
        "        # Mask sensitive columns\n",
        "        for col in SENSITIVE_COLUMNS:\n",
        "            new_chunk.loc[row_idx, col] = mask_text(new_chunk.loc[row_idx, col], col, row_idx)\n",
        "\n",
        "        # Mask phone numbers\n",
        "        for col in new_chunk.columns:\n",
        "            new_chunk.loc[row_idx, col] = re.sub(PHONE_REGEX, lambda m: mask_text(m.group(0), \"phone\", row_idx), str(new_chunk.loc[row_idx, col]))\n",
        "\n",
        "        # Mask descriptive text columns\n",
        "        for col in set(DESCRIPTIVE_COLUMNS) & set(new_chunk.columns):\n",
        "            doc = nlp(str(new_chunk.loc[row_idx, col]))\n",
        "            for ent in doc.ents:\n",
        "                new_chunk.loc[row_idx, col] = new_chunk.loc[row_idx, col].replace(ent.text, mask_text(ent.text, col, row_idx))\n",
        "\n",
        "    return new_chunk  # Returning the new modified DataFrame\n",
        "\n",
        "\n",
        "def main(file_path):\n",
        "    \"\"\"Process only 30 rows of the CSV file.\"\"\"\n",
        "    global SENSITIVE_COLUMNS\n",
        "    # Read first 30 rows\n",
        "    df = pd.read_csv(file_path, nrows=30)\n",
        "\n",
        "    # Identify sensitive columns (case-insensitive)\n",
        "    SENSITIVE_COLUMNS = {col for col in df.columns if is_noun_column(df[col].astype(str).tolist())}\n",
        "\n",
        "    # Process and save output\n",
        "    processed_df = process_chunk(df)\n",
        "    print(\"\\nProcessed Data:\\n\", processed_df.head(10))  # Display first 10 rows for verification\n",
        "    processed_df.to_csv(\"masked_output.csv\", index=False)\n",
        "\n",
        "    with open(\"mappings.json\", \"w\") as f:\n",
        "        json.dump(MAPPINGS, f)\n",
        "\n",
        "    print(\"Processing complete. Masked data saved.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main('smaller_companies.csv')\n"
      ],
      "metadata": {
        "id": "CS9jIsokfzzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TESTING CODE!**"
      ],
      "metadata": {
        "id": "wpOzics_xYe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Regex\n",
        "EMAIL_REGEX = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
        "PHONE_REGEX = r\"\\b(\\+\\d{1,4}\\s?)?(\\(?\\d{1,4}\\)?[-.]?\\s?)?\\d{3,4}[-.]?\\d{3,4}[-.]?\\d{3,4}\\b\"\n",
        "\n",
        "# def detect_noun_desc(text):\n",
        "#     doc = nlp(text)\n",
        "#     modified_text = []\n",
        "\n",
        "#     for token in doc:\n",
        "#         token_text = token.text\n",
        "\n",
        "#         if re.fullmatch(EMAIL_REGEX, token_text):\n",
        "#             modified_text.append(\"<email>\")\n",
        "#         elif re.fullmatch(PHONE_REGEX, token_text):\n",
        "#             modified_text.append(\"<phone>\")\n",
        "#         elif token.pos_ == \"PROPN\":\n",
        "#             modified_text.append(\"<sensitive>\")\n",
        "#         else:\n",
        "#             modified_text.append(token_text)\n",
        "\n",
        "#     return \" \".join(modified_text)\n",
        "\n",
        "def detect_noun(file_path):\n",
        "    if file_path.endswith(\".csv\"):\n",
        "        df = pd.read_csv(file_path, engine=\"python\")\n",
        "    elif file_path.endswith((\".xls\", \".xlsx\")):\n",
        "        df = pd.read_excel(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please provide a CSV or Excel file.\")\n",
        "\n",
        "    sensitive = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype in ['int64', 'float64']:\n",
        "            continue  # Skip purely numeric columns\n",
        "\n",
        "        text_samples = df[col].astype(str).head(5)  # Take first 5 values\n",
        "        noun_count = 0\n",
        "        total_count = 0\n",
        "\n",
        "        for value in text_samples:\n",
        "            if \"%\" in value or value.replace(\".\", \"\").isdigit():\n",
        "                continue  # Skip percentage or number-like values\n",
        "\n",
        "            doc = nlp(value)\n",
        "            for token in doc:\n",
        "                if token.pos_ in ['NOUN', 'PROPN']:\n",
        "                    noun_count += 1\n",
        "                total_count += 1\n",
        "\n",
        "        # Mark column as sensitive only if a significant portion are nouns\n",
        "        if total_count > 0 and (noun_count / total_count) > 0.2:\n",
        "            sensitive.append(col)\n",
        "\n",
        "    return sensitive"
      ],
      "metadata": {
        "id": "R4UOPh72x2mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def descriptive_cols(file_path):\n",
        "    \"\"\"\n",
        "    Reads a CSV or Excel file, removes column names similar to 'description', 'remarks', etc.,\n",
        "    and returns a filtered list of sensitive columns.\n",
        "    \"\"\"\n",
        "    # Define keywords to filter out\n",
        "    keywords = [\"description\", \"remarks\", \"notes\", \"comments\", \"observations\", \"details\", \"summary\", \"explanation\",\n",
        "    \"reviews\", \"feedback\", \"testimonials\", \"opinions\", \"assessment\", \"suggestions\", \"experience\",\n",
        "    \"incident_report\", \"case_notes\", \"audit_notes\", \"findings\", \"status_update\", \"history\", \"progress_report\",\n",
        "    \"additional_info\", \"clarifications\", \"justification\", \"annotations\", \"excerpts\", \"statement\", \"explanation_text\"]\n",
        "\n",
        "    # Ensure columns are properly loaded from CSV/Excel\n",
        "    if file_path.endswith(\".csv\"):\n",
        "        df = pd.read_csv(file_path, nrows=1)  # Read only header\n",
        "    elif file_path.endswith((\".xls\", \".xlsx\")):\n",
        "        df = pd.read_excel(file_path, nrows=1, engine=\"openpyxl\")  # Read only header\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please provide a CSV or Excel file.\")\n",
        "\n",
        "    # Get actual column names\n",
        "    all_columns = df.columns.tolist()\n",
        "\n",
        "    # Filter out columns that match the keywords\n",
        "    filtered_columns = [col for col in all_columns if any(re.search(keyword, col, re.IGNORECASE) for keyword in keywords)]\n",
        "\n",
        "    return filtered_columns\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R6F-UtGRxt9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "# nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def detect_noun(file_path):\n",
        "    # Detect file type and read accordingly\n",
        "    if file_path.endswith(\".csv\"):\n",
        "        df = pd.read_csv(file_path, engine=\"python\")\n",
        "    elif file_path.endswith((\".xls\", \".xlsx\")):\n",
        "        df = pd.read_excel(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please provide a CSV or Excel file.\")\n",
        "\n",
        "    sensitive = []\n",
        "    column=[]\n",
        "    for col in df.columns:\n",
        "        column.append(col)\n",
        "        # **Skip numeric columns**\n",
        "        if pd.api.types.is_numeric_dtype(df[col]): continue\n",
        "\n",
        "        # **Process only non-empty, valid string values**\n",
        "        valid_values = df[col].dropna().astype(str)  # Remove NaN\n",
        "        valid_values = [val for val in valid_values.head(3) if val.lower() not in [\"nan\", \"none\", \"\",\"na\",\"null\",\"n/a\"]]\n",
        "\n",
        "        for value in valid_values:\n",
        "            doc = nlp(value)\n",
        "            noun_count = sum(1 for token in doc if token.pos_ in ['NOUN', 'PROPN'])\n",
        "            word_count = len(doc)\n",
        "\n",
        "            # **Mark column as sensitive only if a high % of words are nouns**\n",
        "            if word_count > 0 and (noun_count / word_count) > 0.2:\n",
        "                if col not in sensitive:\n",
        "                    sensitive.append(col)\n",
        "    print(column)\n",
        "    print(sensitive)\n",
        "    return sensitive\n",
        "\n"
      ],
      "metadata": {
        "id": "hIImmYAbxsnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing code!\n",
        "# Main code\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "mapping = {}\n",
        "\n",
        "def csv_an(input_file, output_file):\n",
        "    df = pd.read_csv(input_file, engine=\"python\")\n",
        "\n",
        "    sensitive_old = detect_noun(input_file)\n",
        "    descrp = descriptive_cols(input_file)\n",
        "    sensitive = list(set(sensitive_old) - set(descrp))\n",
        "    column_counters = {col: 1 for col in df.columns if col in sensitive_old}\n",
        "    column_mappings = {col: {} for col in sensitive}  # Store mappings for each column\n",
        "\n",
        "    for col in sensitive:\n",
        "        new_values = []\n",
        "        for val in df[col].astype(str):\n",
        "            if pd.notna(val):\n",
        "                if val in column_mappings[col]:\n",
        "                    anonymized_value = column_mappings[col][val]  # Use existing mapping\n",
        "                else:\n",
        "                    anonymized_value = f\"{col}{column_counters[col]}\"\n",
        "                    column_mappings[col][val] = anonymized_value  # Store new mapping\n",
        "                    column_counters[col] += 1  # Increment counter\n",
        "\n",
        "                mapping[anonymized_value] = val\n",
        "                new_values.append(anonymized_value)\n",
        "            else:\n",
        "                new_values.append(val)\n",
        "        df[col] = new_values\n",
        "\n",
        "    for col in descrp:\n",
        "        for idx, val in enumerate(df[col].astype(str)):\n",
        "            if pd.notna(val):\n",
        "                df.at[idx, col] = detect_noun_desc(val)\n",
        "\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Anonymized file saved as {output_file}\")\n",
        "\n",
        "    # Save mapping as JSON\n",
        "    with open(\"mappings.json\", \"w\") as f:\n",
        "        json.dump(mapping, f)\n",
        "\n",
        "\n",
        "csv_an('testing-csv-ff.csv', 'masked_csv_output.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJhoM_Lrw3Gt",
        "outputId": "360b7443-725b-4fcc-b2a5-5876878391b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Reporting Month', 'Cluster Name', 'Input Account Name', 'Account Name', 'New Assets Issuance', 'Allocations', 'Welcome Email', 'Onboarding Trainings', 'BGV', 'NDA', 'Granting Access', 'Client Onboarding', 'Deallocation', 'Assets Return', 'Access Removal', 'Compliance % on mandatory trainings', 'Compliance % on mandatory audits', 'Timesheet Compliance %']\n",
            "['Reporting Month', 'Cluster Name', 'Input Account Name', 'Account Name', 'Client Onboarding', 'Compliance % on mandatory trainings', 'Compliance % on mandatory audits', 'Timesheet Compliance %']\n",
            "Anonymized file saved as masked_csv_output.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CONSOLITATING CODE**"
      ],
      "metadata": {
        "id": "8_D1dww-ehSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flair\n",
        "!pip install faker\n",
        "!pip install presidio_analyzer\n",
        "!pip install presidio_anonymizer\n",
        "# !python -m spacy download en_core_web_lg\n",
        "!pip install --upgrade --force-reinstall \"numpy==1.26.4\"\n",
        "!pip install --upgrade --force-reinstall \"Cython\" \"spacy\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FU2nNoKeesf-",
        "outputId": "ba078415-05fe-4b4a-ba31-584d5f60d5f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flair in /usr/local/lib/python3.11/dist-packages (0.15.1)\n",
            "Requirement already satisfied: boto3>=1.20.27 in /usr/local/lib/python3.11/dist-packages (from flair) (1.37.19)\n",
            "Requirement already satisfied: conllu<5.0.0,>=4.0 in /usr/local/lib/python3.11/dist-packages (from flair) (4.5.3)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.11/dist-packages (from flair) (1.2.18)\n",
            "Requirement already satisfied: ftfy>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from flair) (6.3.1)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from flair) (5.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from flair) (0.29.3)\n",
            "Requirement already satisfied: langdetect>=1.0.9 in /usr/local/lib/python3.11/dist-packages (from flair) (1.0.9)\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from flair) (5.3.1)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from flair) (3.10.0)\n",
            "Requirement already satisfied: more-itertools>=8.13.0 in /usr/local/lib/python3.11/dist-packages (from flair) (10.6.0)\n",
            "Requirement already satisfied: mpld3>=0.3 in /usr/local/lib/python3.11/dist-packages (from flair) (0.5.10)\n",
            "Requirement already satisfied: pptree>=3.1 in /usr/local/lib/python3.11/dist-packages (from flair) (3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from flair) (2.8.2)\n",
            "Requirement already satisfied: pytorch-revgrad>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from flair) (0.2.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from flair) (2024.11.6)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from flair) (1.6.1)\n",
            "Requirement already satisfied: segtok>=1.5.11 in /usr/local/lib/python3.11/dist-packages (from flair) (1.5.11)\n",
            "Requirement already satisfied: sqlitedict>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from flair) (2.1.0)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.11/dist-packages (from flair) (0.9.0)\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from flair) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.63.0 in /usr/local/lib/python3.11/dist-packages (from flair) (4.67.1)\n",
            "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from flair) (0.4.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.25.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (4.49.0)\n",
            "Requirement already satisfied: wikipedia-api>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from flair) (0.8.1)\n",
            "Requirement already satisfied: bioc<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from flair) (2.1)\n",
            "Requirement already satisfied: jsonlines>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from bioc<3.0.0,>=2.0.0->flair) (4.0.0)\n",
            "Requirement already satisfied: intervaltree in /usr/local/lib/python3.11/dist-packages (from bioc<3.0.0,>=2.0.0->flair) (3.1.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.11/dist-packages (from bioc<3.0.0,>=2.0.0->flair) (0.6.2)\n",
            "Requirement already satisfied: botocore<1.38.0,>=1.37.19 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.20.27->flair) (1.37.19)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.20.27->flair) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.20.27->flair) (0.11.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.13->flair) (1.17.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair) (2.32.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (4.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect>=1.0.9->flair) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (2.2.4)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mpld3>=0.3->flair) (3.1.6)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair) (3.6.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.1->flair) (1.3.0)\n",
            "Collecting numpy>=1.23 (from matplotlib>=2.2.3->flair)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (5.29.4)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.19->boto3>=1.20.27->flair) (2.3.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair) (25.3.0)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (1.5.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.6)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mpld3>=0.3->flair) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (1.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (5.9.5)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.4\n",
            "    Uninstalling numpy-2.2.4:\n",
            "      Successfully uninstalled numpy-2.2.4\n",
            "Successfully installed numpy-1.26.4\n",
            "Requirement already satisfied: faker in /usr/local/lib/python3.11/dist-packages (37.1.0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.1)\n",
            "Requirement already satisfied: presidio_analyzer in /usr/local/lib/python3.11/dist-packages (2.2.358)\n",
            "Requirement already satisfied: phonenumbers<9.0.0,>=8.12 in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (8.13.55)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (6.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (2024.11.6)\n",
            "Requirement already satisfied: spacy!=3.7.0,<4.0.0,>=3.4.4 in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (3.8.4)\n",
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (5.1.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (78.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.5.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio_analyzer) (3.10)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio_analyzer) (2.1.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio_analyzer) (3.18.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.1.2)\n",
            "Requirement already satisfied: presidio_anonymizer in /usr/local/lib/python3.11/dist-packages (2.2.358)\n",
            "Requirement already satisfied: cryptography<44.1 in /usr/local/lib/python3.11/dist-packages (from presidio_anonymizer) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<44.1->presidio_anonymizer) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<44.1->presidio_anonymizer) (2.22)\n",
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "Successfully installed numpy-1.26.4\n",
            "Collecting Cython\n",
            "  Using cached Cython-3.0.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting spacy\n",
            "  Using cached spacy-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
            "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
            "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
            "  Using cached murmurhash-1.0.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
            "  Using cached cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
            "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
            "  Using cached preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
            "  Using cached thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
            "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
            "  Using cached srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
            "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
            "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
            "  Using cached typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting tqdm<5.0.0,>=4.38.0 (from spacy)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting numpy>=1.19.0 (from spacy)\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting requests<3.0.0,>=2.13.0 (from spacy)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
            "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting jinja2 (from spacy)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting setuptools (from spacy)\n",
            "  Using cached setuptools-78.0.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting packaging>=20.0 (from spacy)\n",
            "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
            "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
            "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
            "  Using cached pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting typing-extensions>=4.12.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3.0.0,>=2.13.0->spacy)\n",
            "  Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.13.0->spacy)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.13.0->spacy)\n",
            "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.13.0->spacy)\n",
            "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
            "  Using cached blis-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
            "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting click>=8.0.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
            "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
            "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
            "  Using cached cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
            "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->spacy)\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
            "  Using cached marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
            "  Using cached pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
            "  Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Using cached Cython-3.0.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Using cached spacy-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.6 MB)\n",
            "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
            "Using cached cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (218 kB)\n",
            "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
            "Using cached murmurhash-1.0.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (134 kB)\n",
            "Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
            "Using cached preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
            "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "Using cached pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
            "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
            "Using cached srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Using cached thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached typer-0.15.2-py3-none-any.whl (45 kB)\n",
            "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
            "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached setuptools-78.0.2-py3-none-any.whl (1.3 MB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached blis-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Using cached cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
            "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
            "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "Using cached marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: cymem, wrapt, wasabi, urllib3, typing-extensions, tqdm, spacy-loggers, spacy-legacy, shellingham, setuptools, pygments, packaging, numpy, murmurhash, mdurl, MarkupSafe, idna, Cython, cloudpathlib, click, charset-normalizer, certifi, catalogue, annotated-types, srsly, smart-open, requests, pydantic-core, preshed, markdown-it-py, marisa-trie, jinja2, blis, rich, pydantic, language-data, typer, langcodes, confection, weasel, thinc, spacy\n",
            "  Attempting uninstall: cymem\n",
            "    Found existing installation: cymem 2.0.11\n",
            "    Uninstalling cymem-2.0.11:\n",
            "      Successfully uninstalled cymem-2.0.11\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.3\n",
            "    Uninstalling wasabi-1.1.3:\n",
            "      Successfully uninstalled wasabi-1.1.3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: spacy-loggers\n",
            "    Found existing installation: spacy-loggers 1.0.5\n",
            "    Uninstalling spacy-loggers-1.0.5:\n",
            "      Successfully uninstalled spacy-loggers-1.0.5\n",
            "  Attempting uninstall: spacy-legacy\n",
            "    Found existing installation: spacy-legacy 3.0.12\n",
            "    Uninstalling spacy-legacy-3.0.12:\n",
            "      Successfully uninstalled spacy-legacy-3.0.12\n",
            "  Attempting uninstall: shellingham\n",
            "    Found existing installation: shellingham 1.5.4\n",
            "    Uninstalling shellingham-1.5.4:\n",
            "      Successfully uninstalled shellingham-1.5.4\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 78.0.2\n",
            "    Uninstalling setuptools-78.0.2:\n",
            "      Successfully uninstalled setuptools-78.0.2\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.19.1\n",
            "    Uninstalling Pygments-2.19.1:\n",
            "      Successfully uninstalled Pygments-2.19.1\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: murmurhash\n",
            "    Found existing installation: murmurhash 1.0.12\n",
            "    Uninstalling murmurhash-1.0.12:\n",
            "      Successfully uninstalled murmurhash-1.0.12\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 3.0.12\n",
            "    Uninstalling Cython-3.0.12:\n",
            "      Successfully uninstalled Cython-3.0.12\n",
            "  Attempting uninstall: cloudpathlib\n",
            "    Found existing installation: cloudpathlib 0.21.0\n",
            "    Uninstalling cloudpathlib-0.21.0:\n",
            "      Successfully uninstalled cloudpathlib-0.21.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 2.0.10\n",
            "    Uninstalling catalogue-2.0.10:\n",
            "      Successfully uninstalled catalogue-2.0.10\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.5.1\n",
            "    Uninstalling srsly-2.5.1:\n",
            "      Successfully uninstalled srsly-2.5.1\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.27.2\n",
            "    Uninstalling pydantic_core-2.27.2:\n",
            "      Successfully uninstalled pydantic_core-2.27.2\n",
            "  Attempting uninstall: preshed\n",
            "    Found existing installation: preshed 3.0.9\n",
            "    Uninstalling preshed-3.0.9:\n",
            "      Successfully uninstalled preshed-3.0.9\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: marisa-trie\n",
            "    Found existing installation: marisa-trie 1.2.1\n",
            "    Uninstalling marisa-trie-1.2.1:\n",
            "      Successfully uninstalled marisa-trie-1.2.1\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 1.2.0\n",
            "    Uninstalling blis-1.2.0:\n",
            "      Successfully uninstalled blis-1.2.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.6\n",
            "    Uninstalling pydantic-2.10.6:\n",
            "      Successfully uninstalled pydantic-2.10.6\n",
            "  Attempting uninstall: language-data\n",
            "    Found existing installation: language_data 1.3.0\n",
            "    Uninstalling language_data-1.3.0:\n",
            "      Successfully uninstalled language_data-1.3.0\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.15.2\n",
            "    Uninstalling typer-0.15.2:\n",
            "      Successfully uninstalled typer-0.15.2\n",
            "  Attempting uninstall: langcodes\n",
            "    Found existing installation: langcodes 3.5.0\n",
            "    Uninstalling langcodes-3.5.0:\n",
            "      Successfully uninstalled langcodes-3.5.0\n",
            "  Attempting uninstall: confection\n",
            "    Found existing installation: confection 0.1.5\n",
            "    Uninstalling confection-0.1.5:\n",
            "      Successfully uninstalled confection-0.1.5\n",
            "  Attempting uninstall: weasel\n",
            "    Found existing installation: weasel 0.4.1\n",
            "    Uninstalling weasel-0.4.1:\n",
            "      Successfully uninstalled weasel-0.4.1\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.3.4\n",
            "    Uninstalling thinc-8.3.4:\n",
            "      Successfully uninstalled thinc-8.3.4\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.8.4\n",
            "    Uninstalling spacy-3.8.4:\n",
            "      Successfully uninstalled spacy-3.8.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "transformer-smaller-training-vocab 0.4.0 requires numpy<2.0.0,>=1.21.0; python_version >= \"3.9\", but you have numpy 2.2.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Cython-3.0.12 MarkupSafe-3.0.2 annotated-types-0.7.0 blis-1.2.0 catalogue-2.0.10 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 cloudpathlib-0.21.0 confection-0.1.5 cymem-2.0.11 idna-3.10 jinja2-3.1.6 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.12 numpy-2.2.4 packaging-24.2 preshed-3.0.9 pydantic-2.10.6 pydantic-core-2.27.2 pygments-2.19.1 requests-2.32.3 rich-13.9.4 setuptools-78.0.2 shellingham-1.5.4 smart-open-7.1.0 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 tqdm-4.67.1 typer-0.15.2 typing-extensions-4.12.2 urllib3-2.3.0 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "Cython",
                  "_distutils_hack",
                  "blis",
                  "catalogue",
                  "certifi",
                  "charset_normalizer",
                  "confection",
                  "cymem",
                  "cython",
                  "langcodes",
                  "markupsafe",
                  "murmurhash",
                  "preshed",
                  "requests",
                  "shellingham",
                  "spacy",
                  "srsly",
                  "thinc",
                  "tqdm",
                  "wasabi",
                  "weasel",
                  "wrapt"
                ]
              },
              "id": "b8281dfbdaac404cb2b4b80c2836c068"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import time\n",
        "import spacy\n",
        "import openpyxl\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "mapping={}\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def time_it(func):\n",
        "  def wrapper(*args, **kwargs):\n",
        "    start = time.time()\n",
        "    result = func(*args, **kwargs)\n",
        "    end = time.time()\n",
        "    print(f'\\n\\nExecution time {func.__name__}: {end-start:.6f} seconds')\n",
        "    return result\n",
        "  return wrapper\n",
        "\n",
        "#-------------------------------------------------------------------------------------------------------------------------------\n",
        "#function to find out the noun values dominating columns considering it will be a sensitive data if there is so many nouns\n",
        "#------------------------------------------------------------------------------------------------------------------------------\n",
        "def detect_noun(file_path):\n",
        "    if file_path.endswith(\".csv\"):\n",
        "        df = pd.read_csv(file_path, engine=\"python\")\n",
        "    elif file_path.endswith((\".xls\", \".xlsx\")):\n",
        "        df = pd.read_excel(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please provide a CSV or Excel file.\")\n",
        "\n",
        "    sensitive = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype in ['int64', 'float64']:\n",
        "            continue  # Skip purely numeric columns\n",
        "\n",
        "        text_samples = df[col].astype(str).head(5)  # Take first 5 values\n",
        "        noun_count = 0\n",
        "        total_count = 0\n",
        "\n",
        "        for value in text_samples:\n",
        "            if \"%\" in value or value.replace(\".\", \"\").isdigit():\n",
        "                continue  # Skip percentage or number-like values\n",
        "\n",
        "            doc = nlp(value)\n",
        "            for token in doc:\n",
        "                if token.pos_ in ['NOUN', 'PROPN']:\n",
        "                    noun_count += 1\n",
        "                total_count += 1\n",
        "\n",
        "        # Mark column as sensitive only if a significant portion are nouns\n",
        "        if total_count > 0 and (noun_count / total_count) > 0.2:\n",
        "            sensitive.append(col)\n",
        "\n",
        "    return sensitive\n",
        "\n",
        "\n",
        "#------------------------------------------------------------------------------------------\n",
        "#finding out the descriptive data columns which may have sensitive data in the form of text\n",
        "#------------------------------------------------------------------------------------------\n",
        "def descriptive_columns(file_path):\n",
        "    # Define keywords to filter out\n",
        "    keywords = [\"description\", \"remarks\", \"notes\", \"comments\", \"observations\", \"details\", \"summary\", \"explanation\",\n",
        "    \"reviews\", \"feedback\", \"testimonials\", \"opinions\", \"assessment\", \"suggestions\", \"experience\",\n",
        "    \"incident_report\", \"case_notes\", \"audit_notes\", \"findings\", \"status_update\", \"history\", \"progress_report\",\n",
        "    \"additional_info\", \"clarifications\", \"justification\", \"annotations\", \"excerpts\", \"statement\", \"explanation_text\"]\n",
        "\n",
        "    # Ensure columns are properly loaded from CSV/Excel\n",
        "    if file_path.endswith(\".csv\"):\n",
        "        df = pd.read_csv(file_path, nrows=1)  # Read only header\n",
        "    elif file_path.endswith((\".xls\", \".xlsx\")):\n",
        "        df = pd.read_excel(file_path, nrows=1, engine=\"openpyxl\")  # Read only header\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please provide a CSV or Excel file.\")\n",
        "\n",
        "    # Get actual column names\n",
        "    all_columns = df.columns.tolist()\n",
        "\n",
        "\n",
        "    des=[col for col in all_columns if any(re.search(keyword, col, re.IGNORECASE) for keyword in keywords)]\n",
        "    return des\n",
        "\n",
        "#-----------------------------------------------------------------\n",
        "#anonymizing descriptive values\n",
        "#-----------------------------------------------------------------\n",
        "def detect_noun_desc(text):\n",
        "    doc = nlp(text)\n",
        "    modified_text=[]\n",
        "    for token in doc:\n",
        "        if token.pos_ in ['PROPN']:\n",
        "            modified_text.append(\"<sensitive>\")\n",
        "        else:\n",
        "            modified_text.append(token.text)\n",
        "    text=\" \".join(modified_text)\n",
        "    return text\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "#function to anonymize a excel file\n",
        "#-------------------------------------------------------------------\n",
        "def excel_an(input_file, output_file):\n",
        "    df = pd.read_excel(input_file)  # Read as string for safety\n",
        "\n",
        "    sensitive_old = detect_noun(input_file)\n",
        "    desc = descriptive_columns(input_file)\n",
        "    sensitive = list(set(sensitive_old) - set(desc))\n",
        "\n",
        "    column_counters = {col: 1 for col in df.columns if col in sensitive_old}\n",
        "    column_mappings = {col: {} for col in sensitive}  # Store mappings for each column\n",
        "    mapping = {}\n",
        "\n",
        "    # Anonymize sensitive columns while maintaining consistency\n",
        "    for col in sensitive:\n",
        "        new_values = []\n",
        "        for val in df[col].astype(str):\n",
        "            if pd.notna(val):\n",
        "                if val in column_mappings[col]:\n",
        "                    anonymized_value = column_mappings[col][val]  # Use existing mapping\n",
        "                else:\n",
        "                    anonymized_value = f\"{col}{column_counters[col]}\"\n",
        "                    column_mappings[col][val] = anonymized_value  # Store new mapping\n",
        "                    column_counters[col] += 1  # Increment counter\n",
        "\n",
        "                mapping[anonymized_value] = val\n",
        "                new_values.append(anonymized_value)\n",
        "            else:\n",
        "                new_values.append(val)\n",
        "\n",
        "        df[col] = new_values\n",
        "\n",
        "    # Anonymize descriptive columns\n",
        "    for col in desc:\n",
        "        for idx, val in enumerate(df[col].astype(str)):\n",
        "            if pd.notna(val):\n",
        "                an_values = detect_noun_desc(val)\n",
        "                df.at[idx, col] = an_values\n",
        "                mapping[an_values] = val\n",
        "\n",
        "    df.to_excel(output_file, index=False, sheet_name=\"Anonymized Data\")\n",
        "    print(f\"✅ Anonymized file saved as {output_file}\")\n",
        "\n",
        "    # Save mapping as JSON\n",
        "    with open(\"mappings.json\", \"w\") as f:\n",
        "        json.dump(mapping, f)\n",
        "\n",
        "#------------------------------------------------------\n",
        "#function for de-anonymizing excel data\n",
        "#------------------------------------------------------\n",
        "\n",
        "def excel_dean(input_file, output_file, mapping_file):\n",
        "    print(\"🔄 Loading data...\")\n",
        "\n",
        "    with open(mapping_file, \"r\") as f:\n",
        "        mapping = json.load(f)\n",
        "\n",
        "    df = pd.read_excel(input_file)  # Read as string for safety\n",
        "    mapping_keys = set(mapping.keys())\n",
        "    df = df.applymap(lambda x: mapping[x] if x in mapping_keys else x)\n",
        "    df.to_excel(output_file, index=False, sheet_name=\"De-anonymized Data\")\n",
        "\n",
        "    print(f\"✅ De-anonymized file saved as {output_file}\")\n",
        "\n",
        "#----------------------------------------------------------\n",
        "#function for anonymizing csv data\n",
        "#----------------------------------------------------------\n",
        "def csv_an(input_file, output_file):\n",
        "    df = pd.read_csv(input_file, engine=\"python\")\n",
        "\n",
        "    sensitive_old = detect_noun(input_file)\n",
        "    desc = descriptive_columns(input_file)\n",
        "    sensitive = list(set(sensitive_old) - set(desc))\n",
        "\n",
        "    column_counters = {col: 1 for col in df.columns if col in sensitive_old}\n",
        "    column_mappings = {col: {} for col in sensitive}  # Store mappings for each column\n",
        "\n",
        "    # Anonymize sensitive columns while maintaining consistency\n",
        "    for col in sensitive:\n",
        "        new_values = []\n",
        "        for val in df[col].astype(str):\n",
        "            if pd.notna(val):\n",
        "                if val in column_mappings[col]:\n",
        "                    anonymized_value = column_mappings[col][val]  # Use existing mapping\n",
        "                else:\n",
        "                    anonymized_value = f\"{col}{column_counters[col]}\"\n",
        "                    column_mappings[col][val] = anonymized_value  # Store new mapping\n",
        "                    column_counters[col] += 1  # Increment counter\n",
        "\n",
        "                mapping[anonymized_value] = val\n",
        "                new_values.append(anonymized_value)\n",
        "            else:\n",
        "                new_values.append(val)\n",
        "\n",
        "        df[col] = new_values\n",
        "\n",
        "    # Anonymize descriptive columns\n",
        "    for col in desc:\n",
        "        for idx, val in enumerate(df[col].astype(str)):\n",
        "            if pd.notna(val):\n",
        "                an_values = detect_noun_desc(val)\n",
        "                df.at[idx, col] = an_values\n",
        "                mapping[an_values] = val\n",
        "\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"✅ Anonymized file saved as {output_file}\")\n",
        "\n",
        "    # Save mapping as JSON\n",
        "    with open(\"mappings.json\", \"w\") as f:\n",
        "        json.dump(mapping, f)\n",
        "\n",
        "#------------------------------------------------------------\n",
        "#function for de anonymizing csv data\n",
        "#------------------------------------------------------------\n",
        "def csv_dean(input_file, output_file, mapping_file):\n",
        "    print(\"🔄 Loading data...\")\n",
        "\n",
        "    with open(mapping_file, \"r\") as f:\n",
        "        mapping = json.load(f)\n",
        "    df = pd.read_csv(input_file, engine=\"python\", dtype=str)  # Read as string for safety\n",
        "    mapping_keys = set(mapping.keys())\n",
        "    df = df.applymap(lambda x: mapping[x] if x in mapping_keys else x)\n",
        "    df.to_csv(output_file, index=False)\n",
        "\n",
        "    print(f\"✅ De-anonymized file saved as {output_file}\")\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------\n",
        "#function to determine whcih type of data is need to perform\n",
        "#--------------------------------------------------------------\n",
        "@time_it\n",
        "def anonymization(input_file):\n",
        "    if input_file.endswith(\".csv\"):\n",
        "        csv_an(input_file,\"intermediate.csv\")\n",
        "        csv_dean(\"intermediate.csv\",\"deanonymized.csv\",\"mappings.json\")\n",
        "    elif input_file.endswith(\".xlsx\"):\n",
        "        excel_an(input_file,\"intermediate.xlsx\")\n",
        "        excel_dean(\"intermediate.xlsx\",\"deanonymized.xlsx\",\"mappings.json\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0].strip().replace(' ', '-')\n",
        "anonymization(file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "LyYn8GSqeobK",
        "outputId": "70617204-e87a-4923-abe3-bb5acb6e9657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-994c98d3-552c-4c0d-839a-034a26198764\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-994c98d3-552c-4c0d-839a-034a26198764\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving testing-csv-ff.csv to testing-csv-ff.csv\n",
            "✅ Anonymized file saved as intermediate.csv\n",
            "🔄 Loading data...\n",
            "✅ De-anonymized file saved as deanonymized.csv\n",
            "\n",
            "\n",
            "Execution time anonymization: 0.533583 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-c92c682ea52b>:220: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: mapping[x] if x in mapping_keys else x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing simplified consolidated code\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "\n",
        "mapping = {}\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "analyzer = AnalyzerEngine()\n",
        "anonymizer = AnonymizerEngine()\n",
        "\n",
        "def time_it(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f'\\n\\nExecution time {func.__name__}: {end-start:.6f} seconds')\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "def read_file(file_path):\n",
        "    \"\"\"Read CSV or Excel file and return DataFrame.\"\"\"\n",
        "    if file_path.endswith(\".csv\"):\n",
        "        return pd.read_csv(file_path, engine=\"python\"), \"csv\"\n",
        "    elif file_path.endswith(\".xlsx\"):\n",
        "        return pd.read_excel(file_path, engine=\"openpyxl\"), \"excel\"\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please provide a CSV or Excel file.\")\n",
        "\n",
        "def detect_noun(df):\n",
        "    sensitive = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype in ['int64', 'float64'] or re.search(r'\\b(id|rate|amount|price|cost|value|score|percentage)\\b', col, re.IGNORECASE):\n",
        "            continue  # Skip numeric and financial data\n",
        "\n",
        "        text_samples = df[col].astype(str).head(10)\n",
        "        noun_count, total_count = 0, 0\n",
        "\n",
        "        for value in text_samples:\n",
        "            if value.replace(\".\", \"\").isdigit() or '%' in value:\n",
        "                continue\n",
        "\n",
        "            doc = nlp(value)\n",
        "            for token in doc:\n",
        "                if token.pos_ in ['PROPN', 'NOUN']:\n",
        "                    noun_count += 1\n",
        "                total_count += 1\n",
        "\n",
        "        if total_count > 0 and (noun_count / total_count) > 0.5:\n",
        "            sensitive.append(col)\n",
        "\n",
        "    print('\\n\\nSensitive cols:', sensitive)\n",
        "    return sensitive\n",
        "\n",
        "def detect_id_columns(df):\n",
        "    return [col for col in df.columns if re.search(r'\\b(id)$\\b', col, re.IGNORECASE)]\n",
        "\n",
        "def descriptive_columns(df):\n",
        "    keywords = [\"description\", \"remarks\", \"notes\", \"comments\", \"observations\", \"details\", \"summary\", \"explanation\", \"reviews\", \"feedback\", \"history\"]\n",
        "    return [col for col in df.columns if any(re.search(keyword, col, re.IGNORECASE) for keyword in keywords)]\n",
        "\n",
        "def detect_pii(text):\n",
        "    results = analyzer.analyze(text=text, entities=[\"PHONE_NUMBER\", \"CREDIT_CARD\"], language=\"en\")\n",
        "    return anonymizer.anonymize(text=text, analyzer_results=results).text if results else text\n",
        "\n",
        "def detect_pii_columns(df):\n",
        "    \"\"\"Detect columns that contain PII data (phone, credit card, ID).\"\"\"\n",
        "    pii_columns = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        sample_texts = df[col].astype(str).head(10).dropna().tolist()\n",
        "        for text in sample_texts:\n",
        "            if analyzer.analyze(text=text, entities=[\"PHONE_NUMBER\", \"CREDIT_CARD\"], language=\"en\"):\n",
        "                pii_columns.append(col)\n",
        "                break\n",
        "\n",
        "    print(\"\\n\\nPII Columns:\", pii_columns)\n",
        "    return pii_columns\n",
        "\n",
        "def anonymize_data(df):\n",
        "    sensitive = detect_noun(df)\n",
        "    id_cols = detect_id_columns(df)\n",
        "    desc = descriptive_columns(df)\n",
        "    pii_cols = detect_pii_columns(df)\n",
        "    all_sensitive_cols = set(sensitive + id_cols + pii_cols)  # Combine all detected sensitive columns\n",
        "\n",
        "    column_counters = {col: 1 for col in all_sensitive_cols}\n",
        "    column_mappings = {col: {} for col in all_sensitive_cols}\n",
        "\n",
        "    for col in all_sensitive_cols:\n",
        "        new_values = []\n",
        "        for val in df[col].astype(str):\n",
        "            if pd.notna(val):\n",
        "                if val in column_mappings[col]:\n",
        "                    anonymized_value = column_mappings[col][val]\n",
        "                else:\n",
        "                    anonymized_value = f\"{col}{column_counters[col]}\"\n",
        "                    column_mappings[col][val] = anonymized_value\n",
        "                    column_counters[col] += 1\n",
        "                mapping[anonymized_value] = val\n",
        "                new_values.append(anonymized_value)\n",
        "            else:\n",
        "                new_values.append(val)\n",
        "        df[col] = new_values\n",
        "\n",
        "    for col in desc:\n",
        "        df[col] = df[col].astype(str).apply(detect_pii)  # PII masking for descriptive columns\n",
        "\n",
        "    return df\n",
        "\n",
        "def save_file(df, file_type, output_file):\n",
        "    if file_type == \"csv\":\n",
        "        df.to_csv(output_file, index=False)\n",
        "    else:\n",
        "        df.to_excel(output_file, index=False, sheet_name=\"Anonymized Data\")\n",
        "\n",
        "@time_it\n",
        "def anonymization(input_file):\n",
        "    df, file_type = read_file(input_file)\n",
        "    df = anonymize_data(df)\n",
        "    output_file = f\"anonymized.{file_type}\"\n",
        "    save_file(df, file_type, output_file)\n",
        "    with open(\"mappings.json\", \"w\") as f:\n",
        "        json.dump(mapping, f)\n",
        "    print(f\"✅ Anonymized file saved as {output_file}\")\n",
        "\n",
        "@time_it\n",
        "def de_anonymization(input_file, mapping_file):\n",
        "    df, file_type = read_file(input_file)\n",
        "    with open(mapping_file, \"r\") as f:\n",
        "        mapping = json.load(f)\n",
        "    df = df.applymap(lambda x: mapping.get(x, x))\n",
        "    output_file = f\"deanonymized.{file_type}\"\n",
        "    save_file(df, file_type, output_file)\n",
        "    print(f\"✅ De-anonymized file saved as {output_file}\")\n",
        "\n",
        "# uploaded = files.upload()\n",
        "# file_name = list(uploaded.keys())[0].strip().replace(' ', '-')\n",
        "# anonymization(file_name)\n",
        "anonymization(input_file = 'testing-csv-ff.csv')\n",
        "de_anonymization(file_name, \"mappings.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0kvk1-tmiMM",
        "outputId": "99c21a61-8cf3-4cb6-f9a0-d000b9bc8ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Sensitive cols: ['Reporting Month', 'Cluster Name', 'Input Account Name', 'Account Name']\n",
            "\n",
            "\n",
            "PII Columns: ['Mobile Number', 'Credit Card Number']\n",
            "✅ Anonymized file saved as anonymized.csv\n",
            "\n",
            "\n",
            "Execution time anonymization: 4.649121 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-7c67c9f901aa>:138: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: mapping.get(x, x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ De-anonymized file saved as deanonymized.csv\n",
            "\n",
            "\n",
            "Execution time de_anonymization: 0.777546 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Masking prompt from values in mappings.json\n",
        "import json\n",
        "\n",
        "def mask_prompt(prompt, mapping_file=\"mappings.json\"):\n",
        "    \"\"\"Replaces original values in the prompt with masked values from mappings.json.\"\"\"\n",
        "    with open(mapping_file, \"r\") as f:\n",
        "        mapping = json.load(f)\n",
        "\n",
        "    reversed_mapping = {v: k for k, v in mapping.items()}  # Reverse mapping for lookup\n",
        "    for original, masked in reversed_mapping.items():\n",
        "        if original in prompt:\n",
        "            prompt = prompt.replace(original, masked)\n",
        "\n",
        "    return prompt\n",
        "\n",
        "def unmask_response(response, mapping_file=\"mappings.json\"):\n",
        "    \"\"\"Replaces masked values in the response with original values from mappings.json.\"\"\"\n",
        "    with open(mapping_file, \"r\") as f:\n",
        "        mapping = json.load(f)\n",
        "\n",
        "    for masked, original in mapping.items():\n",
        "        if masked in response:\n",
        "            response = response.replace(masked, original)\n",
        "\n",
        "    return response\n",
        "\n",
        "prompt_1 = \"Please analyze the sales performance for Gamma Inc in Mar-24. The key account manager is Alex Brown, and their contact number is 7654321098. Employee ID 35678 was responsible for managing this account. Identify any trends or anomalies.\"\n",
        "prompt_2 = \"For the North cluster, examine the transactions linked to Liam Johnson in Apr-24. His registered mobile number is 5432109876, and the associated credit card number is 4539876543210987. Provide insights on spending patterns and any unusual activities.\"\n",
        "prompt_3 = \"Check the financial records for Theta Corp in Jul-24. The primary contact is William Young, and his phone number is 7654321096. Employee ID 55667 handled this account. Assess if there were any fraudulent transactions.\"\n",
        "\n",
        "response_1 = mask_prompt(prompt_1)\n",
        "\n",
        "print(response_1)\n",
        "print(unmask_response(response_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N01tnBJwrfjE",
        "outputId": "80779337-dd2f-49e3-c652-c1d8bfaa9194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please analyze the sales performance for Input Account Name3 in Reporting Month3. The key account manager is Account Name3, and their contact number is Mobile Number3. Employee ID Employee ID3 was responsible for managing this account. Identify any trends or anomalies.\n",
            "Please analyze the sales performance for Gamma Inc in Mar-24. The key account manager is Alex Brown, and their contact number is 7654321098. Employee ID 35678 was responsible for managing this account. Identify any trends or anomalies.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01gv8UuN-LsJ",
        "outputId": "d0cc5a8b-6104-4bc8-e5e1-001459ee56fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-37.0.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.1)\n",
            "Downloading faker-37.0.2-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-37.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing using Faker\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "from google.colab import files\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "\n",
        "# Initialize dependencies\n",
        "fake = Faker()\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "analyzer = AnalyzerEngine()\n",
        "anonymizer = AnonymizerEngine()\n",
        "\n",
        "mapping = {}  # Stores original-to-anonymized values for de-anonymization\n",
        "\n",
        "def time_it(func):\n",
        "    \"\"\"Decorator to measure execution time.\"\"\"\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f'\\n\\nExecution time {func.__name__}: {end-start:.6f} seconds')\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "def read_file(file_path):\n",
        "    \"\"\"Read CSV or Excel file and return DataFrame.\"\"\"\n",
        "    if file_path.endswith(\".csv\"):\n",
        "        return pd.read_csv(file_path, engine=\"python\"), \"csv\"\n",
        "    elif file_path.endswith(\".xlsx\"):\n",
        "        return pd.read_excel(file_path, engine=\"openpyxl\"), \"excel\"\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please provide a CSV or Excel file.\")\n",
        "\n",
        "def detect_noun(df):\n",
        "    \"\"\"Detect columns that contain mostly noun-based text data.\"\"\"\n",
        "    sensitive = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype in ['int64', 'float64'] or re.search(r'\\b(id|rate|amount|price|cost|value|score|percentage)\\b', col, re.IGNORECASE):\n",
        "            continue  # Skip numeric and financial data\n",
        "\n",
        "        text_samples = df[col].astype(str).head(10)\n",
        "        noun_count, total_count = 0, 0\n",
        "\n",
        "        for value in text_samples:\n",
        "            if value.replace(\".\", \"\").isdigit() or '%' in value:\n",
        "                continue\n",
        "\n",
        "            doc = nlp(value)\n",
        "            for token in doc:\n",
        "                if token.pos_ in ['PROPN', 'NOUN']:\n",
        "                    noun_count += 1\n",
        "                total_count += 1\n",
        "\n",
        "        if total_count > 0 and (noun_count / total_count) > 0.5:\n",
        "            sensitive.append(col)\n",
        "\n",
        "    print('\\n\\nSensitive cols:', sensitive)\n",
        "    return sensitive\n",
        "\n",
        "def detect_id_columns(df):\n",
        "    \"\"\"Detect columns that contain ID values.\"\"\"\n",
        "    return [col for col in df.columns if re.search(r'\\b(id)$\\b', col, re.IGNORECASE)]\n",
        "\n",
        "def descriptive_columns(df):\n",
        "    \"\"\"Detect columns that contain descriptive or free-text data.\"\"\"\n",
        "    keywords = [\"description\", \"remarks\", \"notes\", \"comments\", \"observations\", \"details\", \"summary\", \"explanation\", \"reviews\", \"feedback\", \"history\"]\n",
        "    return [col for col in df.columns if any(re.search(keyword, col, re.IGNORECASE) for keyword in keywords)]\n",
        "\n",
        "def detect_pii(text):\n",
        "    \"\"\"Detect and anonymize PII data in text fields.\"\"\"\n",
        "    results = analyzer.analyze(text=text, entities=[\"PHONE_NUMBER\", \"CREDIT_CARD\"], language=\"en\")\n",
        "    return anonymizer.anonymize(text=text, analyzer_results=results).text if results else text\n",
        "\n",
        "def detect_pii_columns(df):\n",
        "    \"\"\"Detect columns that contain PII data (phone, credit card, etc.).\"\"\"\n",
        "    pii_columns = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        sample_texts = df[col].astype(str).head(10).dropna().tolist()\n",
        "        for text in sample_texts:\n",
        "            if analyzer.analyze(text=text, entities=[\"PHONE_NUMBER\", \"CREDIT_CARD\"], language=\"en\"):\n",
        "                pii_columns.append(col)\n",
        "                break\n",
        "\n",
        "    print(\"\\n\\nPII Columns:\", pii_columns)\n",
        "    return pii_columns\n",
        "\n",
        "# Mapping Faker functions to relevant column types\n",
        "faker_mapping = {\n",
        "    \"name\": fake.name,\n",
        "    \"email\": fake.email,\n",
        "    \"phone\": fake.phone_number,\n",
        "    \"address\": fake.address,\n",
        "    \"uuid\": fake.uuid4,\n",
        "    \"credit_card\": fake.credit_card_number,\n",
        "}\n",
        "\n",
        "def get_faker_value(column_name):\n",
        "    \"\"\"Return a Faker-generated value based on column type.\"\"\"\n",
        "    if re.search(r'\\b(name)\\b', column_name, re.IGNORECASE):\n",
        "        return faker_mapping[\"name\"]()\n",
        "    if re.search(r'\\b(email)\\b', column_name, re.IGNORECASE):\n",
        "        return faker_mapping[\"email\"]()\n",
        "    if re.search(r'\\b(phone|mobile|contact)\\b', column_name, re.IGNORECASE):\n",
        "        return faker_mapping[\"phone\"]()\n",
        "    if re.search(r'\\b(address|location)\\b', column_name, re.IGNORECASE):\n",
        "        return faker_mapping[\"address\"]()\n",
        "    if re.search(r'\\b(id)\\b', column_name, re.IGNORECASE):\n",
        "        return faker_mapping[\"uuid\"]()\n",
        "    if re.search(r'\\b(credit_card|card_number|credit card)\\b', column_name, re.IGNORECASE):\n",
        "        return faker_mapping[\"credit_card\"]()\n",
        "    return fake.word()  # Default fallback\n",
        "\n",
        "def anonymize_data(df):\n",
        "    \"\"\"Anonymize sensitive columns using Faker.\"\"\"\n",
        "    sensitive = detect_noun(df)\n",
        "    id_cols = detect_id_columns(df)\n",
        "    desc = descriptive_columns(df)\n",
        "    pii_cols = detect_pii_columns(df)\n",
        "    all_sensitive_cols = set(sensitive + id_cols + pii_cols)\n",
        "\n",
        "    column_mappings = {col: {} for col in all_sensitive_cols}\n",
        "\n",
        "    for col in all_sensitive_cols:\n",
        "        new_values = []\n",
        "        for val in df[col].astype(str):\n",
        "            if pd.notna(val):\n",
        "                if val in column_mappings[col]:\n",
        "                    anonymized_value = column_mappings[col][val]\n",
        "                else:\n",
        "                    anonymized_value = get_faker_value(col)\n",
        "                    column_mappings[col][val] = anonymized_value\n",
        "                mapping[anonymized_value] = val\n",
        "                new_values.append(anonymized_value)\n",
        "            else:\n",
        "                new_values.append(val)\n",
        "        df[col] = new_values\n",
        "\n",
        "    for col in desc:\n",
        "        df[col] = df[col].astype(str).apply(detect_pii)  # Mask PII in descriptive text\n",
        "\n",
        "    return df\n",
        "\n",
        "def save_file(df, file_type, output_file):\n",
        "    \"\"\"Save the DataFrame to a file.\"\"\"\n",
        "    if file_type == \"csv\":\n",
        "        df.to_csv(output_file, index=False)\n",
        "    else:\n",
        "        df.to_excel(output_file, index=False, sheet_name=\"Anonymized Data\")\n",
        "\n",
        "@time_it\n",
        "def anonymization(input_file):\n",
        "    \"\"\"Perform anonymization on a file.\"\"\"\n",
        "    df, file_type = read_file(input_file)\n",
        "    df = anonymize_data(df)\n",
        "    output_file = f\"anonymized.{file_type}\"\n",
        "    save_file(df, file_type, output_file)\n",
        "\n",
        "    # Save mapping for de-anonymization\n",
        "    with open(\"mappings.json\", \"w\") as f:\n",
        "        json.dump(mapping, f)\n",
        "\n",
        "    print(f\"✅ Anonymized file saved as {output_file}\")\n",
        "\n",
        "@time_it\n",
        "def de_anonymization(input_file, mapping_file):\n",
        "    \"\"\"Revert anonymized data to its original values using mappings.\"\"\"\n",
        "    df, file_type = read_file(input_file)\n",
        "\n",
        "    with open(mapping_file, \"r\") as f:\n",
        "        mapping = json.load(f)\n",
        "\n",
        "    df = df.applymap(lambda x: mapping.get(x, x))\n",
        "    output_file = f\"deanonymized.{file_type}\"\n",
        "    save_file(df, file_type, output_file)\n",
        "\n",
        "    print(f\"✅ De-anonymized file saved as {output_file}\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0].strip().replace(' ', '-')\n",
        "anonymization(file_name)\n",
        "# anonymization(\"testing-csv-ff.csv\")\n",
        "de_anonymization(\"anonymized.csv\", \"mappings.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "NE_3TMPO-Aw2",
        "outputId": "7f25cc51-817a-427b-85fd-9854e7f3fb87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e1328290-0e88-4372-a63e-058990c2e74c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e1328290-0e88-4372-a63e-058990c2e74c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving testing-csv-ff.csv to testing-csv-ff.csv\n",
            "\n",
            "\n",
            "Sensitive cols: ['Reporting Month', 'Cluster Name', 'Input Account Name', 'Account Name']\n",
            "\n",
            "\n",
            "PII Columns: ['Mobile Number', 'Credit Card Number']\n",
            "✅ Anonymized file saved as anonymized.csv\n",
            "\n",
            "\n",
            "Execution time anonymization: 2.413634 seconds\n",
            "✅ De-anonymized file saved as deanonymized.csv\n",
            "\n",
            "\n",
            "Execution time de_anonymization: 0.007664 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-322bf1fc318e>:180: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: mapping.get(x, x))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TESTING FAKER CODE**"
      ],
      "metadata": {
        "id": "DDOEZvZeo_jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flair\n",
        "!pip install faker\n",
        "!pip install presidio_analyzer\n",
        "!pip install presidio_anonymizer\n",
        "# !python -m spacy download en_core_web_lg\n",
        "!pip install --upgrade --force-reinstall \"numpy==1.26.4\"\n",
        "!pip install --upgrade --force-reinstall \"Cython\" \"spacy\""
      ],
      "metadata": {
        "id": "IEZcpbeVfnm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Faker code (1)\n",
        "import pandas as pd\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "from faker import Faker\n",
        "\n",
        "def time_it(func):\n",
        "    \"\"\"Decorator to measure execution time.\"\"\"\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f'\\n\\nExecution time {func.__name__}: {end-start:.6f} seconds')\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "@time_it\n",
        "def analyze_column(df):\n",
        "  entity_columns = {}  # Initialize as a dictionary\n",
        "  for col in df.columns:\n",
        "    unique_values = df[col].dropna().astype(str).unique()[:25]\n",
        "    entity_counts = {}\n",
        "\n",
        "    for value in unique_values:\n",
        "      results = analyzer.analyze(text=value, language=\"en\")\n",
        "      for result in results:\n",
        "        entity_counts[result.entity_type] = entity_counts.get(result.entity_type, 0) + 1\n",
        "    if entity_counts:\n",
        "      predominant_entity = max(entity_counts, key=entity_counts.get)\n",
        "      if predominant_entity not in entity_columns:\n",
        "        entity_columns[predominant_entity] = []  # Assign a list to the entity key\n",
        "      entity_columns[predominant_entity].append(col)\n",
        "  return entity_columns  # Return the dictionary\n",
        "\n",
        "def load_and_analyze(file_path):\n",
        "  if file_path.endswith(\".csv\"):\n",
        "    df = pd.read_csv(file_path, engine=\"python\")\n",
        "  elif file_path.endswith((\".xls\", \".xlsx\")):\n",
        "    df = pd.read_excel(file_path)\n",
        "  else:\n",
        "    raise ValueError(\"Unsupported file format. Provide a CSV or Excel file.\")\n",
        "\n",
        "  df_sample = df.drop_duplicates().head()\n",
        "  classified_columns = analyze_column(df_sample)\n",
        "  return classified_columns  # Return the dictionary"
      ],
      "metadata": {
        "id": "IJZv-UcNpVoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Faker code (2)\n",
        "file=\"smaller_companies.csv\"\n",
        "classified_columns=load_and_analyze(file)\n",
        "df=pd.read_csv(file)\n",
        "print(classified_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwyiugG8paCC",
        "outputId": "d59c44c6-36c7-4f79-c16f-9bbeed216ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Execution time analyze_column: 0.468736 seconds\n",
            "{'DATE_TIME': ['id', 'size range'], 'LOCATION': ['name', 'locality', 'country'], 'URL': ['domain', 'linkedin url'], 'US_DRIVER_LICENSE': ['current employee estimate', 'total employee estimate']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Faker code (3)\n",
        "import os\n",
        "import json\n",
        "from faker import Faker\n",
        "\n",
        "fake = Faker()\n",
        "Faker.seed(42)\n",
        "\n",
        "# data_mapping.json\n",
        "MAPPING_FILE = \"output/mappings.json\"\n",
        "forward_mapping = {}\n",
        "reverse_mapping = {}\n",
        "\n",
        "@time_it\n",
        "def load_mapping():\n",
        "    \"\"\"Loads existing mappings from a file if available.\"\"\"\n",
        "    global forward_mapping, reverse_mapping\n",
        "    if os.path.exists(MAPPING_FILE):\n",
        "        try:\n",
        "            with open(MAPPING_FILE, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "                # Convert keys back to tuples if needed\n",
        "                forward_mapping = {tuple(eval(k)): v for k, v in data.get(\"forward_mapping\", {}).items()}\n",
        "                reverse_mapping = {tuple(eval(k)): v for k, v in data.get(\"reverse_mapping\", {}).items()}\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error decoding JSON file: {e}\")\n",
        "            # If the file is invalid, reset the mappings\n",
        "            forward_mapping = {}\n",
        "            reverse_mapping = {}\n",
        "\n",
        "def save_mapping():\n",
        "    \"\"\"Saves the mapping to a JSON file.\"\"\"\n",
        "    os.makedirs(os.path.dirname(MAPPING_FILE), exist_ok=True)\n",
        "    # Convert tuple keys to strings before saving\n",
        "    modified_forward_mapping = {str(k): v for k, v in forward_mapping.items()}\n",
        "    modified_reverse_mapping = {str(k): v for k, v in reverse_mapping.items()}\n",
        "    with open(MAPPING_FILE, \"w\") as f:\n",
        "        json.dump({\"forward_mapping\": modified_forward_mapping, \"reverse_mapping\": modified_reverse_mapping}, f, indent=4)\n",
        "\n",
        "@time_it\n",
        "def generate_fake_value(original: str, entity_type: str) -> str:\n",
        "    \"\"\"Generates fake values while ensuring uniqueness.\"\"\"\n",
        "    if original in forward_mapping:\n",
        "        return forward_mapping[original]\n",
        "\n",
        "    faker_mapping = {\n",
        "        \"PERSON\": fake.name,\n",
        "        \"FIRST_NAME\": fake.first_name,\n",
        "        \"LAST_NAME\": fake.last_name,\n",
        "        \"EMAIL\": fake.email,\n",
        "        \"URL\": fake.url,\n",
        "        \"PHONE_NUMBER\": fake.phone_number,\n",
        "        \"CREDIT_CARD\": fake.credit_card_number,\n",
        "        \"IBAN\": fake.iban,\n",
        "        \"US_SSN\": fake.ssn,\n",
        "        # \"DATE\": fake.date_of_birth,\n",
        "        \"LOCATION\": fake.company,\n",
        "        \"STREET_ADDRESS\": fake.street_address,\n",
        "        \"CITY\": fake.city,\n",
        "        \"STATE\": fake.state,\n",
        "        \"COUNTRY\": fake.country,\n",
        "        \"ZIP_CODE\": fake.zipcode,\n",
        "        \"ORGANIZATION\": fake.company,\n",
        "        \"JOB_TITLE\": fake.job,\n",
        "        \"USERNAME\": fake.user_name,\n",
        "        \"PASSWORD\": fake.password,\n",
        "        \"IP_ADDRESS\": fake.ipv4,\n",
        "        \"MAC_ADDRESS\": fake.mac_address,\n",
        "        \"LICENSE_PLATE\": fake.license_plate,\n",
        "        \"UUID\": fake.uuid4,\n",
        "        \"BANK_ACCOUNT\": fake.bban,\n",
        "        \"TRANSACTION_ID\": fake.uuid4,\n",
        "        \"DEVICE_ID\": fake.uuid4,\n",
        "    }\n",
        "\n",
        "    fake_value = faker_mapping.get(entity_type, lambda: original)()\n",
        "    forward_mapping[original] = fake_value\n",
        "    reverse_mapping[fake_value] = original\n",
        "    return fake_value\n",
        "\n",
        "@time_it\n",
        "def mask_sensitive_data(df: pd.DataFrame, classified_columns: dict) -> pd.DataFrame:\n",
        "    \"\"\"Masks sensitive columns using Faker based on classified entity types.\"\"\"\n",
        "    for entity_type, columns in classified_columns.items():\n",
        "        for column in columns:\n",
        "            if column in df.columns:\n",
        "                df[column] = df[column].astype(str).apply(lambda x: generate_fake_value(x, entity_type) if x.strip() else x)\n",
        "    return df\n",
        "\n",
        "# testing-csv-ff.csv\n",
        "# smaller_companies.csv\n",
        "if __name__ == \"__main__\":\n",
        "    load_mapping()\n",
        "    input_file = \"smaller_companies.csv\"\n",
        "    output_file = \"output/anonymized.csv\"\n",
        "\n",
        "    df = pd.read_csv(input_file)\n",
        "    classified_columns = load_and_analyze(\"smaller_companies.csv\")\n",
        "\n",
        "    df = mask_sensitive_data(df, classified_columns)\n",
        "    df.to_csv(output_file, index=False)\n",
        "    save_mapping()"
      ],
      "metadata": {
        "id": "1XsgZQFzpday"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hashing file so as to reuse it (FAKER)\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import hashlib\n",
        "from faker import Faker\n",
        "\n",
        "fake = Faker()\n",
        "Faker.seed(42)\n",
        "\n",
        "MAPPING_FILE = \"mappings.json\"  # Store mappings directly\n",
        "N_LINES_FOR_HASH = 100  # Number of lines to consider for hashing\n",
        "\n",
        "# Load existing mappings if available\n",
        "if os.path.exists(MAPPING_FILE):\n",
        "    with open(MAPPING_FILE, \"r\") as f:\n",
        "        try:\n",
        "            mappings_data = json.load(f)\n",
        "        except json.JSONDecodeError:\n",
        "            mappings_data = {}\n",
        "else:\n",
        "    mappings_data = {}\n",
        "\n",
        "def compute_file_hash(file_path, num_lines=N_LINES_FOR_HASH):\n",
        "    \"\"\"Compute a quick hash based on the first `num_lines` of the file.\"\"\"\n",
        "    hasher = hashlib.sha256()\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for _ in range(num_lines):\n",
        "            line = f.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            hasher.update(line.encode(\"utf-8\"))\n",
        "    return hasher.hexdigest()\n",
        "\n",
        "def save_mapping(filename, file_hash, forward_mapping, reverse_mapping):\n",
        "    \"\"\"Save mappings along with filename and file hash.\"\"\"\n",
        "    mappings_data[filename] = {\n",
        "        \"file_hash\": file_hash,\n",
        "        \"forward_mapping\": forward_mapping,\n",
        "        \"reverse_mapping\": reverse_mapping\n",
        "    }\n",
        "    with open(MAPPING_FILE, \"w\") as f:\n",
        "        json.dump(mappings_data, f, indent=4)\n",
        "\n",
        "def load_mapping(filename, file_hash):\n",
        "    \"\"\"Load mapping if filename and file hash match.\"\"\"\n",
        "    if filename in mappings_data and mappings_data[filename][\"file_hash\"] == file_hash:\n",
        "        return mappings_data[filename][\"forward_mapping\"], mappings_data[filename][\"reverse_mapping\"]\n",
        "    return {}, {}\n",
        "\n",
        "def generate_fake_value(original: str, entity_type: str, forward_mapping, reverse_mapping):\n",
        "    \"\"\"Generates fake values while ensuring uniqueness.\"\"\"\n",
        "    if original in forward_mapping:\n",
        "        return forward_mapping[original]\n",
        "\n",
        "    faker_mapping = {\n",
        "        \"PERSON\": fake.name,\n",
        "        \"FIRST_NAME\": fake.first_name,\n",
        "        \"LAST_NAME\": fake.last_name,\n",
        "        \"EMAIL\": fake.email,\n",
        "        \"URL\": fake.url,\n",
        "        \"PHONE_NUMBER\": fake.phone_number,\n",
        "        \"CREDIT_CARD\": fake.credit_card_number,\n",
        "        \"IBAN\": fake.iban,\n",
        "        \"US_SSN\": fake.ssn,\n",
        "        \"LOCATION\": fake.company,\n",
        "        \"STREET_ADDRESS\": fake.street_address,\n",
        "        \"CITY\": fake.city,\n",
        "        \"STATE\": fake.state,\n",
        "        \"COUNTRY\": fake.country,\n",
        "        \"ZIP_CODE\": fake.zipcode,\n",
        "        \"ORGANIZATION\": fake.company,\n",
        "        \"JOB_TITLE\": fake.job,\n",
        "        \"USERNAME\": fake.user_name,\n",
        "        \"PASSWORD\": fake.password,\n",
        "        \"IP_ADDRESS\": fake.ipv4,\n",
        "        \"MAC_ADDRESS\": fake.mac_address,\n",
        "        \"LICENSE_PLATE\": fake.license_plate,\n",
        "        \"UUID\": fake.uuid4,\n",
        "        \"BANK_ACCOUNT\": fake.bban,\n",
        "        \"TRANSACTION_ID\": fake.uuid4,\n",
        "        \"DEVICE_ID\": fake.uuid4,\n",
        "    }\n",
        "\n",
        "    fake_value = faker_mapping.get(entity_type, lambda: original)()\n",
        "    forward_mapping[original] = fake_value\n",
        "    reverse_mapping[fake_value] = original\n",
        "    return fake_value\n",
        "\n",
        "def mask_sensitive_data(df: pd.DataFrame, classified_columns: dict, forward_mapping, reverse_mapping):\n",
        "    \"\"\"Masks sensitive columns using Faker based on classified entity types.\"\"\"\n",
        "    for entity_type, columns in classified_columns.items():\n",
        "        for column in columns:\n",
        "            if column in df.columns:\n",
        "                df[column] = df[column].astype(str).apply(lambda x: generate_fake_value(x, entity_type, forward_mapping, reverse_mapping) if x.strip() else x)\n",
        "    return df\n",
        "\n",
        "# Run masking process\n",
        "if __name__ == \"__main__\":\n",
        "    input_file = \"smaller_companies.csv\"\n",
        "    output_file = \"anonymized.csv\"\n",
        "\n",
        "    # Compute file hash\n",
        "    file_hash = compute_file_hash(input_file)\n",
        "\n",
        "    # Load or initialize mappings\n",
        "    forward_mapping, reverse_mapping = load_mapping(input_file, file_hash)\n",
        "\n",
        "    df = pd.read_csv(input_file)\n",
        "    classified_columns = load_and_analyze(input_file)  # Ensure this function is defined\n",
        "\n",
        "    df = mask_sensitive_data(df, classified_columns, forward_mapping, reverse_mapping)\n",
        "    df.to_csv(output_file, index=False)\n",
        "\n",
        "    # Save updated mapping\n",
        "    save_mapping(input_file, file_hash, forward_mapping, reverse_mapping)\n"
      ],
      "metadata": {
        "id": "gmoF0kU225PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tried out finding total unique names\n",
        "from faker import Faker\n",
        "from faker.exceptions import UniquenessException\n",
        "\n",
        "fake = Faker()\n",
        "fake.unique.clear()\n",
        "unique_names = set()\n",
        "\n",
        "try:\n",
        "  while True:\n",
        "    unique_names.add(fake.unique.name())\n",
        "except UniquenessException:\n",
        "  print(f'Unique names length:', len(unique_names))"
      ],
      "metadata": {
        "id": "6Z5jkj4hCHS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Masking ID in column headers\n",
        "\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "\n",
        "# Presidio Analyzer\n",
        "analyzer = AnalyzerEngine()\n",
        "\n",
        "# Faker initalization\n",
        "fake = Faker()\n",
        "Faker.seed(42)\n",
        "\n",
        "# mappings.json\n",
        "MAPPING_FILE = \"mappings.json\"\n",
        "forward_mapping = {}\n",
        "reverse_mapping = {}\n",
        "\n",
        "def time_it(func):\n",
        "    \"\"\"Decorator to measure execution time.\"\"\"\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f'\\n\\nExecution time {func.__name__}: {end-start:.6f} seconds')\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "@time_it\n",
        "def analyze_column(df):\n",
        "  entity_columns = {}  # Initialize as a dictionary\n",
        "  for col in df.columns:\n",
        "    unique_values = df[col].dropna().astype(str).unique()[:15]\n",
        "    entity_counts = {}\n",
        "\n",
        "    for value in unique_values:\n",
        "      results = analyzer.analyze(text=value, language=\"en\")\n",
        "      for result in results:\n",
        "        entity_counts[result.entity_type] = entity_counts.get(result.entity_type, 0) + 1\n",
        "    if entity_counts:\n",
        "      predominant_entity = max(entity_counts, key=entity_counts.get)\n",
        "      if predominant_entity not in entity_columns:\n",
        "        entity_columns[predominant_entity] = []  # Assign a list to the entity key\n",
        "      entity_columns[predominant_entity].append(col)\n",
        "  return entity_columns  # Return the dictionary\n",
        "\n",
        "def load_and_analyze(file_path):\n",
        "  if file_path.endswith(\".csv\"):\n",
        "    df = pd.read_csv(file_path, engine=\"python\")\n",
        "  elif file_path.endswith((\".xls\", \".xlsx\")):\n",
        "    df = pd.read_excel(file_path)\n",
        "  else:\n",
        "    raise ValueError(\"Unsupported file format. Provide a CSV or Excel file.\")\n",
        "\n",
        "  df_sample = df.drop_duplicates().head()\n",
        "  classified_columns = analyze_column(df_sample)\n",
        "  return classified_columns\n",
        "\n",
        "def load_mapping():\n",
        "    \"\"\"Loads existing mappings from a file if available.\"\"\"\n",
        "    global forward_mapping, reverse_mapping\n",
        "    if os.path.exists(MAPPING_FILE):\n",
        "        try:\n",
        "            with open(MAPPING_FILE, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "                forward_mapping = data.get(\"forward_mapping\", {})\n",
        "                reverse_mapping = data.get(\"reverse_mapping\", {})\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error decoding JSON file: {e}\")\n",
        "            forward_mapping = {}\n",
        "            reverse_mapping = {}\n",
        "\n",
        "def save_mapping():\n",
        "    \"\"\"Saves the mapping to a JSON file.\"\"\"\n",
        "    with open(MAPPING_FILE, \"w\") as f:\n",
        "        json.dump({\"forward_mapping\": forward_mapping, \"reverse_mapping\": reverse_mapping}, f, indent=4)\n",
        "\n",
        "def generate_fake_value(original: str, entity_type: str) -> str:\n",
        "    \"\"\"Generates fake values while ensuring uniqueness.\"\"\"\n",
        "    if original in forward_mapping:\n",
        "        return forward_mapping[original]\n",
        "\n",
        "    faker_mapping = {\n",
        "        \"PERSON\": fake.name,\n",
        "        \"FIRST_NAME\": fake.first_name,\n",
        "        \"LAST_NAME\": fake.last_name,\n",
        "        \"EMAIL\": fake.email,\n",
        "        \"URL\": fake.url,\n",
        "        \"PHONE_NUMBER\": fake.phone_number,\n",
        "        \"CREDIT_CARD\": fake.credit_card_number,\n",
        "        \"IBAN\": fake.iban,\n",
        "        \"US_SSN\": fake.ssn,\n",
        "        \"LOCATION\": fake.company,\n",
        "        \"STREET_ADDRESS\": fake.street_address,\n",
        "        \"CITY\": fake.city,\n",
        "        \"STATE\": fake.state,\n",
        "        \"COUNTRY\": fake.country,\n",
        "        \"ZIP_CODE\": fake.zipcode,\n",
        "        \"ORGANIZATION\": fake.company,\n",
        "        \"JOB_TITLE\": fake.job,\n",
        "        \"USERNAME\": fake.user_name,\n",
        "        \"PASSWORD\": fake.password,\n",
        "        \"IP_ADDRESS\": fake.ipv4,\n",
        "        \"MAC_ADDRESS\": fake.mac_address,\n",
        "        \"LICENSE_PLATE\": fake.license_plate,\n",
        "        \"UUID\": fake.uuid4,\n",
        "        \"BANK_ACCOUNT\": fake.bban,\n",
        "        \"TRANSACTION_ID\": fake.uuid4,\n",
        "        \"DEVICE_ID\": fake.uuid4,\n",
        "        \"ID\": fake.uuid4,  # Generating fake values for ID columns\n",
        "    }\n",
        "\n",
        "    fake_value = faker_mapping.get(entity_type, lambda: original)()\n",
        "    forward_mapping[original] = fake_value\n",
        "    reverse_mapping[fake_value] = original\n",
        "    return fake_value\n",
        "\n",
        "@time_it\n",
        "def mask_sensitive_data(df: pd.DataFrame, classified_columns: dict) -> pd.DataFrame:\n",
        "    \"\"\"Masks sensitive columns using Faker based on classified entity types.\"\"\"\n",
        "    for entity_type, columns in classified_columns.items():\n",
        "        for column in columns:\n",
        "            if column in df.columns:\n",
        "                df[column] = df[column].astype(str).apply(lambda x: generate_fake_value(x, entity_type) if x.strip() else x)\n",
        "\n",
        "    # Find columns with 'id' in the name using regex and mask them\n",
        "    id_columns = [col for col in df.columns if re.search(r'\\bid\\b', col, re.IGNORECASE)]\n",
        "    print('ID cols:', id_columns)\n",
        "    for col in id_columns:\n",
        "        df[col] = df[col].astype(str).apply(lambda x: generate_fake_value(x, \"ID\") if x.strip() else x)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# smaller_companies.csv\n",
        "# testing-csv-ff.csv\n",
        "if __name__ == \"__main__\":\n",
        "    load_mapping()\n",
        "    input_file = \"smaller_companies.csv\"\n",
        "    output_file = \"anonymized.csv\"\n",
        "\n",
        "    df = pd.read_csv(input_file)\n",
        "    classified_columns = load_and_analyze(input_file)\n",
        "\n",
        "    df = mask_sensitive_data(df, classified_columns)\n",
        "    df.to_csv(output_file, index=False)\n",
        "    save_mapping()\n"
      ],
      "metadata": {
        "id": "rLibUWPLPWbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing columnwise replacing using Faker\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "\n",
        "# Initialize Faker & Presidio Analyzer\n",
        "fake = Faker()\n",
        "Faker.seed(42)\n",
        "analyzer = AnalyzerEngine()\n",
        "\n",
        "# Mapping file for storing forward/reverse mappings\n",
        "MAPPING_FILE = \"mappings.json\"\n",
        "forward_mapping = {}\n",
        "reverse_mapping = {}\n",
        "\n",
        "def time_it(func):\n",
        "    \"\"\"Decorator to measure execution time.\"\"\"\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f'\\nExecution time {func.__name__}: {end-start:.6f} seconds')\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "def load_mapping():\n",
        "    \"\"\"Loads existing mappings from a file if available.\"\"\"\n",
        "    global forward_mapping, reverse_mapping\n",
        "    if os.path.exists(MAPPING_FILE):\n",
        "        try:\n",
        "            with open(MAPPING_FILE, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "                forward_mapping = data.get(\"forward_mapping\", {})\n",
        "                reverse_mapping = data.get(\"reverse_mapping\", {})\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error decoding JSON file: {e}\")\n",
        "            forward_mapping = {}\n",
        "            reverse_mapping = {}\n",
        "\n",
        "def save_mapping():\n",
        "    \"\"\"Saves the mapping to a JSON file.\"\"\"\n",
        "    with open(MAPPING_FILE, \"w\") as f:\n",
        "        json.dump({\"forward_mapping\": forward_mapping, \"reverse_mapping\": reverse_mapping}, f, indent=4)\n",
        "\n",
        "@time_it\n",
        "def analyze_column(df):\n",
        "    \"\"\"Detects sensitive columns using Presidio.\"\"\"\n",
        "    entity_columns = {}\n",
        "    for col in df.columns:\n",
        "        unique_values = df[col].dropna().astype(str).unique()[:10]\n",
        "        entity_counts = {}\n",
        "\n",
        "        for value in unique_values:\n",
        "            results = analyzer.analyze(text=value, language=\"en\")\n",
        "            for result in results:\n",
        "                entity_counts[result.entity_type] = entity_counts.get(result.entity_type, 0) + 1\n",
        "\n",
        "        if entity_counts:\n",
        "            predominant_entity = max(entity_counts, key=entity_counts.get)\n",
        "            if predominant_entity not in entity_columns:\n",
        "                entity_columns[predominant_entity] = []\n",
        "            entity_columns[predominant_entity].append(col)\n",
        "\n",
        "    return entity_columns\n",
        "\n",
        "def load_and_analyze(file_path):\n",
        "    \"\"\"Loads CSV/Excel and analyzes sensitive columns.\"\"\"\n",
        "    df = pd.read_csv(file_path) if file_path.endswith(\".csv\") else pd.read_excel(file_path)\n",
        "    return analyze_column(df)\n",
        "\n",
        "def generate_fake_values(df, entity_type, column):\n",
        "    \"\"\"Generates fake values for an entire column while preserving uniqueness.\"\"\"\n",
        "    faker_mapping = {\n",
        "        \"PERSON\": fake.name,\n",
        "        \"FIRST_NAME\": fake.first_name,\n",
        "        \"LAST_NAME\": fake.last_name,\n",
        "        \"EMAIL\": fake.email,\n",
        "        \"URL\": fake.url,\n",
        "        \"PHONE_NUMBER\": fake.phone_number,\n",
        "        \"CREDIT_CARD\": lambda: fake.credit_card_number(card_type=None),\n",
        "        \"IBAN\": fake.iban,\n",
        "        \"US_SSN\": fake.ssn,\n",
        "        \"LOCATION\": fake.company,\n",
        "        \"STREET_ADDRESS\": fake.street_address,\n",
        "        \"CITY\": fake.city,\n",
        "        \"STATE\": fake.state,\n",
        "        \"COUNTRY\": fake.country,\n",
        "        \"ZIP_CODE\": fake.zipcode,\n",
        "        \"ORGANIZATION\": fake.company,\n",
        "        \"JOB_TITLE\": fake.job,\n",
        "        \"USERNAME\": fake.user_name,\n",
        "        \"PASSWORD\": fake.password,\n",
        "        \"IP_ADDRESS\": fake.ipv4,\n",
        "        \"MAC_ADDRESS\": fake.mac_address,\n",
        "        \"LICENSE_PLATE\": fake.license_plate,\n",
        "        \"UUID\": fake.uuid4,\n",
        "        \"BANK_ACCOUNT\": fake.bban,\n",
        "        \"TRANSACTION_ID\": fake.uuid4,\n",
        "        \"DEVICE_ID\": fake.uuid4,\n",
        "        \"ID\": fake.uuid4,\n",
        "        \"US_BANK_NUMBER\": lambda: fake.credit_card_number(card_type=\"visa\")\n",
        "    }\n",
        "\n",
        "    if entity_type not in faker_mapping:\n",
        "        return df  # Skip if no Faker function exists\n",
        "\n",
        "    faker_func = faker_mapping[entity_type]\n",
        "\n",
        "    # Convert numeric columns to strings before applying Faker mapping\n",
        "    if df[column].dtype in [int, float]:\n",
        "        df[column] = df[column].astype(str)\n",
        "\n",
        "    original_values = df[column].dropna().astype(str).unique()\n",
        "    fake_values = [forward_mapping.get(value, faker_func()) for value in original_values]\n",
        "\n",
        "    # Store mappings\n",
        "    for original, fake_val in zip(original_values, fake_values):\n",
        "        forward_mapping[original] = str(fake_val)  # Ensure JSON serializable\n",
        "        reverse_mapping[str(fake_val)] = original\n",
        "\n",
        "    df[column] = df[column].map(forward_mapping).fillna(df[column])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "def mask_id_columns(df):\n",
        "    \"\"\"Finds columns with 'id' in the name and replaces them with fake UUIDs.\"\"\"\n",
        "    id_columns = [col for col in df.columns if re.search(r'\\bid\\b', col, re.IGNORECASE)]\n",
        "\n",
        "    for column in id_columns:\n",
        "        unique_ids = df[column].astype(str).dropna().unique()\n",
        "        fake_ids = [forward_mapping.get(value, str(fake.uuid4())) for value in unique_ids]\n",
        "\n",
        "        # Store mappings for ID replacements\n",
        "        for original, fake_id in zip(unique_ids, fake_ids):\n",
        "            forward_mapping[original] = fake_id\n",
        "            reverse_mapping[fake_id] = original\n",
        "\n",
        "        # 🔹 Forcefully update df[column] with mapped values\n",
        "        df[column] = df[column].astype(str).apply(lambda x: forward_mapping.get(x, x))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "@time_it\n",
        "def mask_sensitive_data(df, classified_columns):\n",
        "    \"\"\"Masks all detected sensitive columns using Faker.\"\"\"\n",
        "    for entity_type, columns in classified_columns.items():\n",
        "        for column in columns:\n",
        "            if column in df.columns:\n",
        "                df = generate_fake_values(df, entity_type, column)\n",
        "\n",
        "    # Mask all ID columns separately\n",
        "    df = mask_id_columns(df)\n",
        "\n",
        "    return df\n",
        "\n",
        "# testing-csv-ff.csv\n",
        "# smaller_companies.csv\n",
        "if __name__ == \"__main__\":\n",
        "    load_mapping()\n",
        "    input_file = \"smaller_100k_companies.csv\"\n",
        "    output_file = \"anonymized.csv\"\n",
        "\n",
        "    df = pd.read_csv(input_file)\n",
        "    classified_columns = load_and_analyze(input_file)\n",
        "\n",
        "    df = mask_sensitive_data(df, classified_columns)\n",
        "    df.to_csv(output_file, index=False)\n",
        "\n",
        "    save_mapping()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAEvxZ-SeEYK",
        "outputId": "6900705a-5f15-4b8a-bb19-30a64110cc7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Execution time analyze_column: 6.428666 seconds\n",
            "\n",
            "Execution time mask_sensitive_data: 67.272321 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Thejus code fast!\n",
        "output_folder = \"output_files\"\n",
        "class MaskingModule:\n",
        "    def __init__(self, mapping_file: str = f\"{output_folder}/data_mapping.json\", seed: int = 42):\n",
        "        self.fake = Faker()\n",
        "        Faker.seed(seed)\n",
        "        self.mapping_file = mapping_file\n",
        "        self.forward_mapping = {}\n",
        "        self.reverse_mapping = {}\n",
        "        self._load_mapping_if_exists()\n",
        "        print(\"✅ MaskingModule initialized.\")\n",
        "\n",
        "    def _generate_fake_column(self, column: pd.Series, column_name: str) -> pd.Series:\n",
        "        \"\"\"Generate fake data for a whole column at once and update mappings.\"\"\"\n",
        "        column_lower = column_name.lower()\n",
        "        original_values = column.dropna().unique()\n",
        "        fake_values = []\n",
        "\n",
        "        if (\n",
        "            \"employee\" in column_lower\n",
        "            or \"company\" in column_lower\n",
        "            or \"account\" in column_lower\n",
        "        ):\n",
        "            fake_values = [\n",
        "                f\"{self.fake.first_name()}{self.fake.random_number(digits=12)}{self.fake.first_name()}\"\n",
        "                for _ in original_values\n",
        "            ]\n",
        "        elif \"project\" in column_lower:\n",
        "            fake_values = [\n",
        "                f\"PRJ-{self.fake.random_number(digits=12)}\" for _ in original_values\n",
        "            ]\n",
        "        elif \"entity\" in column_lower:\n",
        "            fake_values = [\n",
        "                f\"ENT-{self.fake.random_number(digits=12)}\" for _ in original_values\n",
        "            ]\n",
        "        elif \"program\" in column_lower:\n",
        "            fake_values = [\n",
        "                f\"PROG-{self.fake.random_number(digits=12)}\" for _ in original_values\n",
        "            ]\n",
        "        else:\n",
        "            fake_values = [\n",
        "                f\"{self.fake.first_name()}-{self.fake.random_number(digits=20)}-{self.fake.first_name()}\"\n",
        "                for _ in original_values\n",
        "            ]\n",
        "\n",
        "        mapping = dict(zip(original_values, fake_values))\n",
        "        self.forward_mapping.update(mapping)\n",
        "        self.reverse_mapping.update({v: k for k, v in mapping.items()})\n",
        "\n",
        "        return column.map(mapping).fillna(column)\n",
        "\n",
        "    def _save_mapping(self):\n",
        "        \"\"\"Save mappings to JSON with string keys and serializable values.\"\"\"\n",
        "\n",
        "        def convert_to_serializable(obj):\n",
        "            if isinstance(\n",
        "                obj, (np.integer, np.int64, np.int32)\n",
        "            ):  # Convert numpy int to Python int\n",
        "                return int(obj)\n",
        "            elif isinstance(\n",
        "                obj, (np.floating, np.float64, np.float32)\n",
        "            ):  # Convert numpy float to Python float\n",
        "                return float(obj)\n",
        "            elif isinstance(obj, np.ndarray):  # Convert numpy array to list\n",
        "                return obj.tolist()\n",
        "            else:\n",
        "                return obj  # Return as-is if already serializable\n",
        "\n",
        "        mapping_data = {\n",
        "            \"forward_mapping\": {\n",
        "                str(k): convert_to_serializable(v) for k, v in self.forward_mapping.items()\n",
        "            },\n",
        "            \"reverse_mapping\": {\n",
        "                str(k): convert_to_serializable(v) for k, v in self.reverse_mapping.items()\n",
        "            },\n",
        "            \"metadata\": {\n",
        "                \"updated_at\": datetime.now().isoformat(),\n",
        "                \"record_count\": len(self.forward_mapping),\n",
        "            },\n",
        "        }\n",
        "\n",
        "        with open(self.mapping_file, \"w\") as f:\n",
        "            json.dump(mapping_data, f, indent=4)\n",
        "\n",
        "        print(\"💾 Mapping saved successfully.\")\n",
        "\n",
        "    def _load_mapping_if_exists(self):\n",
        "        \"\"\"Load existing mappings from JSON.\"\"\"\n",
        "        if os.path.exists(self.mapping_file):\n",
        "            with open(self.mapping_file, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "                self.forward_mapping = data[\"forward_mapping\"]\n",
        "                self.reverse_mapping = data[\"reverse_mapping\"]\n",
        "            print(\"📂 Existing mapping loaded.\")\n",
        "\n",
        "    def process_file(\n",
        "        self,\n",
        "        input_file: str,\n",
        "        output_file: str,\n",
        "        mode: str = \"anonymize\",\n",
        "        include_columns: List[str] = None,\n",
        "    ):\n",
        "        \"\"\"Process CSV and Excel files for anonymization and de-anonymization.\"\"\"\n",
        "        if mode not in [\"anonymize\", \"deanonymize\"]:\n",
        "            raise ValueError(\"Mode must be either 'anonymize' or 'deanonymize'\")\n",
        "\n",
        "        file_ext = os.path.splitext(input_file)[-1].lower()\n",
        "        df = (\n",
        "            pd.read_csv(input_file) if file_ext == \".csv\" else pd.read_excel(input_file)\n",
        "        )\n",
        "        print(\"📊 Data loaded successfully.\")\n",
        "\n",
        "        include_set = {\"id\", \"name\", \"domain\", \"year\", \"founded\", \"industry\", \"size\"}\n",
        "        if include_columns:\n",
        "            include_set.update(include_columns)\n",
        "\n",
        "        for column in df.columns:\n",
        "            if column in include_set:\n",
        "                if mode == \"anonymize\":\n",
        "                    df[column] = self._generate_fake_column(df[column], column)\n",
        "                else:\n",
        "                    df[column] = (\n",
        "                        df[column]\n",
        "                        .astype(str)\n",
        "                        .map(self.reverse_mapping)\n",
        "                        .where(df[column].notna(), df[column])\n",
        "                    )\n",
        "\n",
        "        df.to_csv(output_file, index=False) if file_ext == \".csv\" else df.to_excel(\n",
        "            output_file, index=False\n",
        "        )\n",
        "        if mode == \"anonymize\":\n",
        "            self._save_mapping()\n",
        "        print(f\"✅ Data {mode}d and saved to {output_file}\")\n",
        "\n",
        "    def check_if_two_files_are_same(self, input_file: str, restored_file: str):\n",
        "        \"\"\"Check if the original and restored files match.\"\"\"\n",
        "        file_ext = os.path.splitext(input_file)[-1].lower()\n",
        "        original_df = (\n",
        "            pd.read_csv(input_file) if file_ext == \".csv\" else pd.read_excel(input_file)\n",
        "        )\n",
        "        restored_df = (\n",
        "            pd.read_csv(restored_file)\n",
        "            if file_ext == \".csv\"\n",
        "            else pd.read_excel(restored_file)\n",
        "        )\n",
        "\n",
        "        test = original_df.equals(restored_df)\n",
        "        print(f\"📊 Are files identical? {test}\")\n",
        "        if not test:\n",
        "            print(\"⚠️ Files are not identical!\")\n",
        "            print(\"🔍 Sample from original:\")\n",
        "            print(original_df.head(2))\n",
        "            print(\"🔍 Sample from restored:\")\n",
        "            print(restored_df.head(2))\n",
        "        else:\n",
        "            print(\"✅ Files match perfectly!\")\n",
        "\n",
        "    def print_mapping_sample(self, n: int = 5):\n",
        "        \"\"\"Print sample mappings.\"\"\"\n",
        "        print(\"📌 Forward Mapping (Original → Anonymized):\")\n",
        "        for k, v in list(self.forward_mapping.items())[:n]:\n",
        "            print(f\"{k} → {v}\")\n",
        "        print(\"📌 Reverse Mapping (Anonymized → Original):\")\n",
        "        for k, v in list(self.reverse_mapping.items())[:n]:\n",
        "            print(f\"{k} → {v}\")\n",
        "\n",
        "    def mask_text(self, text, replace_dict):\n",
        "        \"\"\"Mask text using forward mapping.\"\"\"\n",
        "        for key, value in replace_dict.items():\n",
        "            text = text.replace(key, value)\n",
        "        return text\n",
        "\n"
      ],
      "metadata": {
        "id": "buRYOpVj6UDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizing Thejus's logic\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from faker import Faker\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "\n",
        "# Initialize Faker & Presidio Analyzer\n",
        "fake = Faker()\n",
        "Faker.seed(42)\n",
        "analyzer = AnalyzerEngine()\n",
        "\n",
        "# Mapping file for storing forward/reverse mappings\n",
        "MAPPING_FILE = \"mappings.json\"\n",
        "forward_mapping = {}\n",
        "reverse_mapping = {}\n",
        "\n",
        "NUMERIC_PATTERN = re.compile(r\"^[<>]?[\\d,.%]+$\")\n",
        "SENSITIVE_HEADERS = {\"phone\", \"mobile\", \"credit\", \"card\", \"id\"}\n",
        "EXCLUDED_ENTITIES = {\"DATE_TIME\"}  # Exclude unwanted entities\n",
        "\n",
        "\n",
        "def time_it(func):\n",
        "    \"\"\"Decorator to measure execution time of functions.\"\"\"\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f'\\n⏳ Execution time {func.__name__}: {end-start:.6f} seconds')\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "def load_mapping():\n",
        "    \"\"\"Loads existing mapping from file, ensuring proper data handling.\"\"\"\n",
        "    global forward_mapping, reverse_mapping\n",
        "    if os.path.exists(MAPPING_FILE):\n",
        "        try:\n",
        "            with open(MAPPING_FILE, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "                forward_mapping = data.get(\"forward_mapping\", {})\n",
        "                reverse_mapping = data.get(\"reverse_mapping\", {})\n",
        "            print(\"📂 Existing mapping loaded.\")\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"⚠️ Error decoding JSON file: {e}\")\n",
        "\n",
        "\n",
        "def save_mapping():\n",
        "    \"\"\"Saves the mapping to a JSON file with string keys.\"\"\"\n",
        "    mapping_data = {\n",
        "        \"forward_mapping\": {str(k): str(v) for k, v in forward_mapping.items()},\n",
        "        \"reverse_mapping\": {str(k): str(v) for k, v in reverse_mapping.items()},\n",
        "        \"metadata\": {\n",
        "            \"updated_at\": datetime.now().isoformat(),\n",
        "            \"record_count\": len(forward_mapping),\n",
        "        },\n",
        "    }\n",
        "    with open(MAPPING_FILE, \"w\") as f:\n",
        "        json.dump(mapping_data, f, indent=4)\n",
        "    print(\"💾 Mapping saved successfully.\")\n",
        "\n",
        "\n",
        "\n",
        "@time_it\n",
        "def analyze_column(df):\n",
        "    \"\"\"Uses Presidio to classify columns based on detected entity types.\"\"\"\n",
        "    entity_columns = {}\n",
        "    for col in df.columns:\n",
        "        col_lower = col.lower()\n",
        "        if any(keyword in col_lower for keyword in SENSITIVE_HEADERS):\n",
        "            entity_columns.setdefault(\"SENSITIVE\", []).append(col)\n",
        "            continue\n",
        "\n",
        "        unique_values = df[col].dropna().astype(str).unique()[:10]\n",
        "        entity_counts = {}\n",
        "\n",
        "        for value in unique_values:\n",
        "            if NUMERIC_PATTERN.match(value):\n",
        "                continue  # Skip purely numeric values unless it's a phone/credit card\n",
        "\n",
        "            results = analyzer.analyze(text=value, language=\"en\")\n",
        "            for result in results:\n",
        "                if result.entity_type in EXCLUDED_ENTITIES:\n",
        "                    continue  # Skip unwanted entities\n",
        "                entity_counts[result.entity_type] = entity_counts.get(result.entity_type, 0) + 1\n",
        "\n",
        "        if entity_counts:\n",
        "            predominant_entity = max(entity_counts, key=entity_counts.get)\n",
        "            if predominant_entity not in entity_columns:\n",
        "                entity_columns[predominant_entity] = []\n",
        "            entity_columns[predominant_entity].append(col)\n",
        "\n",
        "    return entity_columns\n",
        "\n",
        "\n",
        "def generate_fake_values(column):\n",
        "    \"\"\"Generates consistent fake values for a column while preserving uniqueness.\"\"\"\n",
        "    col_name = column.name.lower()\n",
        "    original_values = column.dropna().unique()\n",
        "\n",
        "    if col_name in forward_mapping:\n",
        "        mapping = forward_mapping[col_name]\n",
        "    else:\n",
        "        mapping = {}\n",
        "\n",
        "    fake_values = []\n",
        "    if re.search(r\"\\b(phone|mobile)\\b\", col_name, re.IGNORECASE):\n",
        "        fake_values = [fake.phone_number() for _ in original_values]\n",
        "    elif re.search(r\"\\b(credit|card)\\b\", col_name, re.IGNORECASE):\n",
        "        fake_values = [fake.credit_card_number() for _ in original_values]\n",
        "    elif re.search(r\"\\b(id|identifier)\\b\", col_name, re.IGNORECASE):\n",
        "        fake_values = [fake.bothify(text=\"ID##########????\") for _ in original_values]\n",
        "    elif re.search(r\"\\b(name|full[_\\s]?name|first[_\\s]?name|last[_\\s]?name)\\b\", col_name, re.IGNORECASE):\n",
        "        fake_values = [f'{fake.name()--{fake.bothify(text=\"??????????\")}}' for _ in original_values]\n",
        "    else:\n",
        "        fake_values = [fake.bothify(text=\"????########\") for _ in original_values]\n",
        "\n",
        "\n",
        "    mapping.update(dict(zip(original_values, fake_values)))\n",
        "    forward_mapping[col_name] = mapping\n",
        "    reverse_mapping[col_name] = {v: k for k, v in mapping.items()}\n",
        "\n",
        "    return column.map(mapping).fillna(column)\n",
        "\n",
        "\n",
        "@time_it\n",
        "def mask_columnwise(df):\n",
        "    \"\"\"Replaces sensitive data only in columns detected as sensitive by Presidio.\"\"\"\n",
        "    sensitive_columns = analyze_column(df)\n",
        "\n",
        "    for entity, cols in sensitive_columns.items():\n",
        "        for column in cols:\n",
        "            print(f\"🔒 Masking sensitive column: {column} (Detected as {entity})\")\n",
        "            df[column] = generate_fake_values(df[column])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def restore_data(df):\n",
        "    \"\"\"Restores original values using stored mappings.\"\"\"\n",
        "    for column in df.columns:\n",
        "        col_name = column.lower()\n",
        "        if col_name in reverse_mapping:\n",
        "            df[column] = df[column].astype(str).map(reverse_mapping[col_name]).fillna(df[column])\n",
        "    return df\n",
        "\n",
        "\n",
        "def check_if_files_match(original_file, restored_file):\n",
        "    \"\"\"Checks if the original and restored files match.\"\"\"\n",
        "    file_ext = os.path.splitext(original_file)[-1].lower()\n",
        "    original_df = pd.read_csv(original_file) if file_ext == \".csv\" else pd.read_excel(original_file)\n",
        "    restored_df = pd.read_csv(restored_file) if file_ext == \".csv\" else pd.read_excel(restored_file)\n",
        "    test = original_df.equals(restored_df)\n",
        "    print(f\"📊 Are files identical? {test}\")\n",
        "    if not test:\n",
        "        print(\"⚠️ Files are not identical!\")\n",
        "    else:\n",
        "        print(\"✅ Files match perfectly!\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    load_mapping()\n",
        "    uploaded = files.upload()\n",
        "    input_file = list(uploaded.keys())[0].strip().replace(' ', '-')\n",
        "    # input_file = \"smaller_companies.csv\" if not input_file else input_file\n",
        "\n",
        "    anonymized_file = \"anonymized.csv\"\n",
        "    restored_file = \"restored.csv\"\n",
        "\n",
        "    df = pd.read_csv(input_file)\n",
        "    df = mask_columnwise(df)  # Only masks detected sensitive columns\n",
        "    df.to_csv(anonymized_file, index=False)\n",
        "    save_mapping()\n",
        "\n",
        "    df = restore_data(pd.read_csv(anonymized_file))\n",
        "    df.to_csv(restored_file, index=False)\n",
        "\n",
        "    check_if_files_match(input_file, restored_file)\n"
      ],
      "metadata": {
        "id": "0G10tyBm7ISe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# V2\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "# Initialize Faker & Presidio Analyzer\n",
        "fake = Faker()\n",
        "Faker.seed(42)\n",
        "analyzer = AnalyzerEngine()\n",
        "\n",
        "# Mapping file for storing forward/reverse mappings\n",
        "MAPPING_FILE = \"mappings.pkl\"\n",
        "forward_mapping = {}\n",
        "reverse_mapping = {}\n",
        "\n",
        "NUMERIC_PATTERN = re.compile(r\"^[<>]?[\\d,.%]+$\")\n",
        "SENSITIVE_HEADERS = {\"phone\", \"mobile\", \"credit\", \"card\", \"id\", \"name\"}\n",
        "EXCLUDED_ENTITIES = {\"DATE_TIME\"}\n",
        "\n",
        "def time_it(func):\n",
        "    \"\"\"Decorator to measure execution time of functions.\"\"\"\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f'\\n⏳ Execution time {func.__name__}: {end-start:.6f} seconds')\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "def de_anonymize_paragraph(text):\n",
        "  for category,mapping in reverse_mapping.items():\n",
        "    for fake_value,original_value in mapping.items():\n",
        "      if fake_value in text:\n",
        "        text=text.replace(fake_value,original_value)\n",
        "  return text\n",
        "\n",
        "def load_merged_pickle():\n",
        "    \"\"\"Loads fake data from fake_dataset.pkl\"\"\"\n",
        "    merged_file = \"fake_dataset.pkl\"\n",
        "\n",
        "    if os.path.exists(merged_file):\n",
        "        try:\n",
        "            with open(merged_file, \"rb\") as f:\n",
        "                return pickle.load(f)\n",
        "        except (pickle.UnpicklingError, EOFError) as e:\n",
        "            print(f\"⚠️ Error loading fake_dataset.pkl: {e}\")\n",
        "\n",
        "    return {}\n",
        "\n",
        "def load_mapping():\n",
        "    \"\"\"Loads existing mapping from Pickle file, ensuring proper data handling.\"\"\"\n",
        "    global forward_mapping, reverse_mapping\n",
        "    if os.path.exists(MAPPING_FILE):\n",
        "        try:\n",
        "            with open(MAPPING_FILE, \"rb\") as f:\n",
        "                data = pickle.load(f)\n",
        "                forward_mapping = data.get(\"forward_mapping\", {})\n",
        "                reverse_mapping = data.get(\"reverse_mapping\", {})\n",
        "            print(\"📂 Existing mapping loaded.\")\n",
        "        except (pickle.UnpicklingError, EOFError) as e:\n",
        "            print(f\"⚠️ Error loading Pickle file: {e}\")\n",
        "\n",
        "def save_mapping(filename):\n",
        "    \"\"\"Saves the mapping to a Pickle file with filename tracking.\"\"\"\n",
        "    mapping_data = {\n",
        "        \"file_name\": filename,\n",
        "        \"forward_mapping\": forward_mapping,\n",
        "        \"reverse_mapping\": reverse_mapping,\n",
        "        \"metadata\": {\n",
        "            \"updated_at\": datetime.now().isoformat(),\n",
        "            \"record_count\": len(forward_mapping),\n",
        "        },\n",
        "    }\n",
        "    with open(MAPPING_FILE, \"wb\") as f:\n",
        "        pickle.dump(mapping_data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    print(\"💾 Mapping saved successfully.\")\n",
        "\n",
        "def load_and_analyze(file_path):\n",
        "    \"\"\"Loads the file (CSV or Excel) and returns a DataFrame.\"\"\"\n",
        "    if file_path.endswith(\".csv\"):\n",
        "        return pd.read_csv(file_path, engine=\"python\")\n",
        "    elif file_path.endswith((\".xls\", \".xlsx\")):\n",
        "        return pd.read_excel(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Provide a CSV or Excel file.\")\n",
        "\n",
        "@time_it\n",
        "def check_existing_mappings(input_file):\n",
        "    \"\"\"Checks if existing mappings match the input file and regenerates anonymized data if needed.\"\"\"\n",
        "    if os.path.exists(MAPPING_FILE):\n",
        "        with open(MAPPING_FILE, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "            stored_filename = data.get(\"file_name\")\n",
        "\n",
        "        if stored_filename and stored_filename == input_file:\n",
        "            if not os.path.exists(\"anonymized.csv\"):\n",
        "                print(\"📌 Regenerating anonymized.csv from existing mappings...\")\n",
        "                df = load_and_analyze(input_file)\n",
        "                df = apply_existing_mappings(df)\n",
        "                write_file(df, \"anonymized.csv\")\n",
        "                return True\n",
        "        else:\n",
        "            print(\"⚠️ Input file does not match stored filename. Overwriting mapping...\")\n",
        "    return False\n",
        "\n",
        "def write_file(df, file_path):\n",
        "    \"\"\"Writes DataFrame to CSV or Excel.\"\"\"\n",
        "    file_ext = os.path.splitext(file_path)[-1].lower()\n",
        "    if file_ext == \".csv\":\n",
        "        df.to_csv(file_path, index=False)\n",
        "    elif file_ext in [\".xls\", \".xlsx\"]:\n",
        "        df.to_excel(file_path, index=False)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please use CSV or Excel.\")\n",
        "\n",
        "@time_it\n",
        "def analyze_column(df):\n",
        "    \"\"\"Uses Presidio to classify columns based on detected entity types.\"\"\"\n",
        "    entity_columns = {}\n",
        "    for col in df.columns:\n",
        "        col_lower = col.lower()\n",
        "        if any(keyword in col_lower for keyword in SENSITIVE_HEADERS):\n",
        "            entity_columns.setdefault(\"SENSITIVE\", []).append(col)\n",
        "            continue\n",
        "\n",
        "        unique_values = df[col].dropna().astype(str).unique()[:10]\n",
        "        entity_counts = {}\n",
        "\n",
        "        for value in unique_values:\n",
        "            if NUMERIC_PATTERN.match(value):\n",
        "                continue  # Skip purely numeric values unless it's a phone/credit card\n",
        "\n",
        "            results = analyzer.analyze(text=value, language=\"en\")\n",
        "            for result in results:\n",
        "                if result.entity_type in EXCLUDED_ENTITIES:\n",
        "                    continue  # Skip unwanted entities\n",
        "                entity_counts[result.entity_type] = entity_counts.get(result.entity_type, 0) + 1\n",
        "\n",
        "        if entity_counts:\n",
        "            predominant_entity = max(entity_counts, key=entity_counts.get)\n",
        "            if predominant_entity not in entity_columns:\n",
        "                entity_columns[predominant_entity] = []\n",
        "            entity_columns[predominant_entity].append(col)\n",
        "\n",
        "    return entity_columns\n",
        "\n",
        "def generate_fake_values(column):\n",
        "    \"\"\"Generates fake values while preserving uniqueness, using bothify and merged.json data.\"\"\"\n",
        "    col_name = column.name.lower()\n",
        "    original_values = column.dropna().unique()\n",
        "\n",
        "    match_key = None\n",
        "    for key in merged_data.keys():\n",
        "        if re.search(fr\"\\b{key}\\b\", col_name, re.IGNORECASE):\n",
        "            match_key = key\n",
        "            break\n",
        "\n",
        "    if column.dtype.kind in 'biufc':  # Skip numeric types except IDs\n",
        "        if re.search(r'\\bid\\b', col_name, re.IGNORECASE):\n",
        "            fake_values = [f\"ID-{fake.bothify(text='???##########')}\" for _ in original_values]\n",
        "            mapping = dict(zip(original_values, fake_values))\n",
        "            forward_mapping[col_name] = mapping\n",
        "            reverse_mapping[col_name] = {v: k for k, v in mapping.items()}\n",
        "            return column.map(mapping).fillna(column)\n",
        "\n",
        "        return column\n",
        "\n",
        "    fake_values = []\n",
        "\n",
        "    # ✅ Handle different column types\n",
        "    if re.search(r'\\b(phone|mobile)\\b', col_name, re.IGNORECASE):\n",
        "        fake_values = [fake.bothify(text='+## ##########') for _ in original_values]\n",
        "    elif re.search(r'\\b(card|credit)\\b', col_name, re.IGNORECASE):\n",
        "        fake_values = [fake.bothify(text='####-####-####-####') for _ in original_values]\n",
        "    elif re.search(r'\\b(domain|url|link)\\b', col_name, re.IGNORECASE):\n",
        "        fake_values = [\n",
        "            f\"www.{fake.bothify(text='?????')}/{fake.bothify(text='##??#?#?#?#?###')}/{fake.bothify(text='####')}.com\"\n",
        "            for _ in original_values\n",
        "        ]\n",
        "    elif re.search(r'\\bname\\b', col_name, re.IGNORECASE) and match_key:\n",
        "        fake_values_list = merged_data[match_key]\n",
        "        fake_values = [\n",
        "            f\"{name.split()[0]} {name.split()[-1]} {fake.bothify(text='????')}\" if ' ' in name else f\"{name} {fake.bothify(text='????')}\"\n",
        "            for name in fake_values_list[:len(original_values)]\n",
        "        ]\n",
        "    elif match_key:\n",
        "        fake_values_list = merged_data[match_key]\n",
        "        fake_values = [\n",
        "            fake_values_list[i] if i < len(fake_values_list) else fake.bothify(text='??????????')\n",
        "            for i in range(len(original_values))\n",
        "        ]\n",
        "    else: fake_values = [fake.bothify(text=\"?????##########\") for _ in original_values]\n",
        "\n",
        "    mapping = dict(zip(original_values, fake_values))\n",
        "    forward_mapping[col_name] = mapping\n",
        "    reverse_mapping[col_name] = {v: k for k, v in mapping.items()}\n",
        "\n",
        "    return column.map(mapping).fillna(column)\n",
        "\n",
        "@time_it\n",
        "def mask_columnwise(df):\n",
        "    \"\"\"Replaces sensitive data only in columns detected as sensitive by Presidio.\"\"\"\n",
        "    sensitive_columns = analyze_column(df)\n",
        "\n",
        "    for entity, cols in sensitive_columns.items():\n",
        "        for column in cols:\n",
        "            print(f\"🔒 Masking sensitive column: {column} (Detected as {entity})\")\n",
        "            df[column] = generate_fake_values(df[column])\n",
        "\n",
        "    return df\n",
        "\n",
        "def apply_existing_mappings(df):\n",
        "    \"\"\"Applies stored mappings to re-anonymize a DataFrame if mappings.json exists.\"\"\"\n",
        "    for column in df.columns:\n",
        "        col_name = column.lower()\n",
        "        if col_name in forward_mapping:\n",
        "            df[column] = df[column].astype(str).map(forward_mapping[col_name]).fillna(df[column])\n",
        "    return df\n",
        "\n",
        "\n",
        "def restore_data(df):\n",
        "    \"\"\"Restores original values using stored mappings.\"\"\"\n",
        "    for column in df.columns:\n",
        "        col_name = column.lower()\n",
        "        if col_name in reverse_mapping:\n",
        "            df[column] = df[column].astype(str).map(reverse_mapping[col_name]).fillna(df[column])\n",
        "    return df\n",
        "\n",
        "\n",
        "def check_if_files_match(original_file, restored_file):\n",
        "    \"\"\"Checks if the original and restored files match.\"\"\"\n",
        "    file_ext = os.path.splitext(original_file)[-1].lower()\n",
        "    original_df = pd.read_csv(original_file) if file_ext == \".csv\" else pd.read_excel(original_file)\n",
        "    restored_df = pd.read_csv(restored_file) if file_ext == \".csv\" else pd.read_excel(restored_file)\n",
        "\n",
        "    test = original_df.equals(restored_df)\n",
        "    print(f\"📊 Are files identical? {test}\")\n",
        "    if not test:\n",
        "        print(\"⚠️ Files are not identical!\")\n",
        "    else:\n",
        "        print(\"✅ Files match perfectly!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    merged_data = load_merged_pickle()\n",
        "    load_mapping()\n",
        "    # uploaded = files.upload()\n",
        "    # input_file = list(uploaded.keys())[0].strip().replace(' ', '-')\n",
        "    input_file = 'smaller_100k_companies.csv'\n",
        "\n",
        "    if not check_existing_mappings(input_file):\n",
        "        df = load_and_analyze(input_file)\n",
        "        df = mask_columnwise(df)\n",
        "        write_file(df, \"anonymized.csv\")\n",
        "        save_mapping(input_file)\n",
        "\n",
        "    restored_df = restore_data(load_and_analyze(\"anonymized.csv\"))\n",
        "    write_file(restored_df, \"restored.csv\")\n",
        "    check_if_files_match(input_file, \"restored.csv\")\n",
        "\n",
        "    print(\"✅ Processing complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_CffsGBAsWE",
        "outputId": "9b0d7ae4-206a-4e2c-8c6b-db1b1f989451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏳ Execution time check_existing_mappings: 0.000007 seconds\n",
            "\n",
            "⏳ Execution time analyze_column: 0.789008 seconds\n",
            "🔒 Masking sensitive column: id (Detected as SENSITIVE)\n",
            "🔒 Masking sensitive column: name (Detected as SENSITIVE)\n",
            "🔒 Masking sensitive column: domain (Detected as URL)\n",
            "🔒 Masking sensitive column: linkedin url (Detected as URL)\n",
            "🔒 Masking sensitive column: locality (Detected as LOCATION)\n",
            "🔒 Masking sensitive column: country (Detected as LOCATION)\n",
            "\n",
            "⏳ Execution time mask_columnwise: 15.929399 seconds\n",
            "💾 Mapping saved successfully.\n",
            "📊 Are files identical? True\n",
            "✅ Files match perfectly!\n",
            "✅ Processing complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converted list of dictionary of lists into dictionary\n",
        "# Converting json to pickle\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "def convert_merged_json(input_file=\"merged.json\", output_file=\"converted_merged.json\"):\n",
        "    \"\"\"Converts a list of dictionaries into a single dictionary and saves it.\"\"\"\n",
        "    if not os.path.exists(input_file):\n",
        "        print(f\"⚠️ File {input_file} not found.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        if isinstance(data, list):\n",
        "            merged_dict = {}\n",
        "            for entry in data:\n",
        "                if isinstance(entry, dict):\n",
        "                    merged_dict.update(entry)\n",
        "\n",
        "            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump(merged_dict, f, indent=4)\n",
        "\n",
        "            print(f\"✅ Successfully converted and saved as {output_file}\")\n",
        "        else:\n",
        "            print(\"⚠️ The input JSON is already in the correct format.\")\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"❌ Error parsing JSON: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Unexpected error: {e}\")\n",
        "\n",
        "def converting_json_to_pickle(input_file=\"fake_dataset.json\", output_file=\"fake_dataset.pkl\"):\n",
        "  with open(input_file, 'r') as fp:\n",
        "    data = json.load(fp)\n",
        "\n",
        "  with open(output_file, 'wb') as fp:\n",
        "    pickle.dump(data, fp)\n",
        "\n",
        "# converting_json_to_pickle()"
      ],
      "metadata": {
        "id": "zC8xAa1DXC01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing - classify orgainization\n",
        "import re\n",
        "import os\n",
        "import gzip\n",
        "import time\n",
        "import json\n",
        "import spacy\n",
        "import string\n",
        "import random\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "from collections import defaultdict, deque\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "\n",
        "# Variable defined\n",
        "ID = {}\n",
        "fake_data={}\n",
        "used_urls = set()\n",
        "\n",
        "url_extensions = [\n",
        "    \".com\", \".net\", \".org\", \".edu\", \".gov\", \".co\", \".us\", \".uk\", \".in\", \".ru\",\n",
        "    \".jp\", \".cn\", \".de\", \".fr\", \".it\", \".nl\", \".es\", \".br\", \".au\", \".ca\",\n",
        "    \".ch\", \".se\", \".no\", \".za\", \".mx\", \".ar\", \".be\", \".kr\", \".pl\", \".tr\",\n",
        "    \".ua\", \".ir\", \".sa\", \".ae\", \".my\", \".sg\", \".hk\", \".tw\", \".nz\", \".id\",\n",
        "    \".th\", \".ph\", \".vn\", \".bd\", \".lk\", \".np\", \".pk\", \".cz\", \".gr\", \".hu\",\n",
        "    \".fi\", \".dk\", \".il\", \".ie\", \".pt\", \".sk\", \".si\", \".ro\", \".bg\", \".rs\",\n",
        "    \".lt\", \".lv\", \".ee\", \".hr\", \".ba\", \".md\", \".ge\", \".kz\", \".by\", \".tm\",\n",
        "    \".uz\", \".af\", \".qa\", \".om\", \".kw\", \".bh\", \".ye\", \".jo\", \".lb\", \".sy\",\n",
        "    \".iq\", \".ps\", \".az\", \".am\", \".kg\", \".mn\", \".bt\", \".mv\", \".mm\", \".kh\",\n",
        "    \".la\", \".tl\", \".sb\", \".fj\", \".pg\", \".to\", \".tv\", \".ws\", \".fm\", \".ki\"\n",
        "]\n",
        "with gzip.open(\"faker_data_v2.json.gz\", \"rt\", encoding = 'utf-8') as f: fake_data_list = json.load(f)\n",
        "# Objects\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "fake=Faker()\n",
        "analyzer = AnalyzerEngine()\n",
        "\n",
        "for data in fake_data_list:\n",
        "    for key,value in data.items(): fake_data[key]=deque(value)\n",
        "domain_pool = list(fake_data.get('url', deque()))\n",
        "\n",
        "entity_mapping={\n",
        "    'names':'PERSON',\n",
        "    'emails':'EMAIL_ADDRESS',\n",
        "    'phone':'PHONE_NUMBER',\n",
        "    'location':'LOCATION',\n",
        "    'credit':'CREDIT_CARD',\n",
        "    'url':'URL',\n",
        "    'country':'COUNTRY',\n",
        "    'company':\"ORG\",\n",
        "    'id':'ID',\n",
        "}\n",
        "\n",
        "mapping_file=\"mapping.json\"\n",
        "forward_mapping=defaultdict(dict)\n",
        "reverse_mapping=defaultdict(dict)\n",
        "\n",
        "if os.path.exists(mapping_file):\n",
        "    with open(mapping_file, \"r\") as f:\n",
        "        mapping_data = json.load(f)\n",
        "        forward_mapping.update(mapping_data.get(\"forward_mapping\", {}))\n",
        "        reverse_mapping.update(mapping_data.get(\"reverse_mapping\", {}))\n",
        "def time_it(func):\n",
        "    \"\"\"Decorator to measure execution time of functions.\"\"\"\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f'\\n⏳ Execution time {func.__name__}: {end-start:.6f} seconds')\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "@time_it\n",
        "def analyze_column(df):\n",
        "    entity_columns = {}\n",
        "\n",
        "    # Step 1: Use Presidio to analyze all columns\n",
        "    for col in df.columns:\n",
        "        if 'id' in col.lower():\n",
        "            entity_columns[col] = 'ID'\n",
        "        elif 'country' in col.lower():\n",
        "            entity_columns[col] = 'COUNTRY'\n",
        "        else:\n",
        "            unique_values = df[col].dropna().astype(str).unique()[:25]\n",
        "            entity_counts = {}\n",
        "\n",
        "            for value in unique_values:\n",
        "                results = analyzer.analyze(text=value, language='en')\n",
        "                for result in results:\n",
        "                    entity_counts[result.entity_type] = entity_counts.get(result.entity_type, 0) + 1\n",
        "\n",
        "            if entity_counts:\n",
        "                predominant_entity = max(entity_counts, key=entity_counts.get)\n",
        "                entity_columns[col] = predominant_entity\n",
        "                if predominant_entity==\"LOCATION\":\n",
        "                  org_count=0\n",
        "                  for value in unique_values:\n",
        "                    doc=nlp(value)\n",
        "                    for ent in doc.ents:\n",
        "                      if ent.label_==\"ORG\":\n",
        "                        org_count+=1\n",
        "                  if org_count>5:\n",
        "                    predominant_entity=\"ORG\"\n",
        "                entity_columns[col]=predominant_entity\n",
        "\n",
        "    # Step 2: Use SpaCy to analyze non-numeric and unclassified columns\n",
        "    for col in df.select_dtypes(exclude=['number']).columns:\n",
        "        if col not in entity_columns:\n",
        "            unique_values = df[col].dropna().astype(str).unique()[:25]\n",
        "            org_count = 0\n",
        "\n",
        "            for value in unique_values:\n",
        "                doc = nlp(value)\n",
        "                for ent in doc.ents:\n",
        "                    if ent.label_ == 'ORG':\n",
        "                        org_count += 1\n",
        "\n",
        "            # If more than half of the sample values are ORG, classify as ORG\n",
        "            if org_count > 12:\n",
        "                entity_columns[col] = 'ORG'\n",
        "\n",
        "    return entity_columns\n",
        "\n",
        "\n",
        "def modify_fake_value(category, base_fake_value, counter):\n",
        "    if category == \"names\": return f\"{base_fake_value} {string.ascii_uppercase[counter % 26]}.\"\n",
        "    elif category == \"emails\":\n",
        "        name, domain = base_fake_value.split(\"@\")\n",
        "        return f\"{name}{counter}@{domain}\"\n",
        "    elif category in {\"location\", \"country\"}: return f\"{base_fake_value}, District {counter % 100_000_000 + 1}\"\n",
        "    elif category == \"url\":\n",
        "        # Check if the URL already exists, if so, append a country extension\n",
        "        fake_value = base_fake_value\n",
        "        while fake_value in used_urls:\n",
        "            ext = random.choice(url_extensions)\n",
        "            if not fake_value.endswith(ext):\n",
        "                fake_value += ext\n",
        "        used_urls.add(fake_value)\n",
        "        return fake_value\n",
        "    elif category == \"phone\": return f\"{base_fake_value[:-2]}{counter % 100:02d}\"\n",
        "    elif category == \"company\": return f\"{base_fake_value} Group {counter % 100_000_000 + 1}\"\n",
        "    elif category == \"credit\": return f\"{base_fake_value[:-4]}{counter % 10000:04d}\"\n",
        "    else: return f\"{base_fake_value}-{counter}\"\n",
        "\n",
        "\n",
        "def get_fake_value(category, original_value):\n",
        "    global ID\n",
        "    fake_value = None\n",
        "    original_value = original_value.strip()\n",
        "    if original_value in forward_mapping[category]: return forward_mapping[category][original_value]\n",
        "\n",
        "    # Special case for ID\n",
        "    if category == 'id':\n",
        "        length = 6\n",
        "        while True:\n",
        "            fake_value = fake.bothify(text=f'ID-{\"#\"*length}')\n",
        "            if fake_value not in ID:\n",
        "                ID[fake_value] = True\n",
        "                break\n",
        "            if len(ID) >= 10 ** length: length += 1\n",
        "    elif category == 'url':\n",
        "        domain1, domain2 = random.sample(domain_pool, 2)\n",
        "        base_fake_value = f\"https://{domain1.lower()}/{domain2.lower()}.co\"\n",
        "\n",
        "        if base_fake_value not in reverse_mapping[\"url\"]:\n",
        "            fake_value = base_fake_value\n",
        "        else:\n",
        "            counter = len(reverse_mapping[\"url\"])\n",
        "            fake_value = modify_fake_value(\"url\", base_fake_value, counter)\n",
        "\n",
        "    elif fake_data.get(category):\n",
        "      for _ in range(len(fake_data[category])):\n",
        "          candidate = fake_data[category].popleft()\n",
        "          fake_data[category].append(candidate)  # Reinsert at end (rotation)\n",
        "          if candidate not in reverse_mapping[category]:\n",
        "              fake_value = candidate\n",
        "              break\n",
        "      else:\n",
        "          counter = len(reverse_mapping[category])\n",
        "          base_fake_value = random.choice(list(reverse_mapping[category])) if reverse_mapping[category] else f\"{category}_\"\n",
        "          fake_value = modify_fake_value(category, base_fake_value, counter)\n",
        "\n",
        "    if not fake_value or fake_value in reverse_mapping[category]:\n",
        "        counter = len(reverse_mapping[category])\n",
        "        base = fake_value if fake_value else f\"{category}_\"\n",
        "        fake_value = modify_fake_value(category, base, counter)\n",
        "\n",
        "    # Store forward & reverse mappings\n",
        "    forward_mapping[category][original_value] = fake_value\n",
        "    reverse_mapping[category][fake_value] = original_value\n",
        "\n",
        "    return fake_value\n",
        "\n",
        "\n",
        "@time_it\n",
        "def mask_dataframe(df):\n",
        "    for col, entity in entity_columns.items():\n",
        "        matching_keys = [key for key, value in entity_mapping.items() if value == entity]\n",
        "        if matching_keys:\n",
        "            df[col] = df[col].astype(str).apply(lambda x: get_fake_value(matching_keys[0], str(x)) if x else str(x))\n",
        "    return df\n",
        "\n",
        "def restore_original_value(category, fake_value):\n",
        "    return reverse_mapping[category].get(fake_value, fake_value)\n",
        "\n",
        "@time_it\n",
        "def unmask_dataframe(df):\n",
        "    for col, entity in entity_columns.items():\n",
        "        matching_keys = [key for key, value in entity_mapping.items() if value == entity]\n",
        "        if matching_keys:\n",
        "            category = matching_keys[0]\n",
        "            df[col] = df[col].astype(str).apply(lambda x: restore_original_value(category, str(x)) if x else str(x))\n",
        "\n",
        "    return df\n",
        "def compare_files(original_file, restored_file):\n",
        "    \"\"\"Check if the original and restored files are identical.\"\"\"\n",
        "    file_ext = os.path.splitext(original_file)[-1].lower()\n",
        "    original_df = pd.read_excel(original_file) if file_ext == \".xlsx\" else pd.read_csv(original_file)\n",
        "    restored_df = pd.read_excel(restored_file) if file_ext == \".xlsx\" else pd.read_csv(restored_file)\n",
        "\n",
        "    is_identical = original_df.equals(restored_df)\n",
        "    print(f\"📊 Are files identical? {'✅ Yes' if is_identical else '❌ No'}\")\n",
        "    if not is_identical:\n",
        "        print(\"⚠️ The restored file does not match the original. There may be an issue with the mapping.\")\n",
        "\n",
        "    return is_identical\n",
        "\n",
        "def de_anonymize_paragraph(text):\n",
        "  for category,mapping in reverse_mapping.items():\n",
        "    for fake_value,original_value in mapping.items():\n",
        "      if fake_value in text:\n",
        "        text=text.replace(fake_value,original_value)\n",
        "  return text\n",
        "\n",
        "def save_mapping(filename):\n",
        "    mapping_data={\n",
        "        \"filename\":filename,\n",
        "        \"updated_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
        "        \"forward_mapping\":forward_mapping,\n",
        "        \"reverse_mapping\":reverse_mapping\n",
        "    }\n",
        "    with open(mapping_file, \"w\") as f:\n",
        "        json.dump(mapping_data, f, indent=4)\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    input_file=\"smaller_100k_companies.csv\"\n",
        "    file_ext=os.path.splitext(input_file)[-1].lower()\n",
        "\n",
        "    df = pd.read_excel(input_file, dtype=str) if file_ext == \".xlsx\" else pd.read_csv(input_file, dtype=str, low_memory=False)\n",
        "    entity_columns=analyze_column(df)\n",
        "    print(entity_columns)\n",
        "\n",
        "    anonymized_df=mask_dataframe(df)\n",
        "    output_file=\"anonymized.xlsx\" if file_ext==\".xlsx\" else \"anonymized.csv\"\n",
        "    anonymized_df.to_excel(output_file,index=False) if file_ext==\".xlsx\" else anonymized_df.to_csv(output_file,index=False)\n",
        "    print(f\"✅ Anonymized data saved as {output_file}\")\n",
        "\n",
        "    save_mapping(input_file)\n",
        "    restored_df=unmask_dataframe(pd.read_excel(output_file) if file_ext==\".xlsx\" else pd.read_csv(output_file))\n",
        "    restored_file=\"restored.xlsx\" if file_ext==\".xlsx\" else \"restored.csv\"\n",
        "    restored_df.to_excel(restored_file,index=False) if file_ext==\".xlsx\" else restored_df.to_csv(restored_file,index=False)\n",
        "    print(f\"✅ Restored data saved as {restored_file}\")\n",
        "    compare_files(input_file, restored_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUrTvwkGF8AB",
        "outputId": "1303ccb3-6cd8-4691-9a68-9b3de228e959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏳ Execution time analyze_column: 3.669720 seconds\n",
            "{'id': 'ID', 'name': 'ORG', 'domain': 'URL', 'size range': 'DATE_TIME', 'locality': 'LOCATION', 'country': 'COUNTRY', 'linkedin url': 'URL', 'current employee estimate': 'US_DRIVER_LICENSE', 'total employee estimate': 'US_DRIVER_LICENSE'}\n",
            "\n",
            "⏳ Execution time mask_dataframe: 2.481203 seconds\n",
            "✅ Anonymized data saved as anonymized.csv\n",
            "\n",
            "⏳ Execution time unmask_dataframe: 0.367132 seconds\n",
            "✅ Restored data saved as restored.csv\n",
            "📊 Are files identical? ✅ Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Code - Optimizing for excel :- Main Code\n",
        "import re\n",
        "import os\n",
        "import gzip\n",
        "import time\n",
        "import json\n",
        "import spacy\n",
        "import string\n",
        "import random\n",
        "import tempfile\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, deque\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "\n",
        "# Variable defined\n",
        "ID, fake_data, used_urls, entity_columns  = {}, {}, set(), {}\n",
        "COMMENT_KEYWORDS = ['comments', 'description', 'remarks', 'note', 'feedback', 'observation']\n",
        "\n",
        "url_extensions = [\n",
        "    \".com\", \".net\", \".org\", \".edu\", \".gov\", \".co\", \".us\", \".uk\", \".in\", \".ru\",\n",
        "    \".jp\", \".cn\", \".de\", \".fr\", \".it\", \".nl\", \".es\", \".br\", \".au\", \".ca\",\n",
        "    \".ch\", \".se\", \".no\", \".za\", \".mx\", \".ar\", \".be\", \".kr\", \".pl\", \".tr\",\n",
        "    \".ua\", \".ir\", \".sa\", \".ae\", \".my\", \".sg\", \".hk\", \".tw\", \".nz\", \".id\",\n",
        "    \".th\", \".ph\", \".vn\", \".bd\", \".lk\", \".np\", \".pk\", \".cz\", \".gr\", \".hu\",\n",
        "    \".fi\", \".dk\", \".il\", \".ie\", \".pt\", \".sk\", \".si\", \".ro\", \".bg\", \".rs\",\n",
        "    \".lt\", \".lv\", \".ee\", \".hr\", \".ba\", \".md\", \".ge\", \".kz\", \".by\", \".tm\",\n",
        "    \".uz\", \".af\", \".qa\", \".om\", \".kw\", \".bh\", \".ye\", \".jo\", \".lb\", \".sy\",\n",
        "    \".iq\", \".ps\", \".az\", \".am\", \".kg\", \".mn\", \".bt\", \".mv\", \".mm\", \".kh\",\n",
        "    \".la\", \".tl\", \".sb\", \".fj\", \".pg\", \".to\", \".tv\", \".ws\", \".fm\", \".ki\"\n",
        "]\n",
        "with open(\"test.json\", \"r\", ) as f: fake_data_list = json.load(f)\n",
        "# Objects\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "fake=Faker()\n",
        "analyzer = AnalyzerEngine()\n",
        "\n",
        "for data in fake_data_list:\n",
        "    for key,value in data.items(): fake_data[key]=deque(value)\n",
        "domain_pool = list(fake_data.get('url', deque()))\n",
        "\n",
        "entity_mapping={\n",
        "    'names':'PERSON',\n",
        "    'emails':'EMAIL_ADDRESS',\n",
        "    'phone':'PHONE_NUMBER',\n",
        "    'location':'LOCATION',\n",
        "    'credit':'CREDIT_CARD',\n",
        "    'url':'URL',\n",
        "    'country':'COUNTRY',\n",
        "    'company':\"ORG\",\n",
        "    'id':'ID',\n",
        "}\n",
        "\n",
        "mapping_file=\"mapping.json\"\n",
        "forward_mapping=defaultdict(dict)\n",
        "reverse_mapping=defaultdict(dict)\n",
        "\n",
        "if os.path.exists(mapping_file):\n",
        "    with open(mapping_file, \"r\") as f:\n",
        "        mapping_data = json.load(f)\n",
        "        forward_mapping.update(mapping_data.get(\"forward_mapping\", {}))\n",
        "        reverse_mapping.update(mapping_data.get(\"reverse_mapping\", {}))\n",
        "# For comments logic\n",
        "def get_comment_columns(df):\n",
        "    return [col for col in df.columns if any(kw in col.lower() for kw in COMMENT_KEYWORDS)]\n",
        "\n",
        "def mask_comment_columns(df, mapping):\n",
        "    comment_cols = get_comment_columns(df)\n",
        "    print('Inside mask comment cols:', comment_cols)\n",
        "    for col in comment_cols:\n",
        "        df[col] = df[col].astype(str).apply(lambda x: mask_comment_text(x, mapping))\n",
        "    return df\n",
        "\n",
        "def mask_comment_text(text, mapping):\n",
        "    if not text.strip():\n",
        "        return text\n",
        "    doc = nlp(text)\n",
        "    modified_text = text\n",
        "    for token in doc:\n",
        "        if token.pos_ == \"PROPN\" or token.ent_type_:\n",
        "            mapped_value = mapping['names'].get(token.text, None)\n",
        "            if mapped_value:\n",
        "              modified_text = re.sub(\n",
        "                rf\"\\b{re.escape(token.text)}(?=[\\W_]|$)\", mapped_value, modified_text\n",
        "            )\n",
        "\n",
        "    return modified_text\n",
        "\n",
        "def unmask_comment_text(text, reverse_mapping):\n",
        "    if not text.strip(): return text\n",
        "    doc = nlp(text)\n",
        "    modified_text = text\n",
        "    for token in doc:\n",
        "        if token.pos_ == \"PROPN\" or token.ent_type_:\n",
        "            original_value = reverse_mapping['names'].get(token.text, None)\n",
        "            if original_value:\n",
        "                modified_text = re.sub(\n",
        "                    rf\"\\b{re.escape(token.text)}(?=[\\W_]|$)\", original_value, modified_text\n",
        "                )\n",
        "    return modified_text\n",
        "\n",
        "# To track time\n",
        "def time_it(func):\n",
        "    \"\"\"Decorator to measure execution time of functions.\"\"\"\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f'\\n⏳ Execution time {func.__name__}: {end-start:.6f} seconds')\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "@time_it\n",
        "def analyze_column(df):\n",
        "    # Step 1: Use Presidio to analyze all columns\n",
        "    comment_cols = get_comment_columns(df)\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col in comment_cols: continue\n",
        "\n",
        "        if 'id' in col.lower():\n",
        "            entity_columns[col] = 'ID'\n",
        "        elif 'country' in col.lower():\n",
        "            entity_columns[col] = 'COUNTRY'\n",
        "        else:\n",
        "            unique_values = df[col].dropna().astype(str).unique()[:25]\n",
        "            entity_counts = {}\n",
        "\n",
        "            for value in unique_values:\n",
        "                results = analyzer.analyze(text=value, language='en')\n",
        "                for result in results:\n",
        "                    entity_counts[result.entity_type] = entity_counts.get(result.entity_type, 0) + 1\n",
        "\n",
        "            if entity_counts:\n",
        "                predominant_entity = max(entity_counts, key=entity_counts.get)\n",
        "                entity_columns[col] = predominant_entity\n",
        "                if predominant_entity==\"LOCATION\":\n",
        "                  org_count=0\n",
        "                  for value in unique_values:\n",
        "                    doc=nlp(value)\n",
        "                    for ent in doc.ents:\n",
        "                      if ent.label_==\"ORG\":\n",
        "                        org_count+=1\n",
        "                  if org_count>5:\n",
        "                    predominant_entity=\"ORG\"\n",
        "                entity_columns[col]=predominant_entity\n",
        "\n",
        "    # Step 2: Use SpaCy to analyze non-numeric and unclassified columns\n",
        "    for col in df.select_dtypes(exclude=['number']).columns:\n",
        "        if col not in entity_columns:\n",
        "            unique_values = df[col].dropna().astype(str).unique()[:25]\n",
        "            org_count = 0\n",
        "\n",
        "            for value in unique_values:\n",
        "                doc = nlp(value)\n",
        "                for ent in doc.ents:\n",
        "                    if ent.label_ == 'ORG':\n",
        "                        org_count += 1\n",
        "\n",
        "            # If more than half of the sample values are ORG, classify as ORG\n",
        "            if org_count > 12:\n",
        "                entity_columns[col] = 'ORG'\n",
        "\n",
        "    return entity_columns\n",
        "\n",
        "def modify_fake_value(category, base_fake_value, counter):\n",
        "    if category == \"names\": return f\"{base_fake_value}{string.ascii_lowercase[counter % 26]}\"\n",
        "    elif category == \"emails\":\n",
        "        name, domain = base_fake_value.split(\"@\")\n",
        "        return f\"{name}{counter}@{domain}\"\n",
        "    elif category in {\"location\", \"country\"}: return f\"{base_fake_value}, District {counter % 100_000_000 + 1}\"\n",
        "    elif category == \"url\":\n",
        "        # Check if the URL already exists, if so, append a country extension\n",
        "        fake_value = base_fake_value\n",
        "        while fake_value in used_urls:\n",
        "            ext = random.choice(url_extensions)\n",
        "            if not fake_value.endswith(ext):\n",
        "                fake_value += ext\n",
        "        used_urls.add(fake_value)\n",
        "        return fake_value\n",
        "    elif category == \"phone\": return f\"{base_fake_value[:-2]}{counter % 100:02d}\"\n",
        "    elif category == \"company\": return f\"{base_fake_value} Group {counter % 100_000_000 + 1}\"\n",
        "    elif category == \"credit\": return f\"{base_fake_value[:-4]}{counter % 10000:04d}\"\n",
        "    else: return f\"{base_fake_value}-{counter}\"\n",
        "\n",
        "\n",
        "def get_fake_value(category, original_value):\n",
        "    global ID\n",
        "    fake_value = None\n",
        "    if category == \"names\":\n",
        "        original_tokens = str(original_value).split()\n",
        "        fake_tokens = []\n",
        "        used_fake_names = set(reverse_mapping[category])\n",
        "\n",
        "        for token in original_tokens:\n",
        "            if token in forward_mapping[category]:\n",
        "                fake_token = forward_mapping[category][token]\n",
        "            else:\n",
        "                fake_token = None\n",
        "\n",
        "                if fake_data.get(category):\n",
        "                    for _ in range(len(fake_data[category])):\n",
        "                        candidate = fake_data[category].popleft()\n",
        "                        fake_data[category].append(candidate)\n",
        "\n",
        "                        if candidate not in used_fake_names and candidate != token:\n",
        "                            fake_token = candidate\n",
        "                            break\n",
        "                        else:\n",
        "                            # Modify it if already used\n",
        "                            counter = 0\n",
        "                            base = candidate\n",
        "                            while True:\n",
        "                                modified = modify_fake_value(category, base, counter)\n",
        "                                if modified not in used_fake_names and modified != token:\n",
        "                                    fake_token = modified\n",
        "                                    break\n",
        "                                counter += 1\n",
        "                            break  # once we found a modified one, skip the rest\n",
        "\n",
        "                # Absolute fallback: no fake_data or nothing worked\n",
        "                if not fake_token:\n",
        "                    counter = 0\n",
        "                    base_pool = list(used_fake_names)\n",
        "                    random.shuffle(base_pool)\n",
        "\n",
        "                    for base in base_pool[:10]:  # Try 10\n",
        "                        fake_token = modify_fake_value(category, base, counter)\n",
        "                        if fake_token not in used_fake_names and fake_token != token:\n",
        "                            break\n",
        "                        counter += 1\n",
        "                    else:\n",
        "                        # Final fallback: just keep modifying the original token\n",
        "                        while True:\n",
        "                            fake_token = modify_fake_value(category, token, counter)\n",
        "                            if fake_token not in used_fake_names:\n",
        "                                break\n",
        "                            counter += 1\n",
        "\n",
        "                # Save mappings\n",
        "                forward_mapping[category][token] = fake_token\n",
        "                reverse_mapping[category][fake_token] = token\n",
        "                used_fake_names.add(fake_token)\n",
        "\n",
        "            fake_tokens.append(fake_token)\n",
        "\n",
        "        return \" \".join(fake_tokens)\n",
        "\n",
        "\n",
        "\n",
        "    if original_value in forward_mapping[category]: return forward_mapping[category][original_value]\n",
        "    # Special case for ID\n",
        "    if category == 'id':\n",
        "        length = 6\n",
        "        while True:\n",
        "            fake_value = fake.bothify(text=f'ID-{\"#\"*length}')\n",
        "            if fake_value not in ID:\n",
        "                ID[fake_value] = True\n",
        "                break\n",
        "            if len(ID) >= 10 ** length: length += 1\n",
        "    elif category == 'url':\n",
        "        domain1, domain2 = random.sample(domain_pool, 2)\n",
        "        base_fake_value = f\"https://{domain1.lower()}/{domain2.lower()}.co\"\n",
        "\n",
        "        if base_fake_value not in reverse_mapping[\"url\"]:\n",
        "            fake_value = base_fake_value\n",
        "        else:\n",
        "            counter = len(reverse_mapping[\"url\"])\n",
        "            fake_value = modify_fake_value(\"url\", base_fake_value, counter)\n",
        "\n",
        "    elif fake_data.get(category):\n",
        "      length = len(fake_data[category])\n",
        "      for _ in range(length):\n",
        "            candidate = fake_data[category].popleft()\n",
        "            fake_data[category].append(candidate)  # Reinsert at end (rotation)\n",
        "            if candidate not in reverse_mapping[category]:\n",
        "                fake_value = candidate\n",
        "                break\n",
        "      else:\n",
        "          counter = len(reverse_mapping[category])\n",
        "          base_fake_value = (\n",
        "              random.choice(list(reverse_mapping[category]))\n",
        "              if reverse_mapping[category]\n",
        "              else f\"{category}_\"\n",
        "          )\n",
        "          fake_value = modify_fake_value(category, base_fake_value, counter)\n",
        "\n",
        "    if not fake_value or fake_value in reverse_mapping[category]:\n",
        "        counter = len(reverse_mapping[category])\n",
        "        base = fake_value if fake_value else f\"{category}_\"\n",
        "        fake_value = modify_fake_value(category, base, counter)\n",
        "\n",
        "    # Store forward & reverse mappings\n",
        "    forward_mapping[category][original_value] = fake_value\n",
        "    reverse_mapping[category][fake_value] = original_value\n",
        "\n",
        "    return fake_value\n",
        "\n",
        "\n",
        "@time_it\n",
        "def mask_dataframe(df):\n",
        "    for col, entity in entity_columns.items():\n",
        "        matching_keys = [\n",
        "            key for key, value in entity_mapping.items() if value == entity\n",
        "        ]\n",
        "        if matching_keys:\n",
        "            category = matching_keys[0]\n",
        "            df[col] = df[col].astype(str).apply(\n",
        "                lambda x: get_fake_value(category, x) if x else x\n",
        "            )\n",
        "    return df\n",
        "\n",
        "\n",
        "def restore_original_value(category, fake_value):\n",
        "    return reverse_mapping[category].get(fake_value, fake_value)\n",
        "\n",
        "@time_it\n",
        "def unmask_dataframe(df):\n",
        "    for col, entity in entity_columns.items():\n",
        "        matching_keys = [key for key, value in entity_mapping.items() if value == entity]\n",
        "        if matching_keys:\n",
        "            category = matching_keys[0]\n",
        "\n",
        "            if category == \"names\":\n",
        "                def reverse_name(val):\n",
        "                    tokens = str(val).split()\n",
        "                    original_tokens = [reverse_mapping[category].get(tok, tok) for tok in tokens]\n",
        "                    return \" \".join(original_tokens)\n",
        "                df[col] = df[col].astype(str).apply(lambda x: reverse_name(x) if pd.notna(x) else x)\n",
        "\n",
        "            else:\n",
        "                df[col] = df[col].astype(str).apply(\n",
        "                    lambda x: restore_original_value(category, str(x)) if pd.notna(str(x)) else x\n",
        "                )\n",
        "    comment_cols = get_comment_columns(df)\n",
        "    for col in comment_cols:\n",
        "        df[col] = df[col].astype(str).apply(lambda x: unmask_comment_text(x, reverse_mapping))\n",
        "    return df\n",
        "\n",
        "@time_it\n",
        "def compare_files(original_csv, restored_csv):\n",
        "    \"\"\"Compare two CSV files and return if they are identical.\"\"\"\n",
        "    original_df = pd.read_csv(original_csv, dtype=str).sort_index(axis=1).reset_index(drop=True)\n",
        "    restored_df = pd.read_csv(restored_csv, dtype=str).sort_index(axis=1).reset_index(drop=True)\n",
        "\n",
        "    is_identical = original_df.equals(restored_df)\n",
        "    print(f\"\\n📊 Are files identical? {'✅ Yes' if is_identical else '❌ No'}\")\n",
        "\n",
        "    if not is_identical:\n",
        "        print(\"⚠️ The restored file does not match the original. Investigate the mapping or masking logic.\")\n",
        "\n",
        "    return is_identical\n",
        "\n",
        "def de_anonymize_paragraph(text):\n",
        "  for category,mapping in reverse_mapping.items():\n",
        "    for fake_value,original_value in mapping.items():\n",
        "      if fake_value in text:\n",
        "        text=text.replace(fake_value,original_value)\n",
        "  return text\n",
        "\n",
        "def save_mapping(filename):\n",
        "    mapping_data={\n",
        "        \"filename\":filename,\n",
        "        \"updated_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
        "        \"forward_mapping\":forward_mapping,\n",
        "        \"reverse_mapping\":reverse_mapping\n",
        "    }\n",
        "    with open(mapping_file, \"a\") as f:\n",
        "        json.dump(mapping_data, f, indent=4)\n",
        "\n",
        "def process_file(input_file, file_ext):\n",
        "    input_base = os.path.splitext(os.path.basename(input_file))[0]\n",
        "    output_dir = os.path.join(\".\", input_base)\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    if file_ext == \".xlsx\":\n",
        "        xl = pd.read_excel(input_file, sheet_name=None, dtype=str, engine='openpyxl')\n",
        "\n",
        "        for sheet_name, df in xl.items():\n",
        "            print(f\"\\n🔍 Processing sheet: {sheet_name}\")\n",
        "\n",
        "            original_csv = os.path.join(output_dir, f\"{sheet_name}_original.csv\")\n",
        "            masked_csv = os.path.join(output_dir, f\"{sheet_name}_masked.csv\")\n",
        "            restored_csv = os.path.join(output_dir, f\"{sheet_name}_restored.csv\")\n",
        "\n",
        "            df.to_csv(original_csv, index=False)\n",
        "\n",
        "            entity_columns = analyze_column(df)\n",
        "            print(f\"Detected entities: {entity_columns}\")\n",
        "\n",
        "            masked_df = mask_dataframe(df.copy())\n",
        "            # masked_df = mask_comment_columns(masked_df, forward_mapping)\n",
        "            restored_df = unmask_dataframe(masked_df.copy())\n",
        "\n",
        "            masked_df.to_csv(masked_csv, index=False)\n",
        "            restored_df.to_csv(restored_csv, index=False)\n",
        "\n",
        "            compare_files(original_csv, restored_csv)\n",
        "\n",
        "            save_mapping(f'{input_file}-->{sheet_name}')\n",
        "            entity_columns.clear()\n",
        "\n",
        "\n",
        "    elif file_ext == \".csv\":\n",
        "        df = pd.read_csv(input_file, dtype=str, low_memory=False)\n",
        "        print(f\"\\n🔍 Processing CSV: {input_file}\")\n",
        "\n",
        "        original_csv = os.path.join(output_dir, \"original.csv\")\n",
        "        masked_csv = os.path.join(output_dir, \"anonymized.csv\")\n",
        "        restored_csv = os.path.join(output_dir, \"restored.csv\")\n",
        "\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        df.to_csv(original_csv, index=False)\n",
        "\n",
        "        entity_columns = analyze_column(df)\n",
        "        print(f\"Detected entities: {entity_columns}\")\n",
        "\n",
        "        masked_df = mask_dataframe(df.copy())\n",
        "        # masked_df = mask_comment_columns(masked_df, forward_mapping)\n",
        "        restored_df = unmask_dataframe(masked_df.copy())\n",
        "\n",
        "        masked_df.to_csv(masked_csv, index=False)\n",
        "        restored_df.to_csv(restored_csv, index=False)\n",
        "\n",
        "        compare_files(original_csv, restored_csv)\n",
        "\n",
        "        save_mapping(input_file)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type. Use .csv or .xlsx only.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_file = \"for_colab_test.csv\"\n",
        "    file_ext = os.path.splitext(input_file)[-1].lower()\n",
        "    process_file(input_file, file_ext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKsxxp6Q7lJh",
        "outputId": "20f40c90-b6da-4f10-93f0-bb422319244d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Processing CSV: for_colab_test.csv\n",
            "\n",
            "⏳ Execution time analyze_column: 2.157893 seconds\n",
            "Detected entities: {'names': 'PERSON', 'emails': 'URL', 'phone': 'PHONE_NUMBER', 'credit': 'US_BANK_NUMBER', 'url': 'URL', 'location': 'LOCATION', 'company': 'ORG'}\n",
            "\n",
            "⏳ Execution time mask_dataframe: 0.005189 seconds\n",
            "\n",
            "⏳ Execution time unmask_dataframe: 0.004125 seconds\n",
            "\n",
            "📊 Are files identical? ❌ No\n",
            "⚠️ The restored file does not match the original. Investigate the mapping or masking logic.\n",
            "\n",
            "⏳ Execution time compare_files: 0.007497 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Code - Testing comments :- Main Code\n",
        "import re\n",
        "import os\n",
        "import gzip\n",
        "import time\n",
        "import json\n",
        "import spacy\n",
        "import string\n",
        "import random\n",
        "import tempfile\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, deque\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "\n",
        "# Variable defined\n",
        "ID, fake_data, used_urls, entity_columns  = {}, {}, set(), {}\n",
        "COMMENT_KEYWORDS = ['comments', 'description', 'remarks', 'note', 'feedback', 'observation']\n",
        "\n",
        "url_extensions = [\n",
        "    \".com\", \".net\", \".org\", \".edu\", \".gov\", \".co\", \".us\", \".uk\", \".in\", \".ru\",\n",
        "    \".jp\", \".cn\", \".de\", \".fr\", \".it\", \".nl\", \".es\", \".br\", \".au\", \".ca\",\n",
        "    \".ch\", \".se\", \".no\", \".za\", \".mx\", \".ar\", \".be\", \".kr\", \".pl\", \".tr\",\n",
        "    \".ua\", \".ir\", \".sa\", \".ae\", \".my\", \".sg\", \".hk\", \".tw\", \".nz\", \".id\",\n",
        "    \".th\", \".ph\", \".vn\", \".bd\", \".lk\", \".np\", \".pk\", \".cz\", \".gr\", \".hu\",\n",
        "    \".fi\", \".dk\", \".il\", \".ie\", \".pt\", \".sk\", \".si\", \".ro\", \".bg\", \".rs\",\n",
        "    \".lt\", \".lv\", \".ee\", \".hr\", \".ba\", \".md\", \".ge\", \".kz\", \".by\", \".tm\",\n",
        "    \".uz\", \".af\", \".qa\", \".om\", \".kw\", \".bh\", \".ye\", \".jo\", \".lb\", \".sy\",\n",
        "    \".iq\", \".ps\", \".az\", \".am\", \".kg\", \".mn\", \".bt\", \".mv\", \".mm\", \".kh\",\n",
        "    \".la\", \".tl\", \".sb\", \".fj\", \".pg\", \".to\", \".tv\", \".ws\", \".fm\", \".ki\"\n",
        "]\n",
        "with open(\"test.json\", \"r\", ) as f: fake_data_list = json.load(f)\n",
        "# Objects\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "fake=Faker()\n",
        "analyzer = AnalyzerEngine()\n",
        "\n",
        "for data in fake_data_list:\n",
        "    for key,value in data.items(): fake_data[key]=deque(value)\n",
        "domain_pool = list(fake_data.get('url', deque()))\n",
        "\n",
        "entity_mapping={\n",
        "    'names':'PERSON',\n",
        "    'emails':'EMAIL_ADDRESS',\n",
        "    'phone':'PHONE_NUMBER',\n",
        "    'location':'LOCATION',\n",
        "    'credit':'CREDIT_CARD',\n",
        "    'url':'URL',\n",
        "    'country':'COUNTRY',\n",
        "    'company':\"ORG\",\n",
        "    'id':'ID',\n",
        "}\n",
        "\n",
        "mapping_file=\"mapping.json\"\n",
        "forward_mapping=defaultdict(dict)\n",
        "reverse_mapping=defaultdict(dict)\n",
        "\n",
        "if os.path.exists(mapping_file):\n",
        "    with open(mapping_file, \"r\") as f:\n",
        "        mapping_data = json.load(f)\n",
        "        forward_mapping.update(mapping_data.get(\"forward_mapping\", {}))\n",
        "        reverse_mapping.update(mapping_data.get(\"reverse_mapping\", {}))\n",
        "\n",
        "# To track time\n",
        "def time_it(func):\n",
        "    \"\"\"Decorator to measure execution time of functions.\"\"\"\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f'\\n⏳ Execution time {func.__name__}: {end-start:.6f} seconds')\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "# For comments logic\n",
        "def get_comment_columns(df):\n",
        "    return [col for col in df.columns if any(kw in col.lower() for kw in COMMENT_KEYWORDS)]\n",
        "\n",
        "@time_it\n",
        "def mask_comment_columns(df, mapping):\n",
        "    comment_cols = get_comment_columns(df)\n",
        "    print('Inside mask comment cols:', comment_cols)\n",
        "    for col in comment_cols:\n",
        "        df[col] = df[col].astype(str).apply(lambda x: mask_comment_text(x, mapping))\n",
        "    return df\n",
        "\n",
        "def mask_comment_text(text, mapping):\n",
        "    if not text.strip():\n",
        "        return text\n",
        "    doc = nlp(text)\n",
        "    modified_text = text\n",
        "    for token in doc:\n",
        "        if token.pos_ == \"PROPN\" or token.ent_type_:\n",
        "            mapped_value = mapping['names'].get(token.text, token.text)\n",
        "            if mapped_value:\n",
        "              modified_text = re.sub(\n",
        "                rf\"\\b{re.escape(token.text)}(?=[\\W_]|$)\", mapped_value, modified_text\n",
        "            )\n",
        "\n",
        "    return modified_text\n",
        "\n",
        "def unmask_comment_text(text, reverse_mapping):\n",
        "    if not text.strip():\n",
        "        return text\n",
        "\n",
        "    doc = nlp(text)\n",
        "    replacements = {}  # Collect replacements first\n",
        "\n",
        "    for token in doc:\n",
        "        if token.pos_ == \"PROPN\" or token.ent_type_:\n",
        "            original_value = reverse_mapping['names'].get(token.text, token.text)\n",
        "            if original_value:\n",
        "                replacements[token.text] = original_value\n",
        "\n",
        "    for fake_token, real_token in replacements.items():\n",
        "        text = re.sub(\n",
        "            rf\"\\b{re.escape(fake_token)}(?=[\\W_]|$)\", real_token, text\n",
        "        )\n",
        "\n",
        "    return text\n",
        "\n",
        "@time_it\n",
        "def analyze_column(df):\n",
        "    # Step 1: Use Presidio to analyze all columns\n",
        "    comment_cols = get_comment_columns(df)\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col in comment_cols: continue\n",
        "\n",
        "        if 'id' in col.lower():\n",
        "            entity_columns[col] = 'ID'\n",
        "        elif 'country' in col.lower():\n",
        "            entity_columns[col] = 'COUNTRY'\n",
        "        else:\n",
        "            unique_values = df[col].dropna().astype(str).unique()[:25]\n",
        "            entity_counts = {}\n",
        "\n",
        "            for value in unique_values:\n",
        "                results = analyzer.analyze(text=value, language='en')\n",
        "                for result in results:\n",
        "                    entity_counts[result.entity_type] = entity_counts.get(result.entity_type, 0) + 1\n",
        "\n",
        "            if entity_counts:\n",
        "                predominant_entity = max(entity_counts, key=entity_counts.get)\n",
        "                entity_columns[col] = predominant_entity\n",
        "                if predominant_entity==\"LOCATION\":\n",
        "                  org_count=0\n",
        "                  for value in unique_values:\n",
        "                    doc=nlp(value)\n",
        "                    for ent in doc.ents:\n",
        "                      if ent.label_==\"ORG\":\n",
        "                        org_count+=1\n",
        "                  if org_count>5:\n",
        "                    predominant_entity=\"ORG\"\n",
        "                entity_columns[col]=predominant_entity\n",
        "\n",
        "    # Step 2: Use SpaCy to analyze non-numeric and unclassified columns\n",
        "    for col in df.select_dtypes(exclude=['number']).columns:\n",
        "        if col not in entity_columns:\n",
        "            unique_values = df[col].dropna().astype(str).unique()[:25]\n",
        "            org_count = 0\n",
        "\n",
        "            for value in unique_values:\n",
        "                doc = nlp(value)\n",
        "                for ent in doc.ents:\n",
        "                    if ent.label_ == 'ORG':\n",
        "                        org_count += 1\n",
        "\n",
        "            # If more than half of the sample values are ORG, classify as ORG\n",
        "            if org_count > 12:\n",
        "                entity_columns[col] = 'ORG'\n",
        "\n",
        "    return entity_columns\n",
        "\n",
        "def modify_fake_value(category, base_fake_value, counter):\n",
        "    if category == \"names\": return f\"{base_fake_value}{string.ascii_lowercase[counter % 26]}\"\n",
        "    elif category == \"emails\":\n",
        "        name, domain = base_fake_value.split(\"@\")\n",
        "        return f\"{name}{counter}@{domain}\"\n",
        "    elif category in {\"location\", \"country\"}: return f\"{base_fake_value}, District {counter % 100_000_000 + 1}\"\n",
        "    elif category == \"url\":\n",
        "        # Check if the URL already exists, if so, append a country extension\n",
        "        fake_value = base_fake_value\n",
        "        while fake_value in used_urls:\n",
        "            ext = random.choice(url_extensions)\n",
        "            if not fake_value.endswith(ext):\n",
        "                fake_value += ext\n",
        "        used_urls.add(fake_value)\n",
        "        return fake_value\n",
        "    elif category == \"phone\": return f\"{base_fake_value[:-2]}{counter % 100:02d}\"\n",
        "    elif category == \"company\": return f\"{base_fake_value} Group {counter % 100_000_000 + 1}\"\n",
        "    elif category == \"credit\": return f\"{base_fake_value[:-4]}{counter % 10000:04d}\"\n",
        "    else: return f\"{base_fake_value}-{counter}\"\n",
        "\n",
        "\n",
        "def get_fake_value(category, original_value):\n",
        "    global ID\n",
        "    fake_value = None\n",
        "    if category == \"names\":\n",
        "        original_tokens = str(original_value).split()\n",
        "        fake_tokens = []\n",
        "        used_fake_names = set(reverse_mapping[category])\n",
        "\n",
        "        for token in original_tokens:\n",
        "            if token in forward_mapping[category]:\n",
        "                fake_token = forward_mapping[category][token]\n",
        "            else:\n",
        "                fake_token = None\n",
        "\n",
        "                if fake_data.get(category):\n",
        "                    for _ in range(len(fake_data[category])):\n",
        "                        candidate = fake_data[category].popleft()\n",
        "                        fake_data[category].append(candidate)\n",
        "\n",
        "                        if candidate not in used_fake_names and candidate != token:\n",
        "                            fake_token = candidate\n",
        "                            break\n",
        "                        else:\n",
        "                            # Modify it if already used\n",
        "                            counter = 0\n",
        "                            base = candidate\n",
        "                            while True:\n",
        "                                modified = modify_fake_value(category, base, counter)\n",
        "                                if modified not in used_fake_names and modified != token:\n",
        "                                    fake_token = modified\n",
        "                                    break\n",
        "                                counter += 1\n",
        "                            break  # once we found a modified one, skip the rest\n",
        "\n",
        "                # Absolute fallback: no fake_data or nothing worked\n",
        "                if not fake_token:\n",
        "                    counter = 0\n",
        "                    base_pool = list(used_fake_names)\n",
        "                    random.shuffle(base_pool)\n",
        "\n",
        "                    for base in base_pool[:10]:  # Try 10\n",
        "                        fake_token = modify_fake_value(category, base, counter)\n",
        "                        if fake_token not in used_fake_names and fake_token != token:\n",
        "                            break\n",
        "                        counter += 1\n",
        "                    else:\n",
        "                        # Final fallback: just keep modifying the original token\n",
        "                        while True:\n",
        "                            fake_token = modify_fake_value(category, token, counter)\n",
        "                            if fake_token not in used_fake_names:\n",
        "                                break\n",
        "                            counter += 1\n",
        "\n",
        "                # Save mappings\n",
        "                forward_mapping[category][token] = fake_token\n",
        "                reverse_mapping[category][fake_token] = token\n",
        "                used_fake_names.add(fake_token)\n",
        "\n",
        "            fake_tokens.append(fake_token)\n",
        "\n",
        "        return \" \".join(fake_tokens)\n",
        "\n",
        "\n",
        "\n",
        "    if original_value in forward_mapping[category]: return forward_mapping[category][original_value]\n",
        "    # Special case for ID\n",
        "    if category == 'id':\n",
        "        length = 6\n",
        "        while True:\n",
        "            fake_value = fake.bothify(text=f'ID-{\"#\"*length}')\n",
        "            if fake_value not in ID:\n",
        "                ID[fake_value] = True\n",
        "                break\n",
        "            if len(ID) >= 10 ** length: length += 1\n",
        "    elif category == 'url':\n",
        "        domain1, domain2 = random.sample(domain_pool, 2)\n",
        "        base_fake_value = f\"https://{domain1.lower()}/{domain2.lower()}.co\"\n",
        "\n",
        "        if base_fake_value not in reverse_mapping[\"url\"]:\n",
        "            fake_value = base_fake_value\n",
        "        else:\n",
        "            counter = len(reverse_mapping[\"url\"])\n",
        "            fake_value = modify_fake_value(\"url\", base_fake_value, counter)\n",
        "\n",
        "    elif fake_data.get(category):\n",
        "      length = len(fake_data[category])\n",
        "      for _ in range(length):\n",
        "            candidate = fake_data[category].popleft()\n",
        "            fake_data[category].append(candidate)  # Reinsert at end (rotation)\n",
        "            if candidate not in reverse_mapping[category]:\n",
        "                fake_value = candidate\n",
        "                break\n",
        "      else:\n",
        "          counter = len(reverse_mapping[category])\n",
        "          base_fake_value = (\n",
        "              random.choice(list(reverse_mapping[category]))\n",
        "              if reverse_mapping[category]\n",
        "              else f\"{category}_\"\n",
        "          )\n",
        "          fake_value = modify_fake_value(category, base_fake_value, counter)\n",
        "\n",
        "    if not fake_value or fake_value in reverse_mapping[category]:\n",
        "        counter = len(reverse_mapping[category])\n",
        "        base = fake_value if fake_value else f\"{category}_\"\n",
        "        fake_value = modify_fake_value(category, base, counter)\n",
        "\n",
        "    # Store forward & reverse mappings\n",
        "    forward_mapping[category][original_value] = fake_value\n",
        "    reverse_mapping[category][fake_value] = original_value\n",
        "\n",
        "    return fake_value\n",
        "\n",
        "\n",
        "@time_it\n",
        "def mask_dataframe(df):\n",
        "    for col, entity in entity_columns.items():\n",
        "        matching_keys = [\n",
        "            key for key, value in entity_mapping.items() if value == entity\n",
        "        ]\n",
        "        if matching_keys:\n",
        "            category = matching_keys[0]\n",
        "            df[col] = df[col].astype(str).apply(\n",
        "                lambda x: get_fake_value(category, x) if x else x\n",
        "            )\n",
        "    return df\n",
        "\n",
        "\n",
        "def restore_original_value(category, fake_value):\n",
        "    return reverse_mapping[category].get(fake_value, fake_value)\n",
        "\n",
        "@time_it\n",
        "def unmask_dataframe(df):\n",
        "    for col, entity in entity_columns.items():\n",
        "        matching_keys = [key for key, value in entity_mapping.items() if value == entity]\n",
        "        if matching_keys:\n",
        "            category = matching_keys[0]\n",
        "\n",
        "            if category == \"names\":\n",
        "                def reverse_name(val):\n",
        "                    tokens = str(val).split()\n",
        "                    original_tokens = [reverse_mapping[category].get(tok, tok) for tok in tokens]\n",
        "                    return \" \".join(original_tokens)\n",
        "                df[col] = df[col].astype(str).apply(lambda x: reverse_name(x) if pd.notna(x) else x)\n",
        "\n",
        "            else:\n",
        "                df[col] = df[col].astype(str).apply(\n",
        "                    lambda x: restore_original_value(category, str(x)) if pd.notna(str(x)) else x\n",
        "                )\n",
        "    comment_cols = get_comment_columns(df)\n",
        "    for col in comment_cols:\n",
        "        df[col] = df[col].astype(str).apply(lambda x: unmask_comment_text(x, reverse_mapping))\n",
        "    return df\n",
        "\n",
        "@time_it\n",
        "def compare_files(original_csv, restored_csv):\n",
        "    \"\"\"Compare two CSV files and return if they are identical.\"\"\"\n",
        "    original_df = pd.read_csv(original_csv, dtype=str).sort_index(axis=1).reset_index(drop=True)\n",
        "    restored_df = pd.read_csv(restored_csv, dtype=str).sort_index(axis=1).reset_index(drop=True)\n",
        "\n",
        "    is_identical = original_df.equals(restored_df)\n",
        "    print(f\"\\n📊 Are files identical? {'✅ Yes' if is_identical else '❌ No'}\")\n",
        "\n",
        "    if not is_identical:\n",
        "        print(\"⚠️ The restored file does not match the original. Investigate the mapping or masking logic.\")\n",
        "\n",
        "    return is_identical\n",
        "\n",
        "def de_anonymize_paragraph(text):\n",
        "  for category,mapping in reverse_mapping.items():\n",
        "    for fake_value,original_value in mapping.items():\n",
        "      if fake_value in text:\n",
        "        text=text.replace(fake_value,original_value)\n",
        "  return text\n",
        "\n",
        "def save_mapping(filename):\n",
        "    mapping_data={\n",
        "        \"filename\":filename,\n",
        "        \"updated_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
        "        \"forward_mapping\":forward_mapping,\n",
        "        \"reverse_mapping\":reverse_mapping\n",
        "    }\n",
        "    with open(mapping_file, \"a\") as f:\n",
        "        json.dump(mapping_data, f, indent=4)\n",
        "\n",
        "def process_file(input_file, file_ext):\n",
        "    input_base = os.path.splitext(os.path.basename(input_file))[0]\n",
        "    output_dir = os.path.join(\".\", input_base)\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    if file_ext == \".xlsx\":\n",
        "        xl = pd.read_excel(input_file, sheet_name=None, dtype=str, engine='openpyxl')\n",
        "\n",
        "        for sheet_name, df in xl.items():\n",
        "            print(f\"\\n🔍 Processing sheet: {sheet_name}\")\n",
        "\n",
        "            original_csv = os.path.join(output_dir, f\"{sheet_name}_original.csv\")\n",
        "            masked_csv = os.path.join(output_dir, f\"{sheet_name}_masked.csv\")\n",
        "            restored_csv = os.path.join(output_dir, f\"{sheet_name}_restored.csv\")\n",
        "\n",
        "            df.to_csv(original_csv, index=False)\n",
        "\n",
        "            entity_columns = analyze_column(df)\n",
        "            print(f\"Detected entities: {entity_columns}\")\n",
        "\n",
        "            masked_df = mask_dataframe(df.copy())\n",
        "            masked_df = mask_comment_columns(masked_df, forward_mapping)\n",
        "            restored_df = unmask_dataframe(masked_df.copy())\n",
        "\n",
        "            masked_df.to_csv(masked_csv, index=False)\n",
        "            restored_df.to_csv(restored_csv, index=False)\n",
        "\n",
        "            compare_files(original_csv, restored_csv)\n",
        "\n",
        "            save_mapping(f'{input_file}-->{sheet_name}')\n",
        "            entity_columns.clear()\n",
        "\n",
        "\n",
        "    elif file_ext == \".csv\":\n",
        "        df = pd.read_csv(input_file, dtype=str, low_memory=False)\n",
        "        print(f\"\\n🔍 Processing CSV: {input_file}\")\n",
        "\n",
        "        original_csv = os.path.join(output_dir, \"original.csv\")\n",
        "        masked_csv = os.path.join(output_dir, \"anonymized.csv\")\n",
        "        restored_csv = os.path.join(output_dir, \"restored.csv\")\n",
        "\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        df.to_csv(original_csv, index=False)\n",
        "\n",
        "        entity_columns = analyze_column(df)\n",
        "        print(f\"Detected entities: {entity_columns}\")\n",
        "\n",
        "        masked_df = mask_dataframe(df.copy())\n",
        "        masked_df = mask_comment_columns(masked_df, forward_mapping)\n",
        "        restored_df = unmask_dataframe(masked_df.copy())\n",
        "\n",
        "        masked_df.to_csv(masked_csv, index=False)\n",
        "        restored_df.to_csv(restored_csv, index=False)\n",
        "\n",
        "        compare_files(original_csv, restored_csv)\n",
        "\n",
        "        save_mapping(input_file)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type. Use .csv or .xlsx only.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_file = \"for_colab_test.csv\"\n",
        "    file_ext = os.path.splitext(input_file)[-1].lower()\n",
        "    process_file(input_file, file_ext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiDZBLIeLEQf",
        "outputId": "d179c4fc-d0b8-4f73-e148-18515e36b728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Processing CSV: for_colab_test.csv\n",
            "\n",
            "⏳ Execution time analyze_column: 1.643175 seconds\n",
            "Detected entities: {'names': 'PERSON', 'emails': 'URL', 'phone': 'PHONE_NUMBER', 'credit': 'US_BANK_NUMBER', 'url': 'URL', 'location': 'LOCATION', 'company': 'ORG'}\n",
            "\n",
            "⏳ Execution time mask_dataframe: 0.004188 seconds\n",
            "Inside mask comment cols: ['comments']\n",
            "\n",
            "⏳ Execution time mask_comment_columns: 0.480729 seconds\n",
            "\n",
            "⏳ Execution time unmask_dataframe: 0.442396 seconds\n",
            "\n",
            "📊 Are files identical? ❌ No\n",
            "⚠️ The restored file does not match the original. Investigate the mapping or masking logic.\n",
            "\n",
            "⏳ Execution time compare_files: 0.005113 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing different mapping technique\n",
        "# Testing - classify orgainization\n",
        "# Problematic -> can't use to demask paragraph\n",
        "import re\n",
        "import os\n",
        "import gzip\n",
        "import time\n",
        "import json\n",
        "import spacy\n",
        "import string\n",
        "import random\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "from collections import defaultdict, deque\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "\n",
        "\n",
        "ID = {}\n",
        "fake_data={}\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "fake=Faker()\n",
        "analyzer = AnalyzerEngine()\n",
        "\n",
        "with gzip.open(\"faker_data.json.gz\", \"rt\", encoding='utf-8') as f:\n",
        "    fake_data_list = json.load(f)\n",
        "for data in fake_data_list:\n",
        "    for key,value in data.items():\n",
        "        fake_data[key]=deque(value)\n",
        "\n",
        "entity_mapping={\n",
        "    'names':'PERSON',\n",
        "    'emails':'EMAIL_ADDRESS',\n",
        "    'phone':'PHONE_NUMBER',\n",
        "    'location':'LOCATION',\n",
        "    'credit':'CREDIT_CARD',\n",
        "    'url':'URL',\n",
        "    'country':'COUNTRY',\n",
        "    'company':\"ORG\",\n",
        "    'id':'ID',\n",
        "}\n",
        "\n",
        "mapping_file=\"mapping.json\"\n",
        "forward_mapping=defaultdict(dict)\n",
        "reverse_mapping=defaultdict(dict)\n",
        "\n",
        "if os.path.exists(mapping_file):\n",
        "    with open(mapping_file, \"r\") as f:\n",
        "        mapping_data = json.load(f)\n",
        "        forward_mapping.update(mapping_data.get(\"forward_mapping\", {}))\n",
        "        reverse_mapping.update(mapping_data.get(\"reverse_mapping\", {}))\n",
        "def time_it(func):\n",
        "    \"\"\"Decorator to measure execution time of functions.\"\"\"\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f'\\n⏳ Execution time {func.__name__}: {end-start:.6f} seconds')\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "@time_it\n",
        "def analyze_column(df):\n",
        "    entity_columns = {}\n",
        "\n",
        "    # Step 1: Use Presidio to analyze all columns\n",
        "    for col in df.columns:\n",
        "        if 'id' in col.lower():\n",
        "            entity_columns[col] = 'ID'\n",
        "        elif 'country' in col.lower():\n",
        "            entity_columns[col] = 'COUNTRY'\n",
        "        else:\n",
        "            unique_values = df[col].dropna().astype(str).unique()[:25]\n",
        "            entity_counts = {}\n",
        "\n",
        "            for value in unique_values:\n",
        "                results = analyzer.analyze(text=value, language='en')\n",
        "                for result in results:\n",
        "                    entity_counts[result.entity_type] = entity_counts.get(result.entity_type, 0) + 1\n",
        "\n",
        "            if entity_counts:\n",
        "                predominant_entity = max(entity_counts, key=entity_counts.get)\n",
        "                entity_columns[col] = predominant_entity\n",
        "                if predominant_entity==\"LOCATION\":\n",
        "                  org_count=0\n",
        "                  for value in unique_values:\n",
        "                    doc=nlp(value)\n",
        "                    for ent in doc.ents:\n",
        "                      if ent.label_==\"ORG\":\n",
        "                        org_count+=1\n",
        "                  if org_count>5:\n",
        "                    predominant_entity=\"ORG\"\n",
        "                entity_columns[col]=predominant_entity\n",
        "\n",
        "    # Step 2: Use SpaCy to analyze non-numeric and unclassified columns\n",
        "    for col in df.select_dtypes(exclude=['number']).columns:\n",
        "        if col not in entity_columns:\n",
        "            unique_values = df[col].dropna().astype(str).unique()[:25]\n",
        "            org_count = 0\n",
        "\n",
        "            for value in unique_values:\n",
        "                doc = nlp(value)\n",
        "                for ent in doc.ents:\n",
        "                    if ent.label_ == 'ORG':\n",
        "                        org_count += 1\n",
        "\n",
        "            # If more than half of the sample values are ORG, classify as ORG\n",
        "            if org_count > 12:\n",
        "                entity_columns[col] = 'ORG'\n",
        "\n",
        "    return entity_columns\n",
        "\n",
        "\n",
        "def modify_fake_value(category, base_fake_value, counter):\n",
        "    if category == \"names\": return f\"{base_fake_value} {string.ascii_uppercase[counter % 26]}.\"\n",
        "    elif category == \"emails\":\n",
        "        name, domain = base_fake_value.split(\"@\")\n",
        "        return f\"{name}{counter}@{domain}\"\n",
        "    elif category == \"location\": return f\"{base_fake_value}, District {counter % 100_000_000 + 1}\"\n",
        "    elif category == \"url\": return base_fake_value.replace(\"://\", f\"://sub{counter}.\", 1)\n",
        "    elif category == \"phone\": return f\"{base_fake_value[:-2]}{counter % 100:02d}\"\n",
        "    elif category == \"company\": return f\"{base_fake_value} Group {counter % 50}\"\n",
        "    elif category == \"credit\": return f\"{base_fake_value[:-4]}{counter % 10000:04d}\"\n",
        "    else: return f\"{base_fake_value}-{counter}\"\n",
        "\n",
        "\n",
        "def get_fake_value(category, original_value, colname):\n",
        "    global ID\n",
        "    # Added\n",
        "    if colname not in forward_mapping[category]: forward_mapping[category][colname] = {}\n",
        "    if colname not in reverse_mapping[category]: reverse_mapping[category][colname] = {}\n",
        "    if colname in forward_mapping[category] and original_value in forward_mapping[category][colname]:\n",
        "      return forward_mapping[category][colname][original_value]\n",
        "\n",
        "    if category == 'id':\n",
        "      length = 6\n",
        "      while True:\n",
        "          fake_value = fake.bothify(text=f'ID-{\"#\"*length}')\n",
        "          if fake_value not in ID:\n",
        "              ID[fake_value] = True\n",
        "              break\n",
        "          # If exhausted all possibilities for the current length, increase the length\n",
        "          if len(ID) >= 10 ** length:\n",
        "              length += 1\n",
        "    elif fake_data.get(category):\n",
        "        fake_value = fake_data[category].pop() if fake_data[category] else None\n",
        "    else:\n",
        "        base_fake=random.choice(list(forward_mapping[category][colname].values()))\n",
        "        if base_fake:\n",
        "          counter=len(forward_mapping[category][colname])\n",
        "          fake_value=modify_fake_value(category,base_fake,counter)\n",
        "\n",
        "    forward_mapping[category][colname][original_value] = fake_value\n",
        "    reverse_mapping[category][colname][fake_value] = original_value\n",
        "\n",
        "\n",
        "    return fake_value\n",
        "\n",
        "@time_it\n",
        "def mask_dataframe(df):\n",
        "    for col, entity in entity_columns.items():\n",
        "        matching_keys = [key for key, value in entity_mapping.items() if value == entity]\n",
        "        if matching_keys:\n",
        "            df[col] = df[col].astype(str).apply(lambda x: get_fake_value(matching_keys[0], str(x), col) if x else str(x))\n",
        "    return df\n",
        "\n",
        "def restore_original_value(category, fake_value, colname):\n",
        "    if colname in reverse_mapping[category]:\n",
        "      return reverse_mapping[category][colname].get(fake_value, fake_value)\n",
        "    return fake_value\n",
        "\n",
        "@time_it\n",
        "def unmask_dataframe(df):\n",
        "    for col, entity in entity_columns.items():\n",
        "        matching_keys = [key for key, value in entity_mapping.items() if value == entity]\n",
        "\n",
        "        if matching_keys:\n",
        "            category = matching_keys[0]\n",
        "            df[col] = df[col].astype(str).apply(lambda x: restore_original_value(category, str(x), col) if x else str(x))\n",
        "\n",
        "    return df\n",
        "def compare_files(original_file, restored_file):\n",
        "    \"\"\"Check if the original and restored files are identical.\"\"\"\n",
        "    file_ext = os.path.splitext(original_file)[-1].lower()\n",
        "    original_df = pd.read_excel(original_file) if file_ext == \".xlsx\" else pd.read_csv(original_file)\n",
        "    restored_df = pd.read_excel(restored_file) if file_ext == \".xlsx\" else pd.read_csv(restored_file)\n",
        "\n",
        "    is_identical = original_df.equals(restored_df)\n",
        "    print(f\"📊 Are files identical? {'✅ Yes' if is_identical else '❌ No'}\")\n",
        "    if not is_identical:\n",
        "        print(\"⚠️ The restored file does not match the original. There may be an issue with the mapping.\")\n",
        "\n",
        "    return is_identical\n",
        "\n",
        "def de_anonymize_paragraph(text):\n",
        "  for category, col_map in reverse_mapping.items():\n",
        "    for colname, mapping in col_map.items():\n",
        "        for fake_value, original_value in mapping.items():\n",
        "            if fake_value in text:\n",
        "                text = text.replace(fake_value, original_value)\n",
        "  return text\n",
        "\n",
        "def save_mapping(filename):\n",
        "    mapping_data={\n",
        "        \"filename\":filename,\n",
        "        \"updated_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
        "        \"forward_mapping\":dict(forward_mapping),\n",
        "        \"reverse_mapping\":dict(reverse_mapping)\n",
        "    }\n",
        "    with open(mapping_file, \"w\") as f:\n",
        "        json.dump(mapping_data, f, indent=4)\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    input_file=\"smaller_100k_companies.csv\"\n",
        "    file_ext=os.path.splitext(input_file)[-1].lower()\n",
        "\n",
        "    df = pd.read_excel(input_file, dtype=str) if file_ext == \".xlsx\" else pd.read_csv(input_file, dtype=str, low_memory=False)\n",
        "    entity_columns=analyze_column(df)\n",
        "    print(entity_columns)\n",
        "\n",
        "    anonymized_df=mask_dataframe(df)\n",
        "    output_file=\"anonymized.xlsx\" if file_ext==\".xlsx\" else \"anonymized.csv\"\n",
        "    anonymized_df.to_excel(output_file,index=False) if file_ext==\".xlsx\" else anonymized_df.to_csv(output_file,index=False)\n",
        "    print(f\"✅ Anonymized data saved as {output_file}\")\n",
        "\n",
        "    save_mapping(input_file)\n",
        "    restored_df=unmask_dataframe(pd.read_excel(output_file) if file_ext==\".xlsx\" else pd.read_csv(output_file))\n",
        "    restored_file=\"restored.xlsx\" if file_ext==\".xlsx\" else \"restored.csv\"\n",
        "    restored_df.to_excel(restored_file,index=False) if file_ext==\".xlsx\" else restored_df.to_csv(restored_file,index=False)\n",
        "    print(f\"✅ Restored data saved as {restored_file}\")\n",
        "    compare_files(input_file, restored_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLSBTwDt3ndb",
        "outputId": "747f1373-034f-4ab6-ed00-3edd20f8f0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏳ Execution time analyze_column: 3.097933 seconds\n",
            "{'id': 'ID', 'name': 'ORG', 'domain': 'URL', 'size range': 'DATE_TIME', 'locality': 'LOCATION', 'country': 'COUNTRY', 'linkedin url': 'URL', 'current employee estimate': 'US_DRIVER_LICENSE', 'total employee estimate': 'US_DRIVER_LICENSE'}\n",
            "\n",
            "⏳ Execution time mask_dataframe: 2.705842 seconds\n",
            "✅ Anonymized data saved as anonymized.csv\n",
            "\n",
            "⏳ Execution time unmask_dataframe: 0.398932 seconds\n",
            "✅ Restored data saved as restored.csv\n",
            "📊 Are files identical? ✅ Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Generating fake names and emails and comparing them\"\"\"\n",
        "from itertools import count\n",
        "import json\n",
        "import faker\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "fake = faker.Faker()\n",
        "\n",
        "def generate_fake_names():\n",
        "    unique_names = set()\n",
        "\n",
        "    for _ in range(500_000):\n",
        "        fake_name = fake.name()\n",
        "        if fake_name in unique_names: fake_name += f' {fake.name()}'\n",
        "        unique_names.add(fake_name)\n",
        "\n",
        "    with open('fake_names.json', 'w') as fp:\n",
        "        json.dump(\n",
        "            {\n",
        "                'names': list(unique_names)\n",
        "            },\n",
        "            fp,\n",
        "            indent=4\n",
        "        )\n",
        "    print('📈Done generating fake names!')\n",
        "\n",
        "def generate_fake_email():\n",
        "    unique_emails = set()\n",
        "    mail_endings = [\n",
        "                    'gmail.com', 'hotmail.com',\n",
        "                    'yahoo.com', 'outlook.com',\n",
        "                    'live.com', 'yandex.com',\n",
        "                    'mail.com', 'aol.com', 'edu.com'\n",
        "                ]\n",
        "    for _ in range(500_000):\n",
        "        fake_email = fake.email()\n",
        "        while fake_email in unique_emails:\n",
        "            body, domain = fake_email.split('@')\n",
        "            fake_email = f'{body}.{fake.name().replace(\" \", \".\")}.{fake.bothify(text=\"#####\")}@{random.choice(mail_endings)}'\n",
        "        unique_emails.add(fake_email)\n",
        "\n",
        "    with open('fake_emails.json', 'w') as fp:\n",
        "        json.dump(\n",
        "            {\n",
        "                'emails': list(unique_emails),\n",
        "            },\n",
        "            fp,\n",
        "            indent=4\n",
        "        )\n",
        "\n",
        "def find_repeating_values():\n",
        "    file_name = 'fake_emails.json'\n",
        "    with open(file_name, 'r') as fp:\n",
        "        data = json.load(fp)\n",
        "\n",
        "    values = data.get('emails', []) or data.get('names', [])\n",
        "\n",
        "    counts = Counter(values)\n",
        "    repeating_values = {item:count for item, count in counts.items() if count > 1}\n",
        "\n",
        "    print(f'Repeating values:{len(repeating_values)}')\n",
        "\n",
        "# find_repeating_values()\n",
        "# generate_fake_email()\n",
        "# generate_fake_names()"
      ],
      "metadata": {
        "id": "cQL6pAoW6SlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy\n",
        "json_data = {\n",
        "    \"name\": \"James Bat Bond\",\n",
        "    \"email\":[ \"jamesbatbond@ust.com\", 'kirant700@gmail.com', '12312@ust.com'],\n",
        "    \"backup_email\": \"b20cs110@mace.ac.in\",\n",
        "    \"phone\": \"+973 30982167\",\n",
        "    \"location\": \"Wakanda, Africa\",\n",
        "    \"description\": \"Abram is a software engineer from Wakanda.\",\n",
        "    \"metadata\": {\n",
        "        \"emergency_contact\": \"+91 9678785654\",\n",
        "        \"company\": \"UST Global\",\n",
        "        \"address\": {\n",
        "            \"city\": \"New York\",\n",
        "            \"country\": \"USA\"\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "eTCcJL5ba6oC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploading json file and doing NER on attributes\n",
        "import json\n",
        "import time\n",
        "from google.colab import files\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "\n",
        "analyzer = AnalyzerEngine()\n",
        "anonymizer = AnonymizerEngine()\n",
        "\n",
        "def time_it(func):\n",
        "  def wrapper(*args, **kwargs):\n",
        "    start = time.time()\n",
        "    result = func(*args, **kwargs)\n",
        "    end = time.time()\n",
        "    print(f'\\n⏳ Execution time {func.__name__}: {end-start:.6f} seconds')\n",
        "    return result\n",
        "  return wrapper\n",
        "\n",
        "# Processing JSON Spacey\n",
        "def processing_json(data):\n",
        "  if isinstance(data, dict):\n",
        "    return {key: processing_json(value) for key, value in data.items()}\n",
        "  elif isinstance(data, list):\n",
        "    return [processing_json(item) for item in data]\n",
        "  elif isinstance(data, str):\n",
        "    result = analyzer.analyze(\n",
        "        text = data,\n",
        "        entities = ['PHONE_NUMBER', 'ADDRESS', 'LOCATION', 'PERSON', 'EMAIL_ADDRESS', 'STREET_ADDRESS', 'CREDIT_CARD'],\n",
        "        language = 'en'\n",
        "    )\n",
        "    return anonymizer.anonymize(text=data, analyzer_results=result).text if result else data\n",
        "  else: return data\n",
        "\n",
        "@time_it\n",
        "def json_format_anonymized(json_data):\n",
        "  processed_data = processing_json(json_data)\n",
        "  print(json.dumps(processed_data, indent = 4))\n",
        "\n",
        "def json_file_anonymized():\n",
        "  file_upload = files.upload()\n",
        "  for filename in file_upload.keys():\n",
        "    if filename.endswith('.json'):\n",
        "      with open(filename, 'r') as fp:\n",
        "        json_data = json.load(fp)\n",
        "        processing_json(json_data)\n",
        "\n",
        "json_format_anonymized(json_data)"
      ],
      "metadata": {
        "id": "zBbEaJWOan9E",
        "outputId": "3c9c032d-86a6-4ec1-e461-c0b289d8a663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Entity ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity STREET_ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity STREET_ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity STREET_ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity STREET_ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity STREET_ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity STREET_ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity STREET_ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity STREET_ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity STREET_ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity STREET_ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity STREET_ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity ADDRESS doesn't have the corresponding recognizer in language : en\n",
            "WARNING:presidio-analyzer:Entity STREET_ADDRESS doesn't have the corresponding recognizer in language : en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"<PERSON>\",\n",
            "    \"email\": [\n",
            "        \"<EMAIL_ADDRESS>\",\n",
            "        \"<EMAIL_ADDRESS>\",\n",
            "        \"<EMAIL_ADDRESS>\"\n",
            "    ],\n",
            "    \"backup_email\": \"<EMAIL_ADDRESS>\",\n",
            "    \"phone\": \"<PHONE_NUMBER>\",\n",
            "    \"location\": \"<LOCATION>, <LOCATION>\",\n",
            "    \"description\": \"<PERSON> is a software engineer from <LOCATION>.\",\n",
            "    \"metadata\": {\n",
            "        \"emergency_contact\": \"<PHONE_NUMBER>\",\n",
            "        \"company\": \"UST Global\",\n",
            "        \"address\": {\n",
            "            \"city\": \"<LOCATION>\",\n",
            "            \"country\": \"<LOCATION>\"\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "⏳ Execution time json_format_anonymized: 0.152774 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!pip install presidio_analyzer\n",
        "!python -m spacy download en_core_web_lg\n",
        "!pip install faker pyxlsb fastexcel faker python-calamine\n",
        "!pip install --upgrade --force-reinstall \"Cython\" \"spacy\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aEpVkesIulix",
        "outputId": "12e11a8c-322d-4afa-b465-92e524f7af4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting presidio_analyzer\n",
            "  Downloading presidio_analyzer-2.2.358-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting phonenumbers<9.0.0,>=8.12 (from presidio_analyzer)\n",
            "  Downloading phonenumbers-8.13.55-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (6.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (2024.11.6)\n",
            "Requirement already satisfied: spacy!=3.7.0,<4.0.0,>=3.4.4 in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (3.8.5)\n",
            "Collecting tldextract (from presidio_analyzer)\n",
            "  Downloading tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.15.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.5.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio_analyzer) (3.10)\n",
            "Collecting requests-file>=1.4 (from tldextract->presidio_analyzer)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio_analyzer) (3.18.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.1.2)\n",
            "Downloading presidio_analyzer-2.2.358-py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading phonenumbers-8.13.55-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.3.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: phonenumbers, requests-file, tldextract, presidio_analyzer\n",
            "Successfully installed phonenumbers-8.13.55 presidio_analyzer-2.2.358 requests-file-2.1.0 tldextract-5.3.0\n",
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting faker\n",
            "  Downloading faker-37.3.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pyxlsb\n",
            "  Downloading pyxlsb-1.0.10-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting fastexcel\n",
            "  Downloading fastexcel-0.14.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting python-calamine\n",
            "  Downloading python_calamine-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from fastexcel) (18.1.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from python-calamine) (24.2)\n",
            "Downloading faker-37.3.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyxlsb-1.0.10-py2.py3-none-any.whl (23 kB)\n",
            "Downloading fastexcel-0.14.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_calamine-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (886 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m886.0/886.0 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyxlsb, python-calamine, fastexcel, faker\n",
            "Successfully installed faker-37.3.0 fastexcel-0.14.0 python-calamine-0.3.2 pyxlsb-1.0.10\n",
            "Collecting Cython\n",
            "  Downloading cython-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (30 kB)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.8.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
            "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
            "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
            "  Downloading murmurhash-1.0.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
            "  Downloading cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
            "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
            "  Downloading preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
            "  Downloading thinc-8.3.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
            "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
            "  Downloading srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
            "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
            "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
            "  Downloading typer-0.15.4-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting tqdm<5.0.0,>=4.38.0 (from spacy)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.19.0 (from spacy)\n",
            "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests<3.0.0,>=2.13.0 (from spacy)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
            "  Downloading pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2 (from spacy)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting setuptools (from spacy)\n",
            "  Downloading setuptools-80.7.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting packaging>=20.0 (from spacy)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
            "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
            "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
            "  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting typing-extensions>=4.12.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
            "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3.0.0,>=2.13.0->spacy)\n",
            "  Downloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.13.0->spacy)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.13.0->spacy)\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.13.0->spacy)\n",
            "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
            "  Downloading blis-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
            "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting click<8.2,>=8.0.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
            "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
            "  Downloading cloudpathlib-0.21.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->spacy)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
            "  Downloading marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
            "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading cython-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spacy-3.8.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
            "Downloading cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (218 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.9/218.9 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.0/183.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading murmurhash-1.0.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.2/157.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.9/443.9 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
            "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
            "Downloading srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.15.4-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
            "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.7.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading blis-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.6/159.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.3/147.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpathlib-0.21.1-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: cymem, wrapt, wasabi, urllib3, typing-extensions, tqdm, spacy-loggers, spacy-legacy, shellingham, setuptools, pygments, packaging, numpy, murmurhash, mdurl, MarkupSafe, idna, Cython, cloudpathlib, click, charset-normalizer, certifi, catalogue, annotated-types, typing-inspection, srsly, smart-open, requests, pydantic-core, preshed, markdown-it-py, marisa-trie, jinja2, blis, rich, pydantic, language-data, typer, langcodes, confection, weasel, thinc, spacy\n",
            "  Attempting uninstall: cymem\n",
            "    Found existing installation: cymem 2.0.11\n",
            "    Uninstalling cymem-2.0.11:\n",
            "      Successfully uninstalled cymem-2.0.11\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.3\n",
            "    Uninstalling wasabi-1.1.3:\n",
            "      Successfully uninstalled wasabi-1.1.3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.4.0\n",
            "    Uninstalling urllib3-2.4.0:\n",
            "      Successfully uninstalled urllib3-2.4.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: spacy-loggers\n",
            "    Found existing installation: spacy-loggers 1.0.5\n",
            "    Uninstalling spacy-loggers-1.0.5:\n",
            "      Successfully uninstalled spacy-loggers-1.0.5\n",
            "  Attempting uninstall: spacy-legacy\n",
            "    Found existing installation: spacy-legacy 3.0.12\n",
            "    Uninstalling spacy-legacy-3.0.12:\n",
            "      Successfully uninstalled spacy-legacy-3.0.12\n",
            "  Attempting uninstall: shellingham\n",
            "    Found existing installation: shellingham 1.5.4\n",
            "    Uninstalling shellingham-1.5.4:\n",
            "      Successfully uninstalled shellingham-1.5.4\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.19.1\n",
            "    Uninstalling Pygments-2.19.1:\n",
            "      Successfully uninstalled Pygments-2.19.1\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: murmurhash\n",
            "    Found existing installation: murmurhash 1.0.12\n",
            "    Uninstalling murmurhash-1.0.12:\n",
            "      Successfully uninstalled murmurhash-1.0.12\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 3.0.12\n",
            "    Uninstalling Cython-3.0.12:\n",
            "      Successfully uninstalled Cython-3.0.12\n",
            "  Attempting uninstall: cloudpathlib\n",
            "    Found existing installation: cloudpathlib 0.21.0\n",
            "    Uninstalling cloudpathlib-0.21.0:\n",
            "      Successfully uninstalled cloudpathlib-0.21.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.2\n",
            "    Uninstalling charset-normalizer-3.4.2:\n",
            "      Successfully uninstalled charset-normalizer-3.4.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.4.26\n",
            "    Uninstalling certifi-2025.4.26:\n",
            "      Successfully uninstalled certifi-2025.4.26\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 2.0.10\n",
            "    Uninstalling catalogue-2.0.10:\n",
            "      Successfully uninstalled catalogue-2.0.10\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: typing-inspection\n",
            "    Found existing installation: typing-inspection 0.4.0\n",
            "    Uninstalling typing-inspection-0.4.0:\n",
            "      Successfully uninstalled typing-inspection-0.4.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.5.1\n",
            "    Uninstalling srsly-2.5.1:\n",
            "      Successfully uninstalled srsly-2.5.1\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: preshed\n",
            "    Found existing installation: preshed 3.0.9\n",
            "    Uninstalling preshed-3.0.9:\n",
            "      Successfully uninstalled preshed-3.0.9\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: marisa-trie\n",
            "    Found existing installation: marisa-trie 1.2.1\n",
            "    Uninstalling marisa-trie-1.2.1:\n",
            "      Successfully uninstalled marisa-trie-1.2.1\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 1.3.0\n",
            "    Uninstalling blis-1.3.0:\n",
            "      Successfully uninstalled blis-1.3.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.4\n",
            "    Uninstalling pydantic-2.11.4:\n",
            "      Successfully uninstalled pydantic-2.11.4\n",
            "  Attempting uninstall: language-data\n",
            "    Found existing installation: language_data 1.3.0\n",
            "    Uninstalling language_data-1.3.0:\n",
            "      Successfully uninstalled language_data-1.3.0\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.15.3\n",
            "    Uninstalling typer-0.15.3:\n",
            "      Successfully uninstalled typer-0.15.3\n",
            "  Attempting uninstall: langcodes\n",
            "    Found existing installation: langcodes 3.5.0\n",
            "    Uninstalling langcodes-3.5.0:\n",
            "      Successfully uninstalled langcodes-3.5.0\n",
            "  Attempting uninstall: confection\n",
            "    Found existing installation: confection 0.1.5\n",
            "    Uninstalling confection-0.1.5:\n",
            "      Successfully uninstalled confection-0.1.5\n",
            "  Attempting uninstall: weasel\n",
            "    Found existing installation: weasel 0.4.1\n",
            "    Uninstalling weasel-0.4.1:\n",
            "      Successfully uninstalled weasel-0.4.1\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.3.6\n",
            "    Uninstalling thinc-8.3.6:\n",
            "      Successfully uninstalled thinc-8.3.6\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.8.5\n",
            "    Uninstalling spacy-3.8.5:\n",
            "      Successfully uninstalled spacy-3.8.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\n",
            "langchain-core 0.3.59 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
            "bigframes 2.3.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Cython-3.1.0 MarkupSafe-3.0.2 annotated-types-0.7.0 blis-1.3.0 catalogue-2.0.10 certifi-2025.4.26 charset-normalizer-3.4.2 click-8.1.8 cloudpathlib-0.21.1 confection-0.1.5 cymem-2.0.11 idna-3.10 jinja2-3.1.6 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.12 numpy-2.2.5 packaging-25.0 preshed-3.0.9 pydantic-2.11.4 pydantic-core-2.33.2 pygments-2.19.1 requests-2.32.3 rich-14.0.0 setuptools-80.7.1 shellingham-1.5.4 smart-open-7.1.0 spacy-3.8.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 tqdm-4.67.1 typer-0.15.4 typing-extensions-4.13.2 typing-inspection-0.4.0 urllib3-2.4.0 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "certifi",
                  "pkg_resources"
                ]
              },
              "id": "9883dbfc65984c3b8ee737124329aeb7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Code - Fixing demasking of comments :- Main Code\n",
        "import re\n",
        "import os\n",
        "import gzip\n",
        "import time\n",
        "import json\n",
        "import spacy\n",
        "import string\n",
        "import random\n",
        "import tempfile\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, deque\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "\n",
        "# Variable defined\n",
        "ID, fake_data, used_urls, entity_columns  = {}, {}, set(), {}\n",
        "COMMENT_KEYWORDS = ['comments', 'description', 'remarks', 'note', 'feedback', 'observation']\n",
        "\n",
        "url_extensions = [\n",
        "    \".com\", \".net\", \".org\", \".edu\", \".gov\", \".co\", \".us\", \".uk\", \".in\", \".ru\",\n",
        "    \".jp\", \".cn\", \".de\", \".fr\", \".it\", \".nl\", \".es\", \".br\", \".au\", \".ca\",\n",
        "    \".ch\", \".se\", \".no\", \".za\", \".mx\", \".ar\", \".be\", \".kr\", \".pl\", \".tr\",\n",
        "    \".ua\", \".ir\", \".sa\", \".ae\", \".my\", \".sg\", \".hk\", \".tw\", \".nz\", \".id\",\n",
        "    \".th\", \".ph\", \".vn\", \".bd\", \".lk\", \".np\", \".pk\", \".cz\", \".gr\", \".hu\",\n",
        "    \".fi\", \".dk\", \".il\", \".ie\", \".pt\", \".sk\", \".si\", \".ro\", \".bg\", \".rs\",\n",
        "    \".lt\", \".lv\", \".ee\", \".hr\", \".ba\", \".md\", \".ge\", \".kz\", \".by\", \".tm\",\n",
        "    \".uz\", \".af\", \".qa\", \".om\", \".kw\", \".bh\", \".ye\", \".jo\", \".lb\", \".sy\",\n",
        "    \".iq\", \".ps\", \".az\", \".am\", \".kg\", \".mn\", \".bt\", \".mv\", \".mm\", \".kh\",\n",
        "    \".la\", \".tl\", \".sb\", \".fj\", \".pg\", \".to\", \".tv\", \".ws\", \".fm\", \".ki\"\n",
        "]\n",
        "# with gzip.open(\"faker_data_v3.json.gz\", \"rt\", encoding='utf-8') as f: fake_data_list = json.load(f)\n",
        "# Objects\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "fake=Faker()\n",
        "analyzer = AnalyzerEngine()\n",
        "\n",
        "\n",
        "fake_data_list = {} # Remove this\n",
        "for data in fake_data_list:\n",
        "    for key,value in data.items(): fake_data[key]=deque(value)\n",
        "domain_pool = list(fake_data.get('url', deque()))\n",
        "\n",
        "entity_mapping={\n",
        "    'names':'PERSON',\n",
        "    'emails':'EMAIL_ADDRESS',\n",
        "    'phone':'PHONE_NUMBER',\n",
        "    'location':'LOCATION',\n",
        "    'credit':'CREDIT_CARD',\n",
        "    'url':'URL',\n",
        "    'country':'COUNTRY',\n",
        "    'company':\"ORG\",\n",
        "    'id':'ID',\n",
        "}\n",
        "\n",
        "mapping_file=\"mapping.json\"\n",
        "forward_mapping=defaultdict(dict)\n",
        "reverse_mapping=defaultdict(dict)\n",
        "comment_entity_positions = defaultdict(dict)\n",
        "\n",
        "if os.path.exists(mapping_file):\n",
        "    with open(mapping_file, \"r\") as f:\n",
        "        mapping_data = json.load(f)\n",
        "        forward_mapping.update(mapping_data.get(\"forward_mapping\", {}))\n",
        "        reverse_mapping.update(mapping_data.get(\"reverse_mapping\", {}))\n",
        "\n",
        "# To track time\n",
        "def time_it(func):\n",
        "    \"\"\"Decorator to measure execution time of functions.\"\"\"\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f'\\n⏳ Execution time {func.__name__}: {end-start:.6f} seconds')\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "# For comments logic\n",
        "def get_comment_columns(df):\n",
        "    return [col for col in df.columns if any(kw in col.lower() for kw in COMMENT_KEYWORDS)]\n",
        "\n",
        "def mask_comment_columns(df, mapping):\n",
        "    comment_cols = get_comment_columns(df)\n",
        "    print('Inside mask comment cols:', comment_cols)\n",
        "\n",
        "    for col in comment_cols:\n",
        "        for i, text in df[col].astype(str).items():\n",
        "            masked_text, entities = mask_comment_text(text, mapping)\n",
        "            df.at[i, col] = masked_text\n",
        "            if entities: comment_entity_positions[col][i] = entities\n",
        "    return df\n",
        "\n",
        "def mask_comment_text(text, mapping):\n",
        "    if not text.strip(): return text, []\n",
        "\n",
        "    doc = nlp(text)\n",
        "    masked_text = text\n",
        "    entities = []\n",
        "    offset = 0\n",
        "\n",
        "    for token in doc:\n",
        "        if token.pos_ == \"PROPN\" or token.ent_type_:\n",
        "            original = token.text\n",
        "            fake = mapping['names'].get(original, None)\n",
        "\n",
        "            if fake and fake != original:\n",
        "                pattern = re.compile(rf\"\\b{re.escape(original)}(?=[\\W_]|$)\")\n",
        "                match = pattern.search(masked_text, token.idx + offset)\n",
        "                if match:\n",
        "                    start, end = match.span()\n",
        "                    masked_text = masked_text[:start] + fake + masked_text[end:]\n",
        "                    entities.append({\n",
        "                        \"start\": start,\n",
        "                        \"end\": start + len(fake),\n",
        "                        \"original\": original,\n",
        "                        \"fake\": fake\n",
        "                    })\n",
        "                    offset += len(fake) - len(original)\n",
        "\n",
        "    return masked_text, entities\n",
        "\n",
        "def unmask_comment_columns(df, reverse_mapping, entity_metadata):\n",
        "    comment_cols = get_comment_columns(df)\n",
        "    print('Inside unmask comment cols:', comment_cols)\n",
        "\n",
        "    for col in comment_cols:\n",
        "        if col not in entity_metadata:\n",
        "            continue\n",
        "\n",
        "        for i, text in df[col].astype(str).items():\n",
        "            if i in entity_metadata[col]:\n",
        "                df.at[i, col] = unmask_comment_text(text, entity_metadata[col][i], reverse_mapping)\n",
        "\n",
        "    return df\n",
        "\n",
        "def unmask_comment_text(text, entities, reverse_mapping):\n",
        "    for ent in sorted(entities, key=lambda x: -x['start']):\n",
        "        fake = ent['fake']\n",
        "        original = reverse_mapping['names'].get(fake, ent['original'])\n",
        "        text = text[:ent['start']] + original + text[ent['end']:]\n",
        "    return text\n",
        "\n",
        "@time_it\n",
        "def analyze_column(df):\n",
        "    # Step 1: Use Presidio to analyze all columns\n",
        "    comment_cols = get_comment_columns(df)\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col in comment_cols: continue\n",
        "\n",
        "        if 'id' in col.lower():\n",
        "            entity_columns[col] = 'ID'\n",
        "        elif 'country' in col.lower():\n",
        "            entity_columns[col] = 'COUNTRY'\n",
        "        else:\n",
        "            unique_values = df[col].dropna().astype(str).unique()[:25]\n",
        "            entity_counts = {}\n",
        "\n",
        "            for value in unique_values:\n",
        "                results = analyzer.analyze(text=value, language='en')\n",
        "                for result in results:\n",
        "                    entity_counts[result.entity_type] = entity_counts.get(result.entity_type, 0) + 1\n",
        "\n",
        "            if entity_counts:\n",
        "                predominant_entity = max(entity_counts, key=entity_counts.get)\n",
        "                entity_columns[col] = predominant_entity\n",
        "                if predominant_entity==\"LOCATION\":\n",
        "                  org_count=0\n",
        "                  for value in unique_values:\n",
        "                    doc=nlp(value)\n",
        "                    for ent in doc.ents:\n",
        "                      if ent.label_==\"ORG\":\n",
        "                        org_count+=1\n",
        "                  if org_count>5:\n",
        "                    predominant_entity=\"ORG\"\n",
        "                entity_columns[col]=predominant_entity\n",
        "\n",
        "    # Step 2: Use SpaCy to analyze non-numeric and unclassified columns\n",
        "    for col in df.select_dtypes(exclude=['number']).columns:\n",
        "        if col not in entity_columns:\n",
        "            unique_values = df[col].dropna().astype(str).unique()[:25]\n",
        "            org_count = 0\n",
        "\n",
        "            for value in unique_values:\n",
        "                doc = nlp(value)\n",
        "                for ent in doc.ents:\n",
        "                    if ent.label_ == 'ORG':\n",
        "                        org_count += 1\n",
        "\n",
        "            # If more than half of the sample values are ORG, classify as ORG\n",
        "            if org_count > 12:\n",
        "                entity_columns[col] = 'ORG'\n",
        "\n",
        "    return entity_columns\n",
        "\n",
        "def modify_fake_value(category, base_fake_value, counter):\n",
        "    if category == \"names\": return f\"{base_fake_value}{string.ascii_lowercase[counter % 26]}\"\n",
        "    elif category == \"emails\":\n",
        "        name, domain = base_fake_value.split(\"@\")\n",
        "        return f\"{name}{counter}@{domain}\"\n",
        "    elif category in {\"location\", \"country\"}: return f\"{base_fake_value}, District {counter % 100_000_000 + 1}\"\n",
        "    elif category == \"url\":\n",
        "        # Check if the URL already exists, if so, append a country extension\n",
        "        fake_value = base_fake_value\n",
        "        while fake_value in used_urls:\n",
        "            ext = random.choice(url_extensions)\n",
        "            if not fake_value.endswith(ext):\n",
        "                fake_value += ext\n",
        "        used_urls.add(fake_value)\n",
        "        return fake_value\n",
        "    elif category == \"phone\": return f\"{base_fake_value[:-2]}{counter % 100:02d}\"\n",
        "    elif category == \"company\": return f\"{base_fake_value} Group {counter % 100_000_000 + 1}\"\n",
        "    elif category == \"credit\": return f\"{base_fake_value[:-4]}{counter % 10000:04d}\"\n",
        "    else: return f\"{base_fake_value}-{counter}\"\n",
        "\n",
        "\n",
        "def get_fake_value(category, original_value):\n",
        "    global ID\n",
        "    if original_value in forward_mapping[category]: return forward_mapping[category][original_value]\n",
        "    fake_value = None\n",
        "    if category == \"names\":\n",
        "        original_tokens = str(original_value).split()\n",
        "        fake_tokens = []\n",
        "        used_fake_names = set(reverse_mapping[category])\n",
        "\n",
        "        for token in original_tokens:\n",
        "            if token in forward_mapping[category]:\n",
        "                fake_token = forward_mapping[category][token]\n",
        "            else:\n",
        "                fake_token = None\n",
        "\n",
        "                if fake_data.get(category):\n",
        "                    for _ in range(len(fake_data[category])):\n",
        "                        candidate = fake_data[category].popleft()\n",
        "                        fake_data[category].append(candidate)\n",
        "\n",
        "                        if candidate not in used_fake_names and candidate != token:\n",
        "                            fake_token = candidate\n",
        "                            break\n",
        "                        else:\n",
        "                            # Modify it if already used\n",
        "                            counter = 0\n",
        "                            base = candidate\n",
        "                            while True:\n",
        "                                modified = modify_fake_value(category, base, counter)\n",
        "                                if modified not in used_fake_names and modified != token:\n",
        "                                    fake_token = modified\n",
        "                                    break\n",
        "                                counter += 1\n",
        "                            break\n",
        "\n",
        "                # Save mappings\n",
        "                forward_mapping[category][token] = fake_token\n",
        "                reverse_mapping[category][fake_token] = token\n",
        "                used_fake_names.add(fake_token)\n",
        "\n",
        "            fake_tokens.append(fake_token)\n",
        "\n",
        "        return \" \".join(fake_tokens)\n",
        "\n",
        "\n",
        "    # Special case for ID\n",
        "    if category == 'id':\n",
        "        length = 6\n",
        "        while True:\n",
        "            fake_value = fake.bothify(text=f'ID-{\"#\"*length}')\n",
        "            if fake_value not in ID:\n",
        "                ID[fake_value] = True\n",
        "                break\n",
        "            if len(ID) >= 10 ** length: length += 1\n",
        "    elif category == 'url':\n",
        "        domain1, domain2 = random.sample(domain_pool, 2)\n",
        "        base_fake_value = f\"https://{domain1.lower()}/{domain2.lower()}.co\"\n",
        "\n",
        "        if base_fake_value not in reverse_mapping[\"url\"]:\n",
        "            fake_value = base_fake_value\n",
        "        else:\n",
        "            counter = len(reverse_mapping[\"url\"])\n",
        "            fake_value = modify_fake_value(\"url\", base_fake_value, counter)\n",
        "\n",
        "    elif fake_data.get(category):\n",
        "      length = len(fake_data[category])\n",
        "      for _ in range(length):\n",
        "            candidate = fake_data[category].popleft()\n",
        "            fake_data[category].append(candidate)  # Reinsert at end (rotation)\n",
        "            if candidate not in reverse_mapping[category]:\n",
        "                fake_value = candidate\n",
        "                break\n",
        "      else:\n",
        "          counter = len(reverse_mapping[category])\n",
        "          base_fake_value = (\n",
        "              random.choice(list(reverse_mapping[category]))\n",
        "              if reverse_mapping[category]\n",
        "              else f\"{category}_\"\n",
        "          )\n",
        "          fake_value = modify_fake_value(category, base_fake_value, counter)\n",
        "\n",
        "    if not fake_value or fake_value in reverse_mapping[category]:\n",
        "        counter = len(reverse_mapping[category])\n",
        "        base = fake_value if fake_value else f\"{category}_\"\n",
        "        fake_value = modify_fake_value(category, base, counter)\n",
        "\n",
        "    forward_mapping[category][original_value] = fake_value\n",
        "    reverse_mapping[category][fake_value] = original_value\n",
        "\n",
        "    return fake_value\n",
        "\n",
        "@time_it\n",
        "def mask_dataframe(df):\n",
        "    for col, entity in entity_columns.items():\n",
        "        matching_keys = [\n",
        "            key for key, value in entity_mapping.items() if value == entity\n",
        "        ]\n",
        "        if matching_keys:\n",
        "            category = matching_keys[0]\n",
        "            df[col] = df[col].astype(str).apply(\n",
        "                lambda x: get_fake_value(category, x) if x else x\n",
        "            )\n",
        "    return df\n",
        "\n",
        "def restore_original_value(category, fake_value):\n",
        "    return reverse_mapping[category].get(fake_value, fake_value)\n",
        "\n",
        "@time_it\n",
        "def unmask_dataframe(df):\n",
        "    for col, entity in entity_columns.items():\n",
        "        matching_keys = [key for key, value in entity_mapping.items() if value == entity]\n",
        "        if matching_keys:\n",
        "            category = matching_keys[0]\n",
        "\n",
        "            if category == \"names\":\n",
        "                def reverse_name(val):\n",
        "                    tokens = str(val).split()\n",
        "                    original_tokens = [reverse_mapping[category].get(tok, tok) for tok in tokens]\n",
        "                    return \" \".join(original_tokens)\n",
        "                df[col] = df[col].astype(str).apply(lambda x: reverse_name(x) if pd.notna(x) else x)\n",
        "\n",
        "            else:\n",
        "                df[col] = df[col].astype(str).apply(\n",
        "                    lambda x: restore_original_value(category, str(x)) if pd.notna(str(x)) else x\n",
        "                )\n",
        "    df = unmask_comment_columns(df, reverse_mapping, comment_entity_positions)\n",
        "    return df\n",
        "\n",
        "@time_it\n",
        "def compare_files(original_csv, restored_csv):\n",
        "    \"\"\"Compare two CSV files and return if they are identical.\"\"\"\n",
        "    original_df = pd.read_csv(original_csv, dtype=str).sort_index(axis=1).reset_index(drop=True)\n",
        "    restored_df = pd.read_csv(restored_csv, dtype=str).sort_index(axis=1).reset_index(drop=True)\n",
        "\n",
        "    is_identical = original_df.equals(restored_df)\n",
        "    print(f\"\\n📊 Are files identical? {'✅ Yes' if is_identical else '❌ No'}\")\n",
        "\n",
        "    if not is_identical:\n",
        "        print(\"⚠️ The restored file does not match the original. Investigate the mapping or masking logic.\")\n",
        "\n",
        "    return is_identical\n",
        "\n",
        "def de_anonymize_paragraph(text):\n",
        "  for category,mapping in reverse_mapping.items():\n",
        "    for fake_value,original_value in mapping.items():\n",
        "      if fake_value in text:\n",
        "        text=text.replace(fake_value,original_value)\n",
        "  return text\n",
        "\n",
        "def save_mapping(filename):\n",
        "    mapping_data={\n",
        "        \"filename\":filename,\n",
        "        \"updated_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
        "        \"forward_mapping\":forward_mapping,\n",
        "        \"reverse_mapping\":reverse_mapping\n",
        "    }\n",
        "    with open(mapping_file, \"a\") as f:\n",
        "        json.dump(mapping_data, f, indent=4)\n",
        "\n",
        "def process_file(input_file, file_ext):\n",
        "    input_base = os.path.splitext(os.path.basename(input_file))[0]\n",
        "    output_dir = os.path.join(\".\", input_base)\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    if file_ext == \".xlsx\":\n",
        "        xl = pd.read_excel(input_file, sheet_name=None, dtype=str, engine='calamine')\n",
        "\n",
        "        for sheet_name, df in xl.items():\n",
        "            print(f\"\\n🔍 Processing sheet: {sheet_name}\")\n",
        "\n",
        "            # original_csv = os.path.join(output_dir, f\"{sheet_name}_original.csv\")\n",
        "            # masked_csv = os.path.join(output_dir, f\"{sheet_name}_masked.csv\")\n",
        "            # restored_csv = os.path.join(output_dir, f\"{sheet_name}_restored.csv\")\n",
        "\n",
        "            # df.to_csv(original_csv, index=False)\n",
        "\n",
        "            entity_columns = analyze_column(df)\n",
        "            print(f\"Detected entities: {entity_columns}\")\n",
        "\n",
        "            # masked_df = mask_dataframe(df.copy())\n",
        "            # masked_df = mask_comment_columns(masked_df, forward_mapping)\n",
        "            # restored_df = unmask_dataframe(masked_df.copy())\n",
        "\n",
        "            # masked_df.to_csv(masked_csv, index=False)\n",
        "            # restored_df.to_csv(restored_csv, index=False)\n",
        "\n",
        "            # compare_files(original_csv, restored_csv)\n",
        "\n",
        "            # save_mapping(f'{input_file}-->{sheet_name}')\n",
        "            # entity_columns.clear()\n",
        "\n",
        "\n",
        "    elif file_ext == \".csv\":\n",
        "        df = pd.read_csv(input_file, dtype=str, low_memory=False)\n",
        "        print(f\"\\n🔍 Processing CSV: {input_file}\")\n",
        "\n",
        "        original_csv = os.path.join(output_dir, \"original.csv\")\n",
        "        masked_csv = os.path.join(output_dir, \"anonymized.csv\")\n",
        "        restored_csv = os.path.join(output_dir, \"restored.csv\")\n",
        "\n",
        "        if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
        "\n",
        "        df.to_csv(original_csv, index=False)\n",
        "\n",
        "        entity_columns = analyze_column(df)\n",
        "        print(f\"Detected entities: {entity_columns}\")\n",
        "\n",
        "        masked_df = mask_dataframe(df.copy())\n",
        "        masked_df = mask_comment_columns(masked_df, forward_mapping)\n",
        "        restored_df = unmask_dataframe(masked_df.copy())\n",
        "\n",
        "        masked_df.to_csv(masked_csv, index=False)\n",
        "        restored_df.to_csv(restored_csv, index=False)\n",
        "\n",
        "        compare_files(original_csv, restored_csv)\n",
        "\n",
        "        save_mapping(input_file)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type. Use .csv or .xlsx only.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_file = \"SO(real).xlsx\"\n",
        "    file_ext = os.path.splitext(input_file)[-1].lower()\n",
        "    process_file(input_file, file_ext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-1pGkJah3k7",
        "outputId": "5d4bddda-7bad-4d24-fa97-8ffff900ff09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Processing sheet: Open demand\n",
            "\n",
            "⏳ Execution time analyze_column: 24.099772 seconds\n",
            "Detected entities: {'Resource Request ID': 'ID', 'Priority': 'US_DRIVER_LICENSE', 'City': 'LOCATION', 'State': 'LOCATION', 'Country': 'COUNTRY', 'Altenate Location': 'ORG', 'Campus': 'ORG', 'Job Grade': 'US_DRIVER_LICENSE', 'RR Start Date': 'DATE_TIME', 'RR End Date': 'DATE_TIME', 'Account Name': 'PERSON', 'Project ID': 'ID', 'Project Name': 'PERSON', 'WFME': 'PERSON', 'WFME ID': 'ID', 'HM': 'PERSON', 'HM ID': 'ID', 'AM': 'PERSON', 'AM ID': 'ID', 'Actual Currency': 'ORG', 'Currency': 'LOCATION', 'Replacement Type': 'PERSON', 'Client Job Title': 'US_DRIVER_LICENSE', 'OBU Name': 'PERSON', 'Project Start Date': 'DATE_TIME', 'Project End Date': 'DATE_TIME', 'Raised On': 'DATE_TIME', 'RR Finance Approved Date': 'DATE_TIME', 'Edit Requested Date': 'DATE_TIME', 'Resubmitted Date': 'DATE_TIME', 'Resubmitted Reason2': 'DATE_TIME', 'Recruiter Name': 'PERSON', 'Recruiter ID': 'ID', 'Last Updated On': 'DATE_TIME', 'Last Activity Date': 'DATE_TIME', 'Last Activity': 'PERSON', 'Mandatory Skills': 'DATE_TIME', 'Optional Skills': 'PERSON', 'RR Skill Group': 'PERSON', 'Hiring request Submit Date (MTE)': 'DATE_TIME', 'SO Initiator Name': 'PERSON', 'SO Initiator ID': 'ID', 'Allocation Project ID': 'ID', 'Allocation Project Start Date': 'DATE_TIME', 'Allocation Project End Date': 'DATE_TIME', 'TA Cluster Lead': 'US_DRIVER_LICENSE', 'Outgoing Employee Id': 'ID', 'Outgoing Employee Name': 'PERSON', 'Country Cluster': 'COUNTRY', 'Parent Account': 'PERSON', 'Vertical': 'PERSON', 'Engagement Type': 'DATE_TIME', 'Sub Skill Cluster': 'PERSON', 'SubSkill': 'PERSON', 'Lead Time Bucket': 'DATE_TIME', 'RH_Recruiter ID': 'ID', 'RH_Recruiter Name': 'PERSON', 'RR Aging': 'DATE_TIME', 'Cluster': 'ORG', 'WFM Lead / Onsite SPOCS': 'PERSON', 'Status': 'US_DRIVER_LICENSE', 'SO Lead Time': 'DATE_TIME', 'External Tagging TAT': 'DATE_TIME', 'Delay In Techincal interview': 'DATE_TIME', 'Reasons': 'PERSON', 'Accepted Resource Type': 'ORG', 'UST Role Description': 'ORG', 'Job Description': 'ORG', 'Notes for WFM or TA': 'ORG', 'Comments': 'ORG'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(\" debugged energy grid anomalies.\")\n",
        "\n",
        "for token in doc:\n",
        "  print(token.text, token.pos_)\n",
        "  if token.pos_ == \"PROPN\" or token.ent_type_:\n",
        "      print(token.text)\n",
        "      # print(reverse_mapping['names'].get(token.text))\n"
      ],
      "metadata": {
        "id": "kKBDzl5uWwzY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b46914-6ae9-4d9a-821a-a58858c74dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rem PROPN\n",
            "Rem\n",
            "debugged VERB\n",
            "energy NOUN\n",
            "grid NOUN\n",
            "anomalies NOUN\n",
            ". PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seeing the differences b/w codes\n",
        "import pandas as pd\n",
        "\n",
        "def difference_in_csv_sm(path):\n",
        "    original_df = pd.read_csv(path)\n",
        "    restored_df = pd.read_csv('./smaller_30k_companies/restored.csv')\n",
        "    diff_df = original_df.compare(restored_df, keep_equal=False)\n",
        "\n",
        "    print(diff_df.head(10))\n",
        "    diff_df.to_csv('difference.csv', index=False)\n",
        "\n",
        "def difference_in_csv(path):\n",
        "    original_df = pd.read_csv(path)\n",
        "    restored_df = pd.read_csv('./for_colab_test/restored.csv')\n",
        "    anonymized_df = pd.read_csv('./for_colab_test/anonymized.csv')\n",
        "\n",
        "    diff_df = original_df.compare(restored_df, keep_equal=False)\n",
        "\n",
        "    diff_df.columns = [\n",
        "        (col[0], 'original' if col[1] == 'self' else 'restored')\n",
        "        for col in diff_df.columns\n",
        "    ]\n",
        "    diff_df.columns = pd.MultiIndex.from_tuples(diff_df.columns)\n",
        "\n",
        "    diff_df = diff_df.reset_index()\n",
        "\n",
        "    anonymized_rows = anonymized_df.loc[diff_df['index']]\n",
        "    anonymized_rows = anonymized_rows.reset_index(drop=True)\n",
        "    diff_df = diff_df.drop(columns='index')\n",
        "\n",
        "    # Flatten multi-index columns for original/restored\n",
        "    diff_flat = pd.DataFrame()\n",
        "    for col in diff_df.columns.get_level_values(0).unique():\n",
        "        diff_flat[f'{col} (original)'] = diff_df[col]['original']\n",
        "        diff_flat[f'{col} (restored)'] = diff_df[col]['restored']\n",
        "\n",
        "    for col in anonymized_rows.columns:\n",
        "        if 'comment' in col.lower():\n",
        "            diff_flat[f'{col} (anonymized)'] = anonymized_rows[col]\n",
        "\n",
        "    diff_flat.to_csv('differences.csv', index=False)\n",
        "    print(diff_flat.head(10))\n",
        "\n",
        "def difference_in_excel(path):\n",
        "  original_df = pd.read_excel(path)\n",
        "  restored_df = pd.read_excel('restored.xlsx')\n",
        "  diff_df = original_df.compare(restored_df, keep_equal=False)\n",
        "  print(diff_df.head(10))\n",
        "  diff_df.to_excel('differences.xlsx')\n",
        "\n",
        "def difference_in_parquet(path):\n",
        "  original_df = pd.read_parquet(path)\n",
        "  restored_df = pd.read_parquet('Sheet1_restored.parquet')\n",
        "  diff_df = original_df.compare(restored_df, keep_equal=False)\n",
        "  print(diff_df.head(10))\n",
        "  diff_df.to_parquet('differences.parquet')\n",
        "\n",
        "difference_in_csv_sm('smaller_30k_companies.csv')\n",
        "# difference_in_csv('for_colab_test.csv')\n",
        "# difference_in_excel()\n",
        "# difference_in_parquet()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSqjIhh14nsr",
        "outputId": "5a3a432f-bb72-424e-f5d4-97bd57e1d6fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing out fuzzy match\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "text = '''Ford-Mendez Corporation Inc., founded in 1911, operates in the information\n",
        "technology and services industry. Based in Port Brett, Delaware Region, Afghanistan,\n",
        "the company has over 10,000 employees and a current employee estimate of 274,047.\n",
        "The total employee estimate is 716,906. For more details, you can visit their LinkedIn page here.\n",
        "Additionally, a key employee at the company, A Aaban Aabarana, has been working there for several years.\n",
        "Kelly, Hobbs and Garcia Industries International, established in 1968,\n",
        "is also a major player in the information technology and services sector. Located in Jefferyburgh,\n",
        "South Dakota, Albania, this company too has over 10,000 employees, with a current employee estimate\n",
        "of 190,771 and a total employee estimate of 341,369. You can learn more about the company by visiting\n",
        "their LinkedIn profile here. One of their top executives, Aabarna Aabarniga, has contributed greatly to\n",
        "their success.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwrY2tgMPmxz",
        "outputId": "a16729bc-8c01-4ce8-e09c-efe84abfc77f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Isolating verbs and adjectives from text\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "common_verbs = {\n",
        "    'is', 'was', 'are', 'were', 'be', 'being', 'been', 'have', 'has', 'had',\n",
        "    'get', 'gets', 'got', 'do', 'does', 'did', 'can', 'could', 'will', 'would',\n",
        "    'shall', 'should', 'may', 'might', 'must', 'found', 'run', 'operate', 'used',\n",
        "    'work', 'working', 'known', 'help', 'helped', 'helping', 'contributed', 'success', 'successful',\n",
        "    'unsuccessful'\n",
        "}\n",
        "\n",
        "def get_entity_candidates(text):\n",
        "    words = re.findall(r'\\b\\w+\\b', text)\n",
        "    filtered = [\n",
        "        word for word in words\n",
        "        if word.lower() not in stop_words\n",
        "        and word.lower() not in common_verbs\n",
        "        and len(word) > 2\n",
        "        # and not word.isdigit()\n",
        "    ]\n",
        "    return filtered\n",
        "\n",
        "corporus = \"Jams Bond was found operating a project called EnrgyNet in New Yrk in 2023. It helps clients.\"\n",
        "print(get_entity_candidates(corporus))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7NjmO5sPb9S",
        "outputId": "2b264424-fa93-45ce-ae63-394b0297b19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Jams', 'Bond', 'operating', 'project', 'called', 'EnrgyNet', 'New', 'Yrk', '2023', 'helps', 'clients']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rapidfuzz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_g2_JO8ImLP",
        "outputId": "53dea1d6-965e-4265-8637-2028dd38148f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing out matching using fuzzy\n",
        "import re\n",
        "\n",
        "verb_roots = {'be', 'is', 'have', 'do', 'say', 'go', 'can', 'get', 'make', 'know', 'think', 'take', 'see', 'come', 'want', 'look', 'use', 'find', 'give', 'tell', 'work', 'call', 'try', 'ask', 'need', 'feel', 'become', 'leave', 'put', 'mean', 'keep', 'let', 'like', 'help'}\n",
        "adj_roots = {'good', 'manag', 'new', 'first', 'last', 'long', 'great', 'little', 'own', 'other', 'old', 'right', 'big', 'high', 'different', 'small', 'large', 'next', 'early', 'young', 'important'}\n",
        "adv_roots = {'very', 'too', 'really', 'just', 'quite', 'soon', 'again', 'still', 'always', 'often'}\n",
        "prepositions = {'in', 'on', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'of', 'off', 'a', 'the', 'too', 'and', 'or', 'what', 'else', 'if'}\n",
        "punctuations = {'.', ',', ';', ':', '!', '?', '(', ')', '[', ']', '{', '}', '\"', \"'\"}\n",
        "common_words = {'father', 'mother', 'daughter', 'son', 'aunty', 'aunt', 'uncle', 'sister', 'brother', }\n",
        "\n",
        "def is_excluded(word):\n",
        "    w = word.lower()\n",
        "    return (\n",
        "        any(re.fullmatch(rf\"{root}(s|ed|ing)?\", w) for root in verb_roots) or\n",
        "        any(re.fullmatch(rf\"{root}(er|est|ly)?\", w) for root in adj_roots) or\n",
        "        any(re.fullmatch(rf\"{root}(ly|ing)?\", w) for root in adv_roots) or\n",
        "        any(re.fullmatch(rf\"{root}(s|'s|ed|ly|ing)?\", w) for root in common_words) or\n",
        "        w in prepositions or\n",
        "        w in punctuations\n",
        "    )\n"
      ],
      "metadata": {
        "id": "kwb2OdIQPU0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rapidfuzz import process, fuzz\n",
        "\n",
        "def correct_word(word, valid_names, threshold=65):\n",
        "    match = process.extractOne(word, valid_names, scorer=fuzz.ratio)\n",
        "    return match[0] if match and match[1] >= threshold else None\n",
        "\n",
        "@time_it\n",
        "def isolate_and_correct_entities(text, valid_names):\n",
        "    tokens = text.split()\n",
        "    entities = []\n",
        "\n",
        "    for idx, word in enumerate(tokens):\n",
        "        if not is_excluded(word):\n",
        "            corrected = correct_word(word, valid_names)\n",
        "            if corrected:\n",
        "                entities.append((idx, word, corrected.capitalize()))\n",
        "\n",
        "    return entities\n"
      ],
      "metadata": {
        "id": "8ugNHl5bPjkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Theressa is a manager working for Wiliams. Ruthu Jenkinz is the mother of\n",
        "  Fransis Waner and Kaitlyn Meyers.\"\"\"\n",
        "\n",
        "valid_names = [name.lower() for name in forward_mapping['names']]\n",
        "entities = isolate_and_correct_entities(text, valid_names)\n",
        "\n",
        "for idx, original, corrected in entities:\n",
        "    print(f\"Position {idx}: '{original}' corrected to '{corrected}'\")\n",
        "\n",
        "tokens = text.split()\n",
        "for idx, original, corrected in entities:\n",
        "    tokens[idx] = corrected\n",
        "\n",
        "corrected_text = ' '.join(tokens)\n",
        "\n",
        "print(\"Corrected text:\")\n",
        "print(corrected_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1ifB6haPmV7",
        "outputId": "63d0908f-ed3e-42a4-b02a-e6c8564dba53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏳ Execution time isolate_and_correct_entities: 0.007842 seconds\n",
            "Position 0: 'Theressa' corrected to 'Theresa'\n",
            "Position 6: 'Wiliams.' corrected to 'Williams'\n",
            "Position 7: 'Ruthu' corrected to 'Ruth'\n",
            "Position 8: 'Jenkinz' corrected to 'Jenkins'\n",
            "Position 13: 'Fransis' corrected to 'Francis'\n",
            "Position 14: 'Waner' corrected to 'Wagner'\n",
            "Position 16: 'Kaitlyn' corrected to 'Kaitlyn'\n",
            "Position 17: 'Meyers.' corrected to 'Meyers'\n",
            "Corrected text:\n",
            "Theresa is a manager working for Williams Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from rapidfuzz import process, fuzz\n",
        "\n",
        "def correct_word(word, valid_names, threshold=65):\n",
        "    name_match = process.extractOne(word, valid_names, scorer=fuzz.ratio)\n",
        "    if name_match and name_match[1] >= threshold: return name_match[0]\n",
        "    return None\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "f_mapping_names = [key.lower() for key in forward_mapping['names']]\n",
        "end_time = time.time()\n",
        "\n",
        "print(f'Mapping list time: {end_time-start_time}')\n",
        "text = \"\"\"Theressa is a manager working for Wiliams Ruthj Jenkinz Fransis Waner Kaitlyn Meyers Nicolas Stevans\n",
        "Dona Berd Solushunz Stefanie Miller.\"\"\".split()\n",
        "\n",
        "start_time = time.time()\n",
        "results = [correct_word(word, f_mapping_names) for word in text]\n",
        "end_time = time.time()\n",
        "print(f'Result: {end_time-start_time}')\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IwLarTSI8Zt",
        "outputId": "78a6b485-3b3f-4a91-937b-1836bf25cd3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Alexandra', 'Alice', 'Armstrong', 'Arthur', 'Ariel', 'Alex', 'Ashley', 'Alejandro', 'Antonio', 'Andrew']\n",
            "Mapping list time: 0.0009248256683349609\n",
            "Result: 0.003665447235107422\n",
            "['theresa', 'lisa', None, 'maynard', 'wong', 'ford', 'williams', 'ruth', 'jenkins', 'francis', 'wagner', 'kaitlyn', 'meyers', 'nicolas', 'evans', 'donna', 'beard', None, 'stefanie', 'miller']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing entity isolation and correction\n",
        "import spacy\n",
        "import re\n",
        "from rapidfuzz import process, fuzz\n",
        "\n",
        "# Load spaCy small English model (you can also try 'en_core_web_md' if you want better tagging)\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "verb_roots = {'be', 'is', 'have', 'do', 'say', 'go', 'can', 'get', 'make', 'know', 'think', 'take', 'see', 'come', 'want', 'look', 'use', 'find', 'give', 'tell', 'work', 'call', 'try', 'ask', 'need', 'feel', 'become', 'leave', 'put', 'mean', 'keep', 'let', 'like', 'help'}\n",
        "adj_roots = {'good', 'manag', 'new', 'first', 'last', 'long', 'great', 'little', 'own', 'other', 'old', 'right', 'big', 'high', 'different', 'small', 'large', 'next', 'early', 'young', 'important'}\n",
        "adv_roots = {'very', 'too', 'really', 'just', 'quite', 'soon', 'again', 'still', 'always', 'often'}\n",
        "prepositions = {'in', 'on', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'of', 'off', 'a', 'the', 'too', 'and', 'or', 'what', 'else', 'if'}\n",
        "punctuations = {'.', ',', ';', ':', '!', '?', '(', ')', '[', ']', '{', '}', '\"', \"'\"}\n",
        "common_words = {'father', 'mother', 'daughter', 'son', 'aunty', 'aunt', 'uncle', 'sister', 'brother'}\n",
        "\n",
        "def is_excluded(word):\n",
        "    w = word.lower()\n",
        "    return (\n",
        "        any(re.fullmatch(rf\"{root}(s|ed|ing)?\", w) for root in verb_roots) or\n",
        "        any(re.fullmatch(rf\"{root}(er|est|ly)?\", w) for root in adj_roots) or\n",
        "        any(re.fullmatch(rf\"{root}(ly|ing)?\", w) for root in adv_roots) or\n",
        "        any(re.fullmatch(rf\"{root}(s|'s|ed|ly|ing)?\", w) for root in common_words) or\n",
        "        w in prepositions or\n",
        "        w in punctuations\n",
        "    )\n",
        "\n",
        "def correct_word(word, valid_names, threshold=65):\n",
        "    match = process.extractOne(word, valid_names, scorer=fuzz.ratio)\n",
        "    return match[0] if match and match[1] >= threshold else None\n",
        "\n",
        "def isolate_and_correct_entities_spacy(text, valid_names, threshold=65):\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.text for token in doc]\n",
        "    corrected_tokens = tokens.copy()\n",
        "\n",
        "    for i, token in enumerate(doc):\n",
        "        if token.is_punct or token.is_space:\n",
        "            continue\n",
        "\n",
        "        if token.pos_ in {\"NOUN\", \"PROPN\"}:\n",
        "            word = token.text\n",
        "            if not is_excluded(word):\n",
        "                corrected = correct_word(word, valid_names, threshold)\n",
        "                if corrected:\n",
        "                    corrected_tokens[i] = corrected.capitalize()\n",
        "\n",
        "    corrected_text = ''.join([\n",
        "        token if token in punctuations or token.isspace() else ' ' + token\n",
        "        for token in corrected_tokens\n",
        "    ]).strip()\n",
        "\n",
        "    return corrected_text\n",
        "\n",
        "# --- Example usage:\n",
        "\n",
        "text = \"\"\"Theressa is a manager working for Wiliams. Ruthu Jenkinz is the mother of Fransis Waner and Kaitlyn Meyers.\"\"\"\n",
        "\n",
        "# Assume forward_mapping['names'] already loaded somewhere\n",
        "valid_names = [name.lower() for name in forward_mapping['names']]\n",
        "\n",
        "corrected_text = isolate_and_correct_entities_spacy(text, valid_names)\n",
        "print(corrected_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSVNbj6Ae0zy",
        "outputId": "1e38d917-447a-44f4-a024-7dd3a62df4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: Nw York, Corrected: New York, Position: (15, 22), Type: GPE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gliner faker rapidfuzz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U4Ab5_IVfA-",
        "outputId": "5e816788-22a6-4750-e3de-cfeb27060d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gliner\n",
            "  Downloading gliner-0.2.19-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gliner) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers>=4.38.2 in /usr/local/lib/python3.11/dist-packages (from gliner) (4.51.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.4 in /usr/local/lib/python3.11/dist-packages (from gliner) (0.30.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gliner) (4.67.1)\n",
            "Collecting onnxruntime (from gliner)\n",
            "  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from gliner) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->gliner) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->gliner) (2.2.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->gliner) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->gliner) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->gliner) (0.5.3)\n",
            "Collecting coloredlogs (from onnxruntime->gliner)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime->gliner) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime->gliner) (5.29.4)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->gliner)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->gliner) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.4->gliner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.4->gliner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.4->gliner) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.4->gliner) (2025.4.26)\n",
            "Downloading gliner-0.2.19-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, onnxruntime, nvidia-cusolver-cu12, gliner\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed coloredlogs-15.0.1 gliner-0.2.19 humanfriendly-10.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.21.1\n",
            "Requirement already satisfied: faker in /usr/local/lib/python3.11/dist-packages (37.1.0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\n",
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gliner import GLiNER\n",
        "from rapidfuzz import process, fuzz\n",
        "\n",
        "model = GLiNER.from_pretrained(\"urchade/gliner_base\")\n",
        "\n",
        "def correct_word(word, valid_list, threshold=65):\n",
        "    match = process.extractOne(word, valid_list, scorer=fuzz.ratio)\n",
        "    return match[0] if match and match[1] >= threshold else word  # fallback if no good match\n",
        "\n",
        "def find_and_correct_entities(text, valid_names, valid_company):\n",
        "    entities = model.predict_entities(text, labels=[\"person\", \"organization\"])\n",
        "\n",
        "    corrected_entities = []\n",
        "\n",
        "    for ent in entities:\n",
        "        entity_text = ent['text']\n",
        "        start = ent['start']\n",
        "        end = ent['end']\n",
        "        label = ent['label']\n",
        "\n",
        "        if label == \"person\":\n",
        "            tokens = entity_text.split()\n",
        "            corrected_tokens = [\n",
        "                correct_word(token.lower(), valid_names).capitalize()\n",
        "                for token in tokens\n",
        "            ]\n",
        "            corrected = \" \".join(corrected_tokens)\n",
        "\n",
        "        elif label == \"organization\":\n",
        "            corrected = correct_word(entity_text.lower(), valid_company).capitalize()\n",
        "\n",
        "        else: corrected = entity_text\n",
        "\n",
        "        corrected_entities.append({\n",
        "            'original': entity_text,\n",
        "            'corrected': corrected,\n",
        "            'start': start,\n",
        "            'end': end,\n",
        "            'label': label\n",
        "        })\n",
        "\n",
        "    return corrected_entities\n",
        "\n",
        "def replace_entities_in_text(text, entities):\n",
        "    entities = sorted(entities, key=lambda x: x['start'], reverse=True)\n",
        "\n",
        "    for ent in entities:\n",
        "        text = text[:ent['start']] + ent['corrected'] + text[ent['end']:]\n",
        "    return text\n",
        "\n",
        "@time_it\n",
        "def main():\n",
        "  text = \"\"\"Theressa is a manager working for Wiliams. Ruthu Jenkinz is the mother of Fransis Waner and Kaitlyy Meeeers.\n",
        "  Donaa Gavln hasn't been seen for a while now by Nickol. THis is concerning!\"\"\"\n",
        "  valid_names = [name.lower() for name in forward_mapping['names']]  # should be tokens\n",
        "  valid_company = [company.lower() for company in forward_mapping['company']]\n",
        "\n",
        "  entities = find_and_correct_entities(text, valid_names, valid_company)\n",
        "  corrected_text = replace_entities_in_text(text, entities)\n",
        "\n",
        "  print(\"\\nCorrected Text:\\n\", corrected_text)\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0b86935e033f45e8821f842319557b47",
            "c8d712f7fcca450b915c5bd629eaaa78",
            "351a1d4ee69d4a58a21ac446d8c5ea84",
            "5c8624920c644775817727136ca0db6a",
            "97b2694d02a6439a8c3b7b1345d061a8",
            "db8e85859e1c47a69cada275aed39680",
            "8eba7d076b8043eba79d5bb5f553ffd2",
            "fbed5108ccf04c11b969d071f1aae3f0",
            "e8dd104bc9e54c4caa9169b96bb14a1d",
            "1d4be75b6c684b8ca02f19971d69a940",
            "8b53f325ddab43c68f96860706b0510a"
          ]
        },
        "id": "DSCOuLSsVhDq",
        "outputId": "06f5fa8e-043a-4973-b58e-3d2465021c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b86935e033f45e8821f842319557b47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Williams. Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers.\n",
            "  Donna Gavin hasn't been seen for a while now by Nikon. THis is concerning!\n",
            "\n",
            "⏳ Execution time main: 0.805174 seconds\n",
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Williams. Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers.\n",
            "  Donna Gavin hasn't been seen for a while now by Nikon. THis is concerning!\n",
            "\n",
            "⏳ Execution time main: 0.640440 seconds\n",
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Williams. Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers.\n",
            "  Donna Gavin hasn't been seen for a while now by Nikon. THis is concerning!\n",
            "\n",
            "⏳ Execution time main: 0.651691 seconds\n",
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Williams. Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers.\n",
            "  Donna Gavin hasn't been seen for a while now by Nikon. THis is concerning!\n",
            "\n",
            "⏳ Execution time main: 0.645857 seconds\n",
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Williams. Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers.\n",
            "  Donna Gavin hasn't been seen for a while now by Nikon. THis is concerning!\n",
            "\n",
            "⏳ Execution time main: 0.666033 seconds\n",
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Williams. Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers.\n",
            "  Donna Gavin hasn't been seen for a while now by Nikon. THis is concerning!\n",
            "\n",
            "⏳ Execution time main: 0.741066 seconds\n",
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Williams. Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers.\n",
            "  Donna Gavin hasn't been seen for a while now by Nikon. THis is concerning!\n",
            "\n",
            "⏳ Execution time main: 1.053959 seconds\n",
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Williams. Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers.\n",
            "  Donna Gavin hasn't been seen for a while now by Nikon. THis is concerning!\n",
            "\n",
            "⏳ Execution time main: 1.036857 seconds\n",
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Williams. Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers.\n",
            "  Donna Gavin hasn't been seen for a while now by Nikon. THis is concerning!\n",
            "\n",
            "⏳ Execution time main: 0.885611 seconds\n",
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Williams. Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers.\n",
            "  Donna Gavin hasn't been seen for a while now by Nikon. THis is concerning!\n",
            "\n",
            "⏳ Execution time main: 0.627140 seconds\n",
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Williams. Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers.\n",
            "  Donna Gavin hasn't been seen for a while now by Nikon. THis is concerning!\n",
            "\n",
            "⏳ Execution time main: 0.657251 seconds\n",
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Williams. Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers.\n",
            "  Donna Gavin hasn't been seen for a while now by Nikon. THis is concerning!\n",
            "\n",
            "⏳ Execution time main: 0.631494 seconds\n",
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Williams. Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers.\n",
            "  Donna Gavin hasn't been seen for a while now by Nikon. THis is concerning!\n",
            "\n",
            "⏳ Execution time main: 0.646412 seconds\n",
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Williams. Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers.\n",
            "  Donna Gavin hasn't been seen for a while now by Nikon. THis is concerning!\n",
            "\n",
            "⏳ Execution time main: 0.682716 seconds\n",
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Williams. Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers.\n",
            "  Donna Gavin hasn't been seen for a while now by Nikon. THis is concerning!\n",
            "\n",
            "⏳ Execution time main: 0.641136 seconds\n",
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Williams. Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers.\n",
            "  Donna Gavin hasn't been seen for a while now by Nikon. THis is concerning!\n",
            "\n",
            "⏳ Execution time main: 0.648865 seconds\n",
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Williams. Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers.\n",
            "  Donna Gavin hasn't been seen for a while now by Nikon. THis is concerning!\n",
            "\n",
            "⏳ Execution time main: 0.653826 seconds\n",
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Williams. Ruth Jenkins is the mother of Francis Wagner and Kaitlyn Meyers.\n",
            "  Donna Gavin hasn't been seen for a while now by Nikon. THis is concerning!\n",
            "\n",
            "⏳ Execution time main: 0.642286 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gliner import GLiNER\n",
        "from rapidfuzz import process, fuzz\n",
        "from faker import Faker\n",
        "import json\n",
        "import time\n",
        "\n",
        "model = GLiNER.from_pretrained(\"urchade/gliner_base\")\n",
        "faker = Faker()\n",
        "\n",
        "forward_mapping = {\n",
        "    \"names\": {\n",
        "        \"Theresa\": \"Aanik\",\n",
        "        \"Fransis\": \"Ben\",\n",
        "        'Alvin' : 'Sam',\n",
        "        'Albin' : 'Bond',\n",
        "        \"Kaitlyn\": \"Lora\",\n",
        "        \"Nickol\": \"Chris\",\n",
        "        \"Dona\": \"Alia\",\n",
        "        \"Ruth\": \"Fay\"\n",
        "    },\n",
        "    \"company\": {\n",
        "        \"Williams-Waller Co\": \"ibm\",\n",
        "        \"Tata Consultancy Services\": \"tcs\",\n",
        "        \"IBM\": \"oracle\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def time_it(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f\"\\nExecution time: {end - start:.4f} seconds\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "def correct_with_forward_mapping(word, mapping_dict, threshold=85):\n",
        "    match = process.extractOne(word, mapping_dict.keys(), scorer=fuzz.ratio)\n",
        "    if match and match[1] >= threshold:\n",
        "        return match[0], mapping_dict[match[0]], False\n",
        "    return word, None, True  # new word\n",
        "\n",
        "def find_and_correct_entities(text):\n",
        "    entities = model.predict_entities(text, labels=[\"person\", \"organization\"])\n",
        "    corrected_entities = []\n",
        "\n",
        "    new_entity_mappings = {\n",
        "        \"forward_mapping\": {},\n",
        "        \"reverse_mapping\": {}\n",
        "    }\n",
        "\n",
        "    for ent in entities:\n",
        "        entity_text = ent['text']\n",
        "        start = ent['start']\n",
        "        end = ent['end']\n",
        "        label = ent['label']\n",
        "\n",
        "        if label == \"person\":\n",
        "            tokens = entity_text.split()\n",
        "            corrected_tokens = []\n",
        "            for token in tokens:\n",
        "                original_token = token.strip()\n",
        "                mapped_key, mapped_value, is_new = correct_with_forward_mapping(original_token, forward_mapping['names'])\n",
        "                if is_new:\n",
        "                    fake_name = faker.first_name()\n",
        "                    new_entity_mappings[\"forward_mapping\"][original_token] = fake_name\n",
        "                    new_entity_mappings[\"reverse_mapping\"][fake_name] = original_token\n",
        "                    corrected_tokens.append(mapped_key)\n",
        "                else:\n",
        "                    corrected_tokens.append(mapped_key)\n",
        "            corrected = \" \".join(corrected_tokens)\n",
        "\n",
        "        elif label == \"organization\":\n",
        "            mapped_key, mapped_value, is_new = correct_with_forward_mapping(entity_text, forward_mapping['company'])\n",
        "            if is_new:\n",
        "                fake_company = faker.company()\n",
        "                new_entity_mappings[\"forward_mapping\"][entity_text] = fake_company\n",
        "                new_entity_mappings[\"reverse_mapping\"][fake_company] = entity_text\n",
        "                corrected = mapped_key\n",
        "            else:\n",
        "                corrected = mapped_key\n",
        "\n",
        "        else:\n",
        "            corrected = entity_text  # not person/org\n",
        "\n",
        "        corrected_entities.append({\n",
        "            'original': entity_text,\n",
        "            'corrected': corrected,\n",
        "            'start': start,\n",
        "            'end': end,\n",
        "            'label': label\n",
        "        })\n",
        "\n",
        "    return corrected_entities, new_entity_mappings\n",
        "\n",
        "def replace_entities_in_text(text, entities):\n",
        "    entities = sorted(entities, key=lambda x: x['start'], reverse=True)\n",
        "    for ent in entities:\n",
        "        text = text[:ent['start']] + ent['corrected'] + text[ent['end']:]\n",
        "    return text\n",
        "\n",
        "@time_it\n",
        "def main():\n",
        "    text = \"\"\"Theressa is a manager working for Wiliams. Ruthu Jenkinz is the mother of Fransis Waner and Kaitlyy Meeeers.\n",
        "    Donaa Gavln hasn't been seen for a while now by Nickol. THis is concerning! Allin is here btw\"\"\"\n",
        "\n",
        "    entities, new_entity_mappings = find_and_correct_entities(text)\n",
        "    corrected_text = replace_entities_in_text(text, entities)\n",
        "\n",
        "    print(\"\\nCorrected Text:\\n\", corrected_text)\n",
        "\n",
        "    print(\"\\nOld Entity Mappings:\\n\", json.dumps(forward_mapping, indent=2))\n",
        "    print(\"\\nNew Entity Mappings:\\n\", json.dumps(new_entity_mappings, indent=2))\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902,
          "referenced_widgets": [
            "6c5714475a1f417aa6cce8b42672d3bf",
            "fc647359cee94638bc823355289eaa8c",
            "8adec450c04d4f44a0bce1a3b1efa8cb",
            "31ba377d1fa347cba7e7f49927b259b3",
            "bc0d52fedfba47288fc58d288fde9d4c",
            "4f4ace23a7b24597937aed301f8e934d",
            "4d2dfc514e0649dbb716716dbb3ca6f6",
            "915ab422976442489c11b5dd800ec28b",
            "fa06cf577e2b45adb239507ace0ec15e",
            "8ead7f86e05d41a7b16666b75880eba2",
            "cfb8dd89dd4243d5804b2275fa2484a0"
          ]
        },
        "id": "OyNt6Yg7vw_H",
        "outputId": "f0c8092b-5b7a-4b7b-8720-44491c9fc8d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c5714475a1f417aa6cce8b42672d3bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Corrected Text:\n",
            " Theresa is a manager working for Wiliams. Ruth Jenkinz is the mother of Fransis Waner and Kaitlyn Meeeers.\n",
            "    Dona Gavln hasn't been seen for a while now by Nickol. THis is concerning! Allin is here btw\n",
            "\n",
            "Old Entity Mappings:\n",
            " {\n",
            "  \"names\": {\n",
            "    \"Theresa\": \"Aanik\",\n",
            "    \"Fransis\": \"Ben\",\n",
            "    \"Alvin\": \"Sam\",\n",
            "    \"Albin\": \"Bond\",\n",
            "    \"Kaitlyn\": \"Lora\",\n",
            "    \"Nickol\": \"Chris\",\n",
            "    \"Dona\": \"Alia\",\n",
            "    \"Ruth\": \"Fay\"\n",
            "  },\n",
            "  \"company\": {\n",
            "    \"Williams-Waller Co\": \"ibm\",\n",
            "    \"Tata Consultancy Services\": \"tcs\",\n",
            "    \"IBM\": \"oracle\"\n",
            "  }\n",
            "}\n",
            "\n",
            "New Entity Mappings:\n",
            " {\n",
            "  \"forward_mapping\": {\n",
            "    \"Wiliams\": \"Clark-Chung\",\n",
            "    \"Jenkinz\": \"Christopher\",\n",
            "    \"Waner\": \"Kayla\",\n",
            "    \"Meeeers\": \"Jennifer\",\n",
            "    \"Gavln\": \"Jason\",\n",
            "    \"Nickol\": \"Ingram and Sons\",\n",
            "    \"Allin\": \"Tina\"\n",
            "  },\n",
            "  \"reverse_mapping\": {\n",
            "    \"Clark-Chung\": \"Wiliams\",\n",
            "    \"Christopher\": \"Jenkinz\",\n",
            "    \"Kayla\": \"Waner\",\n",
            "    \"Jennifer\": \"Meeeers\",\n",
            "    \"Jason\": \"Gavln\",\n",
            "    \"Ingram and Sons\": \"Nickol\",\n",
            "    \"Tina\": \"Allin\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Execution time: 0.8523 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rapidfuzz import process, fuzz\n",
        "\n",
        "lst = ['Albin', 'Alvin', 'Alwin', ]\n",
        "matching_word = process.extractOne('Allin', lst, scorer=fuzz.ratio)\n",
        "print(matching_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_KruLjR3EmS",
        "outputId": "d84428c7-12f5-4132-8c19-9864673eb57a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Albin', 80.0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"\"\"I123-43GXP-APR-2024 I123-Kumar-Airfare-INTL-43GXP-TRV/DOH/SEA-APR-2024 I123-Kumar-Airfare-INTL-43GX-TRV/DOH/SEA-APR-2024\"\"\"\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "print(\"Entities:\")\n",
        "for ent in doc.ents:\n",
        "    print(f\"{ent.text} ({ent.label_})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fsKTXPKNeW-",
        "outputId": "4e7fbcc7-fa66-44f7-f343-3ac3571bbcf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities:\n",
            "I123-43GXP (PRODUCT)\n",
            "I123-Kumar-Airfare (PRODUCT)\n",
            "I123-Kumar-Airfare-INTL-43GX-TRV/DOH/SEA (PRODUCT)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from gliner import GLiNER\n",
        "@time_it\n",
        "def identify_entities():\n",
        "  model = GLiNER.from_pretrained(\"urchade/gliner_medium-v2.1\")\n",
        "  labels = [\"BookingCode\", \"Person\", \"TravelRoute\", \"Date\", \"Location Code\"]\n",
        "  text = \"\"\"I123-43GXP-APR-2024 I123-Kumar-Airfare-INTL-43GXP-TRV/DOH/SEA-APR-2024 I123-Kumar-Airfare-INTL-43GX-TRV/DOH/SEA-APR-2024\"\"\"\n",
        "  text = ' '.join(re.split(r'[-\\n]', text))\n",
        "\n",
        "  print(text, end='\\n\\n')\n",
        "  entities = model.predict_entities(text, labels=labels)\n",
        "  for entity in entities:\n",
        "    print(f\"{entity['text']} -> {entity['label']}\")\n",
        "\n",
        "identify_entities()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "9a9c4e7c415642fd879075edf5efcc4a",
            "07d4ac7c6f6e4aa4956d5915b44f9315",
            "038dad85288a444f8cc2683388602da4",
            "4a51e5dc9f264b029c826926e9eaa1d6",
            "086a164794744099b21a33c4d9dd0a61",
            "02f23c1704684efb9d8f0a84788341cc",
            "9b4e28f9d5c74bc788a62451175c1854",
            "9650a0b658244b45a49a34934075f80f",
            "f50ecb80884c47faaf3513154873e2ba",
            "641b3431f72c402f8446b99a64f95d95",
            "7ff55eeda5ac41c5899ddc24c7042586"
          ]
        },
        "id": "VWAsOjwvOwIe",
        "outputId": "0cadc1e3-364a-472e-a715-4d276ea8c176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a9c4e7c415642fd879075edf5efcc4a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I123 43GXP APR 2024 I123 Kumar Airfare INTL 43GXP TRV/DOH/SEA APR 2024 I123 Kumar Airfare INTL 43GX TRV/DOH/SEA APR 2024\n",
            "\n",
            "I123 43GXP -> BookingCode\n",
            "APR 2024 -> Date\n",
            "I123 -> Person\n",
            "Kumar -> Person\n",
            "INTL 43GXP -> BookingCode\n",
            "TRV/DOH/SEA -> TravelRoute\n",
            "APR 2024 -> Date\n",
            "I123 -> Person\n",
            "INTL 43GX -> BookingCode\n",
            "APR 2024 -> Date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gliner polars rapidfuzz pyxlsb fastexcel python-calamine gliner-spacy"
      ],
      "metadata": {
        "id": "ojE0I_a3V5AY",
        "outputId": "06fc1a8d-2f3a-4f42-c9e5-0b3563c3c2b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gliner\n",
            "  Downloading gliner-0.2.20-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (1.21.0)\n",
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting pyxlsb\n",
            "  Downloading pyxlsb-1.0.10-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting fastexcel\n",
            "  Downloading fastexcel-0.14.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting python-calamine\n",
            "  Downloading python_calamine-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting gliner-spacy\n",
            "  Downloading gliner_spacy-0.0.11-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gliner) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers>=4.38.2 in /usr/local/lib/python3.11/dist-packages (from gliner) (4.51.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.4 in /usr/local/lib/python3.11/dist-packages (from gliner) (0.31.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gliner) (4.67.1)\n",
            "Collecting onnxruntime (from gliner)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from gliner) (0.2.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from fastexcel) (18.1.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from python-calamine) (24.2)\n",
            "Requirement already satisfied: spacy>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from gliner-spacy) (3.8.5)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from gliner-spacy) (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from gliner-spacy) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from gliner-spacy) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (4.13.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (0.15.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (3.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->gliner) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->gliner) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->gliner) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->gliner) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gliner-spacy) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gliner-spacy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gliner-spacy) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gliner-spacy) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gliner-spacy) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gliner-spacy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gliner-spacy) (2.9.0.post0)\n",
            "Collecting coloredlogs (from onnxruntime->gliner)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime->gliner) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime->gliner) (5.29.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn->gliner-spacy) (2.2.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.0.0->gliner-spacy) (1.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn->gliner-spacy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn->gliner-spacy) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.0->gliner-spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.0->gliner-spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.0->gliner-spacy) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->gliner-spacy) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.4->gliner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.4->gliner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.4->gliner) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.4->gliner) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.0.0->gliner-spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.0.0->gliner-spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.0.0->gliner-spacy) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.0.0->gliner-spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.0.0->gliner-spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.0.0->gliner-spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.0.0->gliner-spacy) (7.1.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->gliner)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy>=3.0.0->gliner-spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.0.0->gliner-spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.0.0->gliner-spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.0.0->gliner-spacy) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3.0.0->gliner-spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.0.0->gliner-spacy) (0.1.2)\n",
            "Downloading gliner-0.2.20-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyxlsb-1.0.10-py2.py3-none-any.whl (23 kB)\n",
            "Downloading fastexcel-0.14.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_calamine-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (886 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m886.0/886.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gliner_spacy-0.0.11-py3-none-any.whl (6.8 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyxlsb, rapidfuzz, python-calamine, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, fastexcel, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, onnxruntime, nvidia-cusolver-cu12, gliner, gliner-spacy\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed coloredlogs-15.0.1 fastexcel-0.14.0 gliner-0.2.20 gliner-spacy-0.0.11 humanfriendly-10.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.22.0 python-calamine-0.3.2 pyxlsb-1.0.10 rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import time\n",
        "import polars as pl\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from gliner import GLiNER\n",
        "\n",
        "def time_it(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f\"\\nExecution time: {end - start:.4f} seconds\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "model = GLiNER.from_pretrained(\"gliner-community/gliner_small-v2.5\")\n",
        "\n",
        "labels = [\n",
        "    \"Person name\", \"Organization name\",\n",
        "    \"BookingCode\", \"Location\", \"Location Code\",\n",
        "    \"Generic ID\", \"TravelRoute\"\n",
        "]\n",
        "\n",
        "@time_it\n",
        "def reading_descriptive_excel():\n",
        "  df_pd = pd.read_excel(\"Desc-Data-Testing-1000.xlsx\", engine=\"calamine\")\n",
        "  df = pl.from_pandas(df_pd)\n",
        "\n",
        "  if \"DESCRIPTION\" not in df.columns:\n",
        "      raise ValueError(\"Missing 'DESCRIPTION' column in the Excel file\")\n",
        "\n",
        "  results = []\n",
        "\n",
        "  for desc in tqdm(df[\"DESCRIPTION\"].to_list(), desc=\"Extracting Entities\"):\n",
        "      entities = model.predict_entities(str(desc), labels=labels)\n",
        "      results.append({\n",
        "          \"text\": desc,\n",
        "          \"entities\": entities\n",
        "      })\n",
        "\n",
        "  with open(\"extracted_entities.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "      json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "  print(\"\\n\\n✅ JSON saved as 'extracted_entities.json'\")\n",
        "\n",
        "reading_descriptive_excel()"
      ],
      "metadata": {
        "id": "pgQPACgmWCAo",
        "outputId": "635ab4c1-acc5-416b-86b9-337c9e0e3186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196,
          "referenced_widgets": [
            "20533d86030b4ccfb538cefdb3787e0d",
            "eddc9c32ef0545aaaecfbff03d196dbc",
            "014ccbc715974ad987e316949326d9c7",
            "eb4b35721bd941ed8121f81a87f68219",
            "9924900b79ba4ffb82dca4c69198428d",
            "1a4d663f21064321bdc4cdd16e2a6701",
            "b9dc732bddcd4df2af8cc53ec71880df",
            "d55b3c526b054e7e915f8ba072e54342",
            "1598aef765a14914b8654811a61c49b2",
            "2a8e7b9df80a4dbab7c52638311891b5",
            "55eecc50c08d4592bf9020488847d6e8"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20533d86030b4ccfb538cefdb3787e0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Entities:   0%|          | 0/1004 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Extracting Entities: 100%|██████████| 1004/1004 [06:39<00:00,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "✅ JSON saved as 'extracted_entities.json'\n",
            "\n",
            "Execution time: 399.7302 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "from gliner import GLiNER\n",
        "import json\n",
        "import random\n",
        "import string\n",
        "import gzip\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "model = GLiNER.from_pretrained(\"gliner-community/gliner_small-v2.5\")\n",
        "\n",
        "label_to_fake_category = {\n",
        "    \"Person\": \"names\",\n",
        "    \"BookingCode\": \"ID-code\",\n",
        "    \"Location\": \"location\",\n",
        "    \"TravelRoute\": \"location\",\n",
        "    # \"Date\": None  # Skip this\n",
        "}\n",
        "\n",
        "def load_faker_data(path=\"faker_data_v3.json.gz\"):\n",
        "    with gzip.open(path, 'rt', encoding='utf-8') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def generate_booking_code():\n",
        "    return \"ID-\" + ''.join(random.choices(string.digits, k=6))\n",
        "\n",
        "def generate_fake_value(label, faker_data, used_fakes):\n",
        "    if label == \"BookingCode\":\n",
        "        while True:\n",
        "            code = generate_booking_code()\n",
        "            if code not in used_fakes:\n",
        "                used_fakes.add(code)\n",
        "                return code\n",
        "    category = label_to_fake_category.get(label)\n",
        "    if category not in faker_data:\n",
        "        raise ValueError(f\"No fake data available for label '{label}'\")\n",
        "    for val in faker_data[category]:\n",
        "        if val not in used_fakes:\n",
        "            used_fakes.add(val)\n",
        "            return val\n",
        "    raise ValueError(f\"Exhausted fake values for label '{label}'\")\n",
        "\n",
        "def anonymize_excel_description(input_excel_path: str, output_json_path: str = None):\n",
        "    df = pl.read_excel(input_excel_path)\n",
        "    if \"Description\" not in df.columns: raise ValueError(\"Missing 'Description' column in the Excel file\")\n",
        "\n",
        "    input_filename = os.path.splitext(os.path.basename(input_excel_path))[0]\n",
        "    mapping_path = f\"{input_filename}.mapping.json\"\n",
        "    anonymized_path = f\"{input_filename}.anonymized.json\"\n",
        "    restored_path = f\"{input_filename}.restored.json\"\n",
        "\n",
        "    faker_data = load_faker_data()\n",
        "\n",
        "    forward_mapping = {}\n",
        "    reverse_mapping = {}\n",
        "    used_fakes = set()\n",
        "\n",
        "    results = []\n",
        "    restored_results = []\n",
        "\n",
        "    for desc in tqdm(df[\"Description\"].to_list(), desc=\"Extracting and Anonymizing\"):\n",
        "        original_text = ' '.join(desc.split('-'))\n",
        "        entities = model.predict_entities(str(original_text), labels=list(label_to_fake_category.keys()))\n",
        "\n",
        "        replacements = []\n",
        "\n",
        "        for ent in sorted(entities, key=lambda x: x['start'], reverse=True):\n",
        "            label = ent['label']\n",
        "            text = ent['text']\n",
        "\n",
        "            if label == \"Date\": continue\n",
        "\n",
        "            if text not in forward_mapping:\n",
        "                fake_value = generate_fake_value(label, faker_data, used_fakes)\n",
        "                forward_mapping[text] = fake_value\n",
        "                reverse_mapping[fake_value] = text\n",
        "            else:\n",
        "                fake_value = forward_mapping[text]\n",
        "\n",
        "            replacements.append((ent['start'], ent['end'], fake_value))\n",
        "\n",
        "        # Anonymize\n",
        "        anon_text = original_text\n",
        "        for start, end, fake in replacements:\n",
        "            anon_text = anon_text[:start] + fake + anon_text[end:]\n",
        "\n",
        "        results.append({\"original\": original_text, \"anonymized\": anon_text})\n",
        "        # Restore\n",
        "        restored = anon_text\n",
        "        for fake_val, original_val in reverse_mapping.items():\n",
        "            restored = restored.replace(fake_val, original_val)\n",
        "        restored_results.append({\"anonymized\": anon_text, \"restored\": restored})\n",
        "\n",
        "    with open(mapping_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\"forward_mapping\": forward_mapping, \"reverse_mapping\": reverse_mapping}, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    with open(anonymized_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    with open(restored_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(restored_results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\\n✅ Anonymization complete.\\n- Mapping: {mapping_path}\\n- Anonymized: {anonymized_path}\\n- Restored: {restored_path}\")\n",
        "\n",
        "anonymize_excel_description(\"Desc-Data-Testing.xlsx\")\n"
      ],
      "metadata": {
        "id": "GwjoaFDoWT6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "from gliner import GLiNER\n",
        "print(\"🔍 Loading GLiNER model once outside...\")\n",
        "gliner_model = GLiNER.from_pretrained(\"gliner-community/gliner_small-v2.5\")\n",
        "end = time.time()\n",
        "print(f\"✅ Model loaded in {end - start:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566,
          "referenced_widgets": [
            "431ddacf7baf4c9aad18c98310c0f126",
            "c7801ee466004777b6edb8d95662d8d6",
            "add29d58d15e41eea764ebf248f82087",
            "dd9aa95389a54fb1b746b967b1ad625a",
            "718b7baac2414d8296d7c500236b63a1",
            "f33710b4a2f94b7f83307d411adee18d",
            "9f6e2e44a9e044e49e3cfd8cf246c101",
            "00a75900e1d24f259ae80fc997bf13bb",
            "efea51bb228e4ece94003cb03b89fe2f",
            "b00796c78fa64fc686cdcaeb949f60ae",
            "6aaf39d7cda041ddbdda53243fe3868b",
            "2451decc84104fc1902423c262b43bf1",
            "a86bf731f70c4391b537672891dd7d6b",
            "902e355f5205411e94d861353a823214",
            "67852404bbed47198233248f2ad4d753",
            "b1d7861a40bc4555b886d3463f0c122e",
            "b4424049a88543c79acd923ef0a7c104",
            "cc0006e363a94486853a111b7123083f",
            "55c4fc4f67d7411d9e644a38c9d446a6",
            "e641e0e1b0974745b3af7359d1794fb1",
            "f45a444d330148a7b8aaad946cf05fb1",
            "1637d557a0164900be43faf54f3327da",
            "9c50163c5eab4fd2b80c6c4bd4cdc63d",
            "071f950a7343404798f80234738bf746",
            "c9a758068dca4a5591a143908a066340",
            "69cccb4e381c4ff994feaf55919313fe",
            "70f046c576b845e29f54b1c5ce9b96b3",
            "80fdddea27fe492882b7d38c7b8b6690",
            "90132f24bfa240cf951b81ca45ee28b0",
            "09e632803abc4310932b228f2d3ed00a",
            "7e6c7921295147c7ace40a93e2596a9b",
            "13a5aa7ab8264e35ae3aa4912054cf10",
            "0637283b566d4dd2938a3b5d3f80b2fa",
            "0acbf0abdcef4cbfb4f66ace31e36275",
            "3dbe3b7fcf044ebbad73217069523fd0",
            "accb8a9dfcbb4758b0ed847bf904e3d4",
            "c89c41adf0f34b59b4f5524f2cbc22cc",
            "ed22396ae4aa4e46a040f773643967e9",
            "d6524da4f56a410c811001d48e840a0e",
            "dd5275a17cbc496da10162b28a6caa5b",
            "17c8f17dc8a044b1b0f003c679d44b21",
            "6e72deba0269482693e1030aaac58fc3",
            "6bd07d77f004441b9a7539a3593316d7",
            "5b3bdbd35331457e939e66c7c9688a40",
            "938df6a5704343d3911c850cc15e6050",
            "c4e2510182da469faa74a02a76e5574a",
            "36392021543d4bfd80189c6eb0933887",
            "e2622760982645b6b621615507c45d22",
            "5d34e471388f478cabd83dd8212cb06b",
            "5ebe22b5e9c542c1b929c5f9437a7779",
            "ef91a26beedf417b9cccde970bde4aeb",
            "d47c3c87bd9c46a99ca8bd1d9d91199e",
            "5809388a25a245f3964c1c4644cda90a",
            "144d1966e5014363a501bc0c4675e5e1",
            "5077c0a3b64647a9a169e9acda4c9c49",
            "3497a330051b4915ae28924af75e8361",
            "9e387e15645d496ea89b7c70e4afc80e",
            "04a86873f4db498fa9610bf8bab020f4",
            "64f78865e98a4a5faf867b06c99bb910",
            "0666f6191be84d4ba61e0c67bb508a0e",
            "7fd12b1fd72b4436add34c8a046ff988",
            "1d387b74eb0948f287537b5aad701caa",
            "966d8ae99a694b72b1eea0b30ea23794",
            "a1275077389149d28877f0b6e196619d",
            "ac839ae06fb340a68ee10cf79bc717f1",
            "e337f0b0367842f3962d5dfaf4c29f22",
            "ea980712284d426eaf60cb79e36019b4",
            "489b75973b9a4a549cb2e2fb99bfacc8",
            "af4f5bcf37d94fd5bdd5040cd1c1fa73",
            "d34fd1cc1ed440b8a8f3c14b67ed4135",
            "a1a8aeaf19f5474a9c6a63f56693604f",
            "484f7e35d4464c7da567d2d5cea872eb",
            "bb9e3e6cd162417b8ed1dd46861a1d6c",
            "5b014ca6369546f0a6db0657a7792a92",
            "df347ad839594991880b57b5bd115c0c",
            "899778de26cc46d99c17e27f5abf8c40",
            "bab722e82b26458699ea0496eadf4fd0",
            "a59c8eb4d7eb4adab4f9093e89e12c68",
            "f09cb3c2e746446f9dd0bf308ea022f5",
            "88e4a4a5ee8f4151add8afc965ad3f14",
            "f5b8709a2cec4220acb07b3f474498f4",
            "e5fb6aa2d10e47df83f2f607a8d1e4f9",
            "421d3c059c31403b94d1902fc294dd38",
            "ec4bde669dc94d5e9a9fecca0f58ca44",
            "421f8eeadb194522b7295e47ddc06fc5",
            "cf9c0886588541f3a2415841f9eeeb41",
            "21fac192c6474be999daf1c4612e3f52",
            "26af9c1c36a844afbe28391b49cd41af",
            "d06dea89e1d149d49105d53107f24444",
            "b37ba72a109d493996d31a6452b3809c",
            "efbc9bc77aca49459c4139a952b52959",
            "c594e76632a34eaeb525e2763d42ef2d",
            "78c4b45dd5d24cb6bbee3189b707a75e",
            "8968e23c0b814689b8529e1001f33f1e",
            "953f1f3023134712ad6f5162cd6ff97f",
            "c1bfca09a18a49b7895aaee79b742ae3",
            "ba20bfd563e1462bb8b7eead61b7fe90",
            "4f3c12d462064d36b13febffc6c90820",
            "63446c3a4db4414bada4f79371ecf5f5",
            "b10bca9cfc7a493ab27fdbf4bbfca3e9",
            "3b15c967508d496397d87d98d61b2b41",
            "0571bffd33574dd1b9b89454323550cf",
            "d913bfe73af644bdabc510880347151f",
            "c2c9879e8e0a452681224182c18d6052",
            "8d34046c4f60439f96835804ad91b35c",
            "ce47fe1904a0433c813e00513c765173",
            "79d7e7a172a94fed87d07f079cf08097",
            "622ec29160604f088baea7809d29d8dc",
            "2f434163e33b4f88a6e9caf00ccb4ace",
            "e4f4d8498fee4bfa92f5a7e134028e39",
            "0dd1c91edc3d45b381d9224886403641",
            "ea63b020484c4893bb28e741b9190ec1",
            "4fe9989c55a1412b92281b0a9bc3073d",
            "1db4ad6bfd4c44ecbf649099f6ccf9ed",
            "c8bb67eedc7048998e01f397c7603591",
            "6cc4d3b8445b48dfb1731a961024d3e2",
            "d2d660e88b854d2b95d76026c537745b",
            "51f4e0fc5b8a4bb08c1c0f386f812043",
            "88368945684d428cb17f1893da75d3ac",
            "33e9967bde724fdb8aa7aab0a1243de2",
            "438e5715761a4e28b2c85c5bd4bc22cf",
            "731b6d502b0c49768c9ea823638be10e",
            "fd248a74306141f591505862f64ed07f",
            "3187c3b4a2404185a3ab723df5edba91",
            "30285d419a034ef2b378e48744ab96d5",
            "dbba3d213fbc42fa951c8b098321c24c",
            "370ab81613f14c988d1f7084c0b6485c",
            "954b6b78fa09463fba19cdb1e99edce7",
            "cbacb6e9a1ad449580933f66198efe67",
            "ba729f9d2e9a4d36845bcf039cfd7ffe",
            "1872c4d750d2462abaac6f6c69b248b6",
            "4b96c516635a4e5b80f7819b15f9048a"
          ]
        },
        "id": "4RUIfgmEZ8Z5",
        "outputId": "c3bb1d30-4d90-49de-d867-6265a5e78892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Loading GLiNER model once outside...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "431ddacf7baf4c9aad18c98310c0f126"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2451decc84104fc1902423c262b43bf1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c50163c5eab4fd2b80c6c4bd4cdc63d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/23.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0acbf0abdcef4cbfb4f66ace31e36275"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "938df6a5704343d3911c850cc15e6050"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/970 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3497a330051b4915ae28924af75e8361"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "models_comparison.png:   0%|          | 0.00/156k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea980712284d426eaf60cb79e36019b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/664M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a59c8eb4d7eb4adab4f9093e89e12c68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "gliner_config.json:   0%|          | 0.00/676 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d06dea89e1d149d49105d53107f24444"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/8.65M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b10bca9cfc7a493ab27fdbf4bbfca3e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0dd1c91edc3d45b381d9224886403641"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "731b6d502b0c49768c9ea823638be10e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded in 56.39 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing identification of entities in descriptive data\n",
        "import re\n",
        "import polars as pl\n",
        "import pandas as pd\n",
        "from functools import wraps\n",
        "from collections import Counter\n",
        "from typing import List, Tuple, Dict, Any\n",
        "\n",
        "class EntityExtractor:\n",
        "    def __init__(self, model):\n",
        "        print(\"🔍 Loading GLiNER model...\")\n",
        "        self.model = model\n",
        "        self.labels = [\"Name of Person\", \"Organization\", \"Location\", \"BookingID\", \"ID\",]\n",
        "        self.descriptive_keywords = {\n",
        "            \"description\", \"remarks\", \"notes\", \"comments\", \"observations\", \"details\", \"summary\", \"explanation\", \"skills\",\n",
        "            \"reviews\", \"feedback\", \"testimonials\", \"opinions\", \"assessment\", \"suggestions\", \"experience\", 'subskill', 'subkills',\n",
        "            \"incident_report\", \"case_notes\", \"audit_notes\", \"findings\", \"status_update\", \"history\", \"progress_report\", \"skill\",\n",
        "            \"additional_info\", \"clarifications\", \"justification\", \"annotations\", \"excerpts\", \"statement\", \"explanation_text\", \"reason\"\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def time_it(func):\n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            print(f\"\\n⏱️ Starting '{func.__name__}'...\")\n",
        "            start = time.time()\n",
        "            result = func(*args, **kwargs)\n",
        "            end = time.time()\n",
        "            print(f\"✅ Finished '{func.__name__}' in {end - start:.2f} seconds.\")\n",
        "            return result\n",
        "        return wrapper\n",
        "\n",
        "    def analyze_batch(self, texts: List[str]) -> List[List[Dict[str, Any]]]:\n",
        "        \"\"\"Process a batch of texts and return list of entity dictionaries with positions.\"\"\"\n",
        "        results = []\n",
        "        for text in texts:\n",
        "            try:\n",
        "                entities = self.model.predict_entities(text, self.labels)\n",
        "                results.append([\n",
        "                    {\n",
        "                        \"label\": ent[\"label\"],\n",
        "                        \"text\": ent[\"text\"],\n",
        "                        \"start\": ent[\"start\"],\n",
        "                        \"end\": ent[\"end\"]\n",
        "                    }\n",
        "                    for ent in entities\n",
        "                ])\n",
        "            except Exception: results.append([])\n",
        "        return results\n",
        "\n",
        "    @time_it\n",
        "    def process_excel(self, file_path: str, batch_size: int = 100) -> dict:\n",
        "        print(f\"📥 Reading Excel file: {file_path}\")\n",
        "        df_pd = pd.read_excel(file_path, engine=\"calamine\")\n",
        "\n",
        "        column_entities = {}\n",
        "\n",
        "        for col in df_pd.columns:\n",
        "            if any(re.search(rf\"\\b{re.escape(keyword)}\\b\", col, re.IGNORECASE) for keyword in self.descriptive_keywords):\n",
        "                column_entities[col] = \"Descriptive\"\n",
        "                continue\n",
        "\n",
        "            if 'id' in col.lower():\n",
        "                column_entities[col] = 'ID'\n",
        "                continue\n",
        "\n",
        "            values = df_pd[col].dropna().astype(str).unique()[:5]\n",
        "            values = [str(v) for v in values if str(v).strip()]\n",
        "            combined_text = \". \".join(values)\n",
        "\n",
        "            print(f\"🔍 Analyzing column: {col}\")\n",
        "            entities = self.analyze_batch([combined_text])[0]\n",
        "            label_counter = Counter(ent[\"label\"] for ent in entities)\n",
        "\n",
        "            if label_counter:\n",
        "                most_common_label, _ = label_counter.most_common(1)[0]\n",
        "                column_entities[col] = most_common_label\n",
        "            else:\n",
        "                column_entities[col] = None\n",
        "\n",
        "        print(f\"\\n🧾 Finished analyzing {len(df_pd.columns)} columns.\")\n",
        "        return column_entities\n",
        "\n",
        "\n",
        "    @time_it\n",
        "    def save_to_parquet(self, df: pl.DataFrame, output_path: str):\n",
        "        print(f\"💾 Saving to {output_path}\")\n",
        "        df.write_parquet(output_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"SO(real).xlsx\"\n",
        "    output_path = \"entities_with_positions.parquet\"\n",
        "    start = time.time()\n",
        "    extractor = EntityExtractor(gliner_model)\n",
        "    df = extractor.process_excel(file_path)\n",
        "    end = time.time()\n",
        "    print(df)\n",
        "    print(f\"Total time: {end - start:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPw80fYaJPX_",
        "outputId": "4abcdb5a-94c6-4c8c-b894-11ee321a6f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Loading GLiNER model...\n",
            "\n",
            "⏱️ Starting 'process_excel'...\n",
            "📥 Reading Excel file: SO(real).xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Analyzing column: RR Status\n",
            "🔍 Analyzing column: RR Type\n",
            "🔍 Analyzing column: Priority\n",
            "🔍 Analyzing column: UST - Role\n",
            "🔍 Analyzing column: City\n",
            "🔍 Analyzing column: State\n",
            "🔍 Analyzing column: Country\n",
            "🔍 Analyzing column: Altenate Location\n",
            "🔍 Analyzing column: Campus\n",
            "🔍 Analyzing column: Job Grade\n",
            "🔍 Analyzing column: RR Start Date\n",
            "🔍 Analyzing column: RR End Date\n",
            "🔍 Analyzing column: Account Name\n",
            "🔍 Analyzing column: Project Name\n",
            "🔍 Analyzing column: WFME\n",
            "🔍 Analyzing column: HM\n",
            "🔍 Analyzing column: AM\n",
            "🔍 Analyzing column: Billable\n",
            "🔍 Analyzing column: Actual Bill Rate\n",
            "🔍 Analyzing column: Actual Currency\n",
            "🔍 Analyzing column: Bill Rate\n",
            "🔍 Analyzing column: Billing Frequency\n",
            "🔍 Analyzing column: Currency\n",
            "🔍 Analyzing column: Target ECR\n",
            "🔍 Analyzing column: Accepted Resource Type\n",
            "🔍 Analyzing column: Replacement Type\n",
            "🔍 Analyzing column: Exclusive to UST\n",
            "🔍 Analyzing column: Contract to Hire\n",
            "🔍 Analyzing column: Client Job Title\n",
            "🔍 Analyzing column: Client Evaluation\n",
            "🔍 Analyzing column: OBU Name\n",
            "🔍 Analyzing column: Project Start Date\n",
            "🔍 Analyzing column: Project End Date\n",
            "🔍 Analyzing column: Raised On\n",
            "🔍 Analyzing column: RR Finance Approved Date\n",
            "🔍 Analyzing column: WFM Approved Date\n",
            "🔍 Analyzing column: Cancelled Reasons\n",
            "🔍 Analyzing column: Edit Requested Date\n",
            "🔍 Analyzing column: Resubmitted Date\n",
            "🔍 Analyzing column: Duration in Edit(Days)\n",
            "🔍 Analyzing column: # of Edits\n",
            "🔍 Analyzing column: Resubmitted Reason2\n",
            "🔍 Analyzing column: Recruiter Name\n",
            "🔍 Analyzing column: Recruitment Type\n",
            "🔍 Analyzing column: Project Type\n",
            "🔍 Analyzing column: Last Updated On\n",
            "🔍 Analyzing column: Last Activity Date\n",
            "🔍 Analyzing column: Last Activity\n",
            "🔍 Analyzing column: Contract Category\n",
            "🔍 Analyzing column: Matching Resources Count (Score 50% and above)\n",
            "🔍 Analyzing column: Hiring request Submit Date (MTE)\n",
            "🔍 Analyzing column: Marked To External\n",
            "🔍 Analyzing column: MTE Status\n",
            "🔍 Analyzing column: External - System\n",
            "🔍 Analyzing column: SO Initiator Name\n",
            "🔍 Analyzing column: External Status\n",
            "🔍 Analyzing column: Allocation Project Start Date\n",
            "🔍 Analyzing column: Allocation Project End Date\n",
            "🔍 Analyzing column: Practice Line\n",
            "🔍 Analyzing column: TA Cluster Lead\n",
            "🔍 Analyzing column: RR Ageing\n",
            "🔍 Analyzing column: Duration before Cancellation\n",
            "🔍 Analyzing column: Edit Requested \n",
            "🔍 Analyzing column: Outgoing Employee Name\n",
            "🔍 Analyzing column: Cancel Requested\n",
            "🔍 Analyzing column: Internal/External\n",
            "🔍 Analyzing column: Country Cluster\n",
            "🔍 Analyzing column: Parent Account\n",
            "🔍 Analyzing column: Vertical\n",
            "🔍 Analyzing column: CRM Status\n",
            "🔍 Analyzing column: Engagement Type\n",
            "🔍 Analyzing column: Expired RR\n",
            "🔍 Analyzing column: Expired Project\n",
            "🔍 Analyzing column: Lead Time Bucket\n",
            "🔍 Analyzing column: RH_Recruiter Name\n",
            "🔍 Analyzing column: Semicon Accounts\n",
            "🔍 Analyzing column: RR start date wise\n",
            "🔍 Analyzing column: Special Focus SO#\n",
            "🔍 Analyzing column: Revenue Loss_Based on SF\n",
            "🔍 Analyzing column: Recalculating RR Ageing\n",
            "🔍 Analyzing column: RR Aging\n",
            "🔍 Analyzing column: Cluster\n",
            "🔍 Analyzing column: WFM Lead / Onsite SPOCS\n",
            "🔍 Analyzing column: Status\n",
            "🔍 Analyzing column: JD Quality\n",
            "🔍 Analyzing column: Change in Requirement\n",
            "🔍 Analyzing column: SO Complexity\n",
            "🔍 Analyzing column: SO Lead Time\n",
            "🔍 Analyzing column: External Tagging TAT\n",
            "🔍 Analyzing column: Profile flow \n",
            "🔍 Analyzing column: Delay In Techincal interview\n",
            "🔍 Analyzing column: L1 Rejection\n",
            "🔍 Analyzing column: L2 Rejection\n",
            "🔍 Analyzing column: Backup Offer\n",
            "🔍 Analyzing column: Offer Backout\n",
            "🔍 Analyzing column: Quality of Demand\n",
            "🔍 Analyzing column: Quality of Sourcing\n",
            "🔍 Analyzing column: Quality of Shortlisting\n",
            "🔍 Analyzing column: Reasons\n",
            "\n",
            "🧾 Finished analyzing 120 columns.\n",
            "✅ Finished 'process_excel' in 32.83 seconds.\n",
            "{'Resource Request ID': 'ID', 'RR Status': None, 'RR Type': 'Organization', 'Priority': 'ID', 'UST - Role': 'Organization', 'City': 'Location', 'State': 'Location', 'Country': 'Location', 'Altenate Location': 'Location', 'Campus': 'Location', 'Job Grade': 'ID', 'RR Start Date': None, 'RR End Date': None, 'Account Name': 'Organization', 'Project ID': 'ID', 'Project Name': 'Organization', 'WFME': 'Name of Person', 'WFME ID': 'ID', 'HM': 'Name of Person', 'HM ID': 'ID', 'AM': 'Name of Person', 'AM ID': 'ID', 'Billable': None, 'Actual Bill Rate': None, 'Actual Currency': None, 'Bill Rate': None, 'Billing Frequency': 'Name of Person', 'Currency': None, 'Target ECR': None, 'Accepted Resource Type': None, 'Replacement Type': None, 'Exclusive to UST': None, 'Contract to Hire': None, 'Client Job Title': 'Organization', 'UST Role Description': 'Descriptive', 'Job Description': 'Descriptive', 'Notes for WFM or TA': 'Descriptive', 'Client Evaluation': None, 'OBU Name': 'Organization', 'Project Start Date': None, 'Project End Date': None, 'Raised On': None, 'RR Finance Approved Date': None, 'WFM Approved Date': None, 'Cancelled Reasons': None, 'Edit Requested Date': None, 'Resubmitted Date': None, 'Duration in Edit(Days)': None, '# of Edits': None, 'Resubmitted Reason2': 'Location', 'Recruiter Name': 'Name of Person', 'Recruiter ID': 'ID', 'Recruitment Type': 'Location', 'Project Type': 'Organization', 'Last Updated On': None, 'Last Activity Date': None, 'Last Activity': None, 'Contract Category': None, 'Mandatory Skills': 'Descriptive', 'Optional Skills': 'Descriptive', 'RR Skill Group': 'Descriptive', 'Matching Resources Count (Score 50% and above)': None, 'Hiring request Submit Date (MTE)': None, 'Marked To External': None, 'MTE Status': None, 'External - System': 'Location', 'SO Initiator Name': 'Name of Person', 'SO Initiator ID': 'ID', 'External Status': None, 'Allocation Project ID': 'ID', 'Allocation Project Start Date': None, 'Allocation Project End Date': None, 'Practice Line': 'Organization', 'TA Cluster Lead': 'ID', 'RR Ageing': 'BookingID', 'Duration before Cancellation': None, 'Edit Requested ': None, 'Outgoing Employee Id': 'ID', 'Outgoing Employee Name': 'Name of Person', 'Cancel Requested': None, 'Internal/External': 'Location', 'Country Cluster': 'Location', 'Parent Account': 'Organization', 'Vertical': 'Organization', 'CRM Status': None, 'Engagement Type': 'ID', 'Skill Category': 'Descriptive', 'Skill Cluster': 'Descriptive', 'Sub Skill Cluster': 'Descriptive', 'SubSkill': 'Descriptive', 'Expired RR': None, 'Expired Project': None, 'Lead Time Bucket': None, 'RH_Recruiter ID': 'ID', 'RH_Recruiter Name': 'Name of Person', 'Semicon Accounts': None, 'RR start date wise': None, 'Special Focus SO#': None, 'Revenue Loss_Based on SF': None, 'Recalculating RR Ageing': 'BookingID', 'RR Aging': None, 'Cluster': 'Organization', 'WFM Lead / Onsite SPOCS': 'Name of Person', 'Status': None, 'Comments': 'Descriptive', 'JD Quality': None, 'Change in Requirement': None, 'SO Complexity': None, 'SO Lead Time': None, 'External Tagging TAT': None, 'Profile flow ': None, 'Delay In Techincal interview': None, 'L1 Rejection': None, 'L2 Rejection': None, 'Backup Offer': None, 'Offer Backout': None, 'Quality of Demand': None, 'Quality of Sourcing': None, 'Quality of Shortlisting': None, 'Reasons': None}\n",
            "Total time: 32.83 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "\n",
        "import time\n",
        "from gliner import GLiNER\n",
        "\n",
        "start = time.time()\n",
        "# model = GLiNER.from_pretrained(\n",
        "#     \"juampahc/gliner_multi-v2.1-onnx\",\n",
        "#     load_onnx_model=True,\n",
        "#     onnx_model_file=\"model.onnx\"\n",
        "# )\n",
        "model_small = GLiNER.from_pretrained(\n",
        "    \"juampahc/gliner_multi-v2.1-onnx\",\n",
        "    load_onnx_model=True,\n",
        "    onnx_model_file=\"model.onnx\"\n",
        ")\n",
        "end = time.time()\n",
        "print(f'📈📈Model loading time: {end - start:.2f}')\n",
        "\n",
        "labels = [\"Name of Person\", \"Organization\", \"Location\", \"TravelRoute\", \"ID\"]\n",
        "\n",
        "start_time = time.time()\n",
        "entities = model.predict_entities(string, labels, flat_ner=True, threshold=0.5)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"\\n⏱️ Inference Time: {end_time - start_time:.4f} seconds\")\n",
        "print(\"🔍 Detected Entities:\")\n",
        "for ent in entities:\n",
        "    print(f\"🔹 '{ent['text']}' → 🏷️ {ent['label']} 📍({ent['start']}-{ent['end']})\")"
      ],
      "metadata": {
        "id": "_vIB4zdMA52L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string = \"\"\"\n",
        "\"Looking for a Cybersecurity Project Manager (Cybersecurity PM) who could involve in planning, executing, and overseeing cybersecurity projects to safeguard an organization's digital assets and data, ensuring compliance, and mitigating risks.\n",
        "\n",
        "Responsibilities\n",
        "\n",
        "•\tDefining project scope, objectives, and deliverables.\n",
        "•\tDeveloping detailed project plans and timelines.\n",
        "•\tTracking project progress, identifying potential issues, and implementing corrective actions.\n",
        "•\tWorking closely with technical teams, stakeholders, and management.\n",
        "•\tCommunicating project status, risks, and issues effectively.\n",
        "\n",
        "Skillset\n",
        "\n",
        "•\t5+ Years of Agile PM expertise\n",
        "•\tUnderstanding of cybersecurity principles, technologies, and threats.\n",
        "•\tAbility to effectively communicate with technical and non-technical audiences.\n",
        "•\tUnderstanding of risk assessment and mitigation techniques.\n",
        "\n",
        "\"\n",
        "Same as above\n",
        "The ideal candidate will be skilled in: • Process discovery and optimization • Data analysis, visualization, and dashboarding • Identifying opportunities to improve our processes and systems, especially in finance domain. A strong business architecture mindset is a plus, with experience or familiarity in Various ERP system like Oracle and SAP. Expertise in various tools like  Process Mining tools • BizzDesign / Business Architecture tools • Power BI • Power Apps • Qualtrics Analysis • User journey mapping • Problem statement generation • Developing actionable plans\n",
        "\"\n",
        "The Opportunity I am looking for a Technical Data Analyst who has hands on experience migrating Sales users and Sales data like Accounts, Opportunities, Contacts from Salesforce.com to Dynamics 365. He should also have strong experience in data profiling, data integration, transformations, understanding how data impacts downstream systems like Sales and Finance data warehouses/data lakes, reporting etc.\n",
        "What You’ll Do\n",
        "• Work with Customer internal data teams and business teams to decipher the data related requirements for the project • Need to have hands on experience in understanding the SFDC to Dynamics field mappings & data models. • Design end to end strategy to stitch objects from various systems and financial KPIs • Building integrations between SFDC, Dynamics, SAP ECC and DBX for Power BI reporting and financial metrics. • Leverage data sources across the enterprise to build sophisticated and insightful analyses and data models for Sales, Finance and Marketing • Need to have hands on experience with migrating Marketing and Sales data and users from Salesforce.com to Dynamics • Work with the Product Managers to build detailed data requirements/specifications for Engineering teams to build the solution in downstream data management and reporting systems. • Need to understand the migration challenges from similar experiences and build creative solutions to help with migrating data from SFDC to Dynamics. • Consolidate requirements and suggest building new reporting capabilities for analysis using advanced BI techniques and tools. • Proactively collaborate with various product managers to bring a perspective on all data we work on. • Conducts QA testing and validations and provides inputs to the Engineering teams – along with the PdMs • Support Release Planning, scheduling backlog items into regular releases aligned to business priority while working with the PdM’s • Supports production cutover and Production acceptance testing. • Supports post go live sessions with business, addresses and drives technical issues raised during Hyper Care. This will be done with the PdM’s and Engineering teams.\n",
        "\n",
        "Qualifications\n",
        "• Requires bachelor’s degree. Preferred candidates will have a major in computer science, MBA from reputable institution or equivalent experience. • 4+ years of data analytics, ‘data BSA’ or data product management experience with solid understanding of how to deliver data solutions in an agile environment. • Strong proficiency in SQL/SparkSQL/Python to query and manipulate large data sets. Experience with platforms like Databricks, Power BI and Tableau. • You are a self-starter, independent, hard worker, with a high degree of motivation to go above and beyond the task at hand. You anticipate and creatively implement next steps in a complex environment. • You have mastered the ability to influence outcomes, navigate, mediate to consensus with integrity. You possess great interpersonal communication, presentation skills, and social skills and a solid sense of humor. • Data requirement writing skills: collecting, prioritizing, and gathering input from multiple sources, providing accurate requirements with attention to detail. • You already know or can rapidly learn enterprise application capabilities in order to deliver transaction and event-driven data solutions (examples: SAP/HANA, MS Dynamics or Salesforce Data, ADLS/Hadoop/Databricks datalake/lakehouse solutions, and/or Kafka streams)\n",
        "\"\n",
        "\"Lead II - Data Analysis\n",
        "\n",
        "This is an onsite role with minimum 4 days in office, and work directly under the senior leadership.\n",
        "Responsibilities:\n",
        "•\tData collection from various sources, clean & validate the data\n",
        "•\tAnalyze the data for the patterns & any anomalies\n",
        "•\tUse predictive models & techniques for insights\n",
        "•\tCreate dashboards/reports\n",
        "Experience:\n",
        "•\t6 plus years of IT experience in Data Analyst/Data Scientist roles\n",
        "•\tBusiness Knowledge of Telecom eCommerce Omni channel (OSS/BSS)\n",
        "•\tHands on experience in SQL, Python, Databricks\n",
        "•\tHands-on experience in Data Visualization Tools – Tableau (preferred) or Power BI.\n",
        "•\tHands-on experience in Data Analytics, AL/ML – LLM and do predictive analysis\n",
        "•\tFamiliarity with ETL, Data pipelines\n",
        "•\tStrong analytical and problem solving skills\n",
        "•\tExperience with cloud platform – AWS/Azure/Google\n",
        "•\tAble to work with less or no guidance\n",
        "\"\n",
        "\"Responsibilities:\n",
        "Develop Software: Design, develop, test, and deploy high-quality applications and microservices in both Java and Python.\n",
        "\n",
        "Code Optimization: Ensure optimal performance and efficiency of applications by writing efficient, reusable, and maintainable code.\n",
        "\n",
        "Collaboration: Work closely with cross-functional teams, including product managers, designers, and QA engineers to build solutions that meet business needs.\n",
        "\n",
        "Troubleshooting and Debugging: Identify and resolve issues in existing code, ensuring minimal downtime and high availability.\n",
        "\n",
        "Integration: Integrate third-party APIs, databases, and other systems into the applications.\n",
        "\n",
        "Code Reviews: Participate in peer code reviews, providing constructive feedback to improve the quality of code across the team.\n",
        "\n",
        "Documentation: Write technical documentation, including design, architecture, and user guides.\n",
        "\n",
        "Agile Development: Work in an Agile environment, contributing to sprint planning, backlog grooming, and iterative development cycles.\n",
        "\n",
        "Security: Adhere to best practices for application security, including secure coding techniques and data protection.\n",
        "\n",
        "Required Skills & Qualifications:\n",
        "=================================\n",
        "Programming Experience: hands-on experience in developing applications using Java (Spring, Hibernate, etc.) and Python (Django, Flask, or other frameworks).\n",
        "\n",
        "Software Development: Solid understanding of object-oriented programming (OOP) principles and design patterns.\n",
        "\n",
        "Web Development: Experience in building RESTful APIs and web services using both Java and Python.\n",
        "\n",
        "Databases: Proficiency with relational databases (e.g., PostgreSQL, MySQL) and NoSQL databases (e.g., MongoDB, Cassandra).\n",
        "\n",
        "Version Control: Experience with version control systems such as Git, GitHub, or GitLab.\n",
        "\n",
        "Testing: Knowledge of unit testing and test-driven development (TDD) using tools like JUnit, pytest, or similar frameworks.\n",
        "\n",
        "Cloud Platforms: Experience working with cloud platforms like AWS, GCP, or Azure, including serverless architecture and containerized applications (e.g., Docker, Kubernetes).\n",
        "\n",
        "CI/CD: Familiarity with continuous integration and continuous deployment practices, and tools like Jenkins, CircleCI, or GitLab CI.\n",
        "\n",
        "Problem Solving: Strong problem-solving skills and the ability to think through complex technical challenges.\n",
        "\n",
        "Collaboration & Communication: Excellent verbal and written communication skills with the ability to work effectively in a team-oriented environment.\n",
        "\n",
        "Preferred Qualifications:\n",
        "Microservices Architecture: Experience building and maintaining microservices-based applications.\n",
        "\n",
        "Frameworks: Familiarity with Java frameworks like Spring Boot, and Python frameworks like Flask or Django.\n",
        "\n",
        "Cloud-Native: Experience with building cloud-native applications and working with container orchestration tools like Kubernetes.\n",
        "\n",
        "Message Queues: Experience with message brokers and queues like Kafka, RabbitMQ, or AWS SQS.\n",
        "\n",
        "Agile Practices: Experience working in Agile software development methodologies (Scrum, Kanban).\n",
        "\n",
        "CI/CD Pipelines: Advanced knowledge of setting up and managing CI/CD pipelines in a cloud environment.\n",
        "\n",
        "Security Best Practices: Knowledge of secure coding practices and implementing security measures in web applications.\"\n",
        "\"Solid foundation and hands-on experience building and operating Kubernetes; Proficiency in deploying, scaling, and managing Kubernetes clusters; Experience in cloud platforms (AWS, Azure or GCP); Hands-on experience with cloud infrastructure provisioning at scale using tools like Terraform, Pulumi, Crossplane, CloudFormation, etc.; Experience developing and maintaining control planes; Proficiency in Python or Golang; Experience in devops and agile for solution delivery through CI/CD; Hands-on experience with automation and development; Ability to work independently and collaboratively\n",
        "\n",
        "Primary Skills: 1. Understanding of Kubernetes fundamentals and experience building/operating Kubernetes.2. Golang or Python experience 3. DevOps pipeline understanding- Terraform4. Cloud: AWS or Azure or GCPExperience Range 5-8 years of experience in this tech stack. ( dont restrict the search to years of experience)\n",
        "SO# created for contractor hiring\"\n",
        "\"Sr Cloud Network Engineer\n",
        "Key Responsibilities\n",
        "• Oversee the network onboarding process for new users and systems into Cloud environment\n",
        "• Provision and configure network resources in Cloud, ensuring compliance with security policies and government regulations.\n",
        "• Implement secure network architectures, including Virtual Private Clouds (VPCs), subnets, routing tables, and network access control lists across AWS, Azure, and other cloud platforms.\n",
        "• Configure and manage cloud networking services for secure connectivity between on-premises and cloud environments, such as AWS Direct Connect, Azure VPN Gateway, and transit gateways.\n",
        "• Implement network security controls, such as security groups, network firewalls, and web application firewalls to protect against unauthorized access and cyber threats.\n",
        "• Monitor network traffic and security logs using cloud services for flow logs, activity trails, and threat detection to identify and respond to potential security incidents.\n",
        "• Collaborate with cross-functional teams to ensure secure integration of applications and services into the cloud network infrastructure.\n",
        "• Conduct regular network assessments and audits to ensure compliance with internal and external requirements.\n",
        "• Develop and maintain comprehensive network security policies, procedures, and documentation in compliance with security standards.\n",
        "• Provide technical support and troubleshooting for Cloud network-related issues\n",
        "• Stay up-to-date with the latest cloud networking services, security features, and best practices across multiple platforms\n",
        "\n",
        "Automation Skills:\n",
        "• Proficiency in Python or Golang for automation\n",
        "• Strong expertise in Terraform automation with the ability to create custom templates and modules is a plus.\n",
        "• Hands-on experience in CI/CD implementation and gitlab\n",
        "• Experience with containerization would be a plus\n",
        "\n",
        "Qualifications\n",
        "• Assesses the candidate's experience with the network onboarding process and provisioning in cloud environments such as AWS and Azure.\n",
        "• Evaluates the candidate's experience with automation tools for network configuration and management.\n",
        "• Measures the candidate's hands-on experience with cloud networking services across AWS, Azure, and other major cloud providers.\n",
        "• Assesses the candidate's in-depth knowledge of network security principles, protocols, and best practices for secure network design and implementation.\n",
        "• Evaluates the candidate's knowledge of government network security standards and compliance requirements.\n",
        "• Measures the candidate's relevant certifications which indicate their proficiency and expertise in cloud\n",
        "\n",
        "\"\n",
        "\"Project Manager\n",
        "\n",
        "Responsibilities:\n",
        "•\tManage multiple work streams/Scrum teams\n",
        "•\tManage multiple SCRUM teams and manage all SCRUM ceremonies such as Daily Standup, Sprint Planning, Retrospective, Sprint Review meetings.\n",
        "•\tWorking with Scrum team, as well as internal and external stakeholders, to influence and drive decision making and support organizational project or product teams.\n",
        "•\tMaintain project timeframe, estimates and status reports.\n",
        "•\tPrepare and present project and program status reports\n",
        "•\tAssist senior leaders in staffing, planning, report preparations\n",
        "•\tDevelops, maintains and manages detailed project plans, action item registers and major milestone timelines for all assigned projects.\n",
        "•\tConduct risk assessments for the projects.\n",
        "•\tCollaborate in preparing for the PI Planning\n",
        "•\tAssist Product Owner and team in backlog refinement.\n",
        "•\tFacilitate Scrum of Scrum meetings with other Scrum teams\n",
        "•\tCoordinate the project release and deployments.\n",
        "•\tMonitor project deliverables.\n",
        "•\tPrepare status reports, presentations and present to stakeholders.\n",
        "•\tPerform other duties and responsibilities as assigned\n",
        "Experience:\n",
        "•\t10 plus years of IT experience\n",
        "•\tMinimum of at least 4 years of experience in a project management capacity in Project Manager & Scrum Master roles in software development projects\n",
        "•\tPrior experience managing multiple project teams for a common roadmap\n",
        "•\tExperience managing system implementation and integration projects\n",
        "•\tStrong presentation and communication skills\n",
        "•\tStrong conceptual, analytic and problem-solving skills.\n",
        "•\tStrong communication skills\n",
        "•\tStrong project and time management skills.\n",
        "•\tAbility to work under pressure, meet deadlines, and work on multiple projects simultaneously.\n",
        "•\tMust be a team player and be able to effectively interact with stakeholders at all levels\n",
        "•\tStrong leadership capabilities and excellent communication skills with the ability to engage with technical teams and business stakeholders alike\n",
        "•\tProficiency in creating engaging PowerPoint presentations.\n",
        "\n",
        "Preferred Experience:\n",
        "•\tPrevious experience in the fintech or payment industry.\n",
        "•\tScrum Master certification and/or PMP certification is preferred\n",
        "\"\n",
        "\"Experienced Senior Software Development Engineer in Test (SDET). Candidate to have significant experience in mobile test automation, with expertise in Appium and Java. Will be responsible for designing and executing automated test scripts, improving test frameworks, and ensuring the highest quality of our mobile applications across both iOS and Android platforms.\n",
        "\n",
        "Key Responsibilities:\n",
        "Design and Develop Test Automation Scripts:\n",
        "Create, implement, and maintain automated test scripts using Appium with Java for both iOS and Android applications to ensure comprehensive test coverage.\n",
        "\n",
        "Automation Framework Development:\n",
        "Build, improve, and scale automated test frameworks in Java to support mobile testing, ensuring reusability, maintainability, and scalability.\n",
        "\n",
        "Mobile Application Testing:\n",
        "Perform end-to-end testing on mobile applications for compatibility, performance, security, and functionality across various devices, OS versions, and screen resolutions.\n",
        "\n",
        "Cross-Platform Mobile Testing:\n",
        "Develop and execute tests across multiple mobile platforms (iOS, Android) using Appium to ensure uniform test execution and results.\n",
        "\n",
        "CI/CD Integration:\n",
        "Integrate automated mobile tests into CI/CD pipelines (e.g., Jenkins, GitLab CI, etc.) to ensure continuous testing and faster feedback.\n",
        "\n",
        "Test Execution and Monitoring:\n",
        "Monitor automated test executions, debug failures, and provide actionable feedback to developers to ensure issues are quickly addressed and fixed.\n",
        "\n",
        "Defect Identification and Root Cause Analysis:\n",
        "Investigate and report defects, tracking them through to resolution while working with the development team to identify root causes and solutions.\n",
        "\n",
        "Collaboration and Communication:\n",
        "Work closely with cross-functional teams, including developers, product managers, and other SDETs, to understand application features and contribute to test strategy and planning.\n",
        "\n",
        "Mentorship and Leadership:\n",
        "Mentor junior testers and engineers, providing guidance on best practices in mobile automation using Appium and Java.\n",
        "\n",
        "Test Reporting and Metrics:\n",
        "Generate reports and analyze automated test results, providing clear and actionable insights to improve mobile application quality.\n",
        "\n",
        "Required Skills and Qualifications:\n",
        "Experience:\n",
        "At least 5+ years of experience in software development or quality assurance, with 3+ years specifically focused on mobile test automation using Appium and Java.\n",
        "\n",
        "Programming Skills:\n",
        "Strong proficiency in Java for writing automated test scripts, creating frameworks, and debugging test failures.\n",
        "\n",
        "Appium Expertise:\n",
        "Deep knowledge of Appium and its integration with mobile testing on iOS and Android platforms.\n",
        "\n",
        "Test Frameworks:\n",
        "Experience in building and maintaining test automation frameworks using Java and supporting tools like TestNG, JUnit, Maven, and Gradle.\n",
        "\n",
        "Mobile Testing:\n",
        "In-depth understanding of mobile testing strategies and best practices for both Android and iOS devices.\n",
        "\n",
        "Version Control Systems:\n",
        "Experience with Git and using Git for version control and collaboration in a team environment.\n",
        "\n",
        "CI/CD Tools:\n",
        "Familiarity with CI/CD tools such as Jenkins, GitLab CI, CircleCI, or similar to integrate automated tests into the build pipeline.\n",
        "\n",
        "Bug Tracking:\n",
        "Proficiency in bug tracking tools (e.g., Jira) to log, track, and manage defects through resolution.\n",
        "\n",
        "Analytical Skills:\n",
        "Strong analytical and debugging skills, with the ability to troubleshoot and resolve complex automation issues.\n",
        "\n",
        "Excellent Communication:\n",
        "Strong written and verbal communication skills, with the ability to effectively report test results and collaborate with cross-functional teams.\"\n",
        "\"Product Manager\n",
        "\n",
        "Develop, own, and evolve the product roadmap for cloud security solutions, ensuring alignment with organizational goals and cloud security objectives.\n",
        "     Drive the execution of security product features, enhancements, and initiatives that protect our cloud environments and applications from threats.\n",
        "     Collaborate closely with cloud security engineers, development teams, DevOps, and stakeholders to define product requirements and ensure seamless integration of security features.\n",
        "     Engage with various teams to understand their needs and translate them into actionable security solutions, features, and backlog items.\n",
        "     Prioritize the product backlog based on technical feasibility, business impact, customer value, and risk mitigation.\n",
        "     Continuously refine the backlog to ensure the team is focused on the highest value work, balancing innovation with security requirements.\n",
        "Cloud Security Expertise:\n",
        "     Leverage deep knowledge of cloud platforms (AWS, Azure, GCP) and experience in designing, building, and operating cloud-native security tools and services.\n",
        "     Ensure the cloud environments comply with internal control requirements, regulatory obligations, and external security standards (e.g., NIST, CIS, ISO), with comprehensive reporting and dashboards.\n",
        "     Lead efforts to design, implement, and maintain robust security controls and solutions that proactively protect the cloud infrastructure from emerging threats.\n",
        "     Act as the primary point of contact for product-related decisions and issues, ensuring swift resolution and continuous delivery of high-quality security features.\n",
        "Qualifications:\n",
        "     Bachelor’s degree in computer science, Information Security, or related field (or equivalent experience).\n",
        "     Relevant cloud security certifications (e.g., AWS Certified Security, Microsoft Certified: Azure Security Engineer, Certified Information Systems Security Professional (CISSP)).\n",
        "     5+ years of experience in product management, with a focus on cloud security or cloud-native product development.\n",
        "     Proven experience in developing cloud security solutions on AWS, Azure, and GCP, including hands-on familiarity with cloud security services (e.g., AWS Shield, Azure Security Center).\n",
        "     Experience working in agile development teams and environments, leveraging DevSecOps principles and integrating security into CI/CD pipelines.\n",
        "     Strong understanding of security frameworks and standards (NIST, CIS, ISO) and their application in cloud environments. • Ability to manage complex cross-functional teams, projects, and priorities with excellent organizational and time-management skills.\n",
        "     Proficiency in product management tools (e.g., JIRA, Confluence) and experience in backlog management, refinement, and prioritization.\n",
        "     Excellent communication, stakeholder management, and leadership skills, with the ability to influence and guide technical and non-technical teams.\n",
        "\"\n",
        "\"Sr. Cloud Security Engineer\n",
        "\n",
        "Cloud Security and tool skills:\n",
        "• Experience in cloud onboarding, tool management, and issue analysis using Wiz Security platforms (or equivalent CNAPP solutions) is a must.\n",
        "• Deep understanding of cloud computing, including virtualization, containerization, and microservices; Good understanding of IAM concepts.\n",
        "• Knowledge of security concepts (with zero-trust design principles as a plus);\n",
        "• Hands-on experience in container security.\n",
        "• Hands-on experience designing and implementing for information security on public cloud;\n",
        "• Experience in authoring security policies in the cloud and remediation.\n",
        "• Strong knowledge of security across layers (OS, network, application, data, container, CI/CD, etc.);\n",
        "• Hands-on experience with CSP security tools (like AWS Security Hub, Azure Security Center, or GCP Security Command Center) would be a plus;\n",
        "• Ability to work independently and collaboratively\n",
        "\n",
        "Automation Skills:\n",
        "\n",
        "• Proficiency in Python for automation or in observability engineering,\n",
        "• Experience in Gitops implementation and gitlab would be a plus.\n",
        "• Hands-on experience in Terraform automation with ability to create custom provider is a plus.\n",
        "• Experience in managing the secrets in Vault and Hashicorp Vault is a plus.\n",
        "\"\n",
        "\"Role Proficiency:\n",
        "\n",
        "Contributes to driving the Product Vision that addresses cross-domain market needs with strong business viability; in line with the Product/Platform Portfolio with guidance from Managers. Assists Managers in delivering the desired product and platform outcomes from original inspiration through implementation and support.rnContributes to the discovery and development of the product/platform per the phases and stages of the product/platform.  as guided by the Product Managers.\n",
        "\n",
        "\n",
        "\n",
        "Outcomes:\n",
        "\n",
        "      A strong evangelist of Product & Platforms Division’s Vision and Philosophy.\n",
        "      Performs primary and secondary research on Market Driven Products & Platforms; executes the product/platform strategy\n",
        "      Ensures clear and unambiguous translation of Product Value Roadmap through deliverables to enable the product team to complete work\n",
        "      Ensures adherence to the Product Value Roadmap set by Product Managers and Product Leadership\n",
        "      Drafts user stories and ensures they are clearly understood by cross functional product teams\n",
        "      Ensures Product requirements are gathered and prioritized\n",
        "      Drives the execution of product development in collaboration with Product Team members comprised of Product Design Technology & Data Science\n",
        "      Adherence to the modern product management practises and standards; providing periodic status updates\n",
        "      Supports Product Managers and Senior Product Managers in product demos\n",
        "  Supports in achieving the Product OKR's\n",
        "\n",
        "\n",
        "Measures of Outcomes:\n",
        "\n",
        "      Adherence to agreed product roll-out timelines\n",
        "      Achievement of Product Metrics\n",
        "      Achievement of Product OKR's\n",
        "      Product Team Performance\n",
        "     Number of domain and product certifications\n",
        "\n",
        "\n",
        "Outputs Expected:\n",
        "\n",
        "Plan to develop great products and platforms:\n",
        "\n",
        "Strong research enabling sound Product Discovery\n",
        "Co-facilitates Discovery Sprints under guidance from Product and Senior Product Managers\n",
        "Write and articulate great user stories by capturing and translating solutions for identified user problems into product features that deliver value and impress users\n",
        "Adherence to Product OKR's\n",
        "\n",
        "\n",
        "Design to deliver vast end -user experience:\n",
        "\n",
        "Facilitate sound user research across target market segments\n",
        "Influence in implementing design user-centric experiences throughout the user's journey\n",
        "Assist in defining user experience (e.g.  wire framing journey maps); partnering with product designers\n",
        "\n",
        "\n",
        "Research the market to ensure an unfair advantage:\n",
        "\n",
        "Sound understanding of market trends partner ecosystems and competitive strategies\n",
        "Understanding users the marketplace the competition and future trends for the domain or type of system being developed through customer and market research competitive analysis and rapidly acquiring domain expertise\n",
        "Define and articulate unique product and business differentiation\n",
        "\n",
        "\n",
        "Manage business to go to and win in the markets:\n",
        "\n",
        "Assist in implementing the GTM strategies and achieve the metrics for product success\n",
        "Protect assets and mitigate risks employing IP knowledge\n",
        "\n",
        "\n",
        "Manage great people:\n",
        "\n",
        "Inspire Product teams communicate with diverse groups and influence change throughout the organization\n",
        "\n",
        "\n",
        "Use great technology:\n",
        "\n",
        "Good understanding and usage of tech stacks\n",
        "Good understanding of exponential technologies including AI/ML IoT Blockchain\n",
        "Agile proficiency for Rapid Product Discovery & Development\n",
        "Employ eminent technology in product management by diving deep into technology trends and architectures\n",
        "\n",
        "\n",
        "Employ great methods in product management :\n",
        "\n",
        "Understand different product management and development approaches\n",
        "Understand product usage models\n",
        "\n",
        "\n",
        "Skill Examples:\n",
        "\n",
        "       Skill in understanding and articulating the core positioning messaging and value propositions for the product\n",
        "      Ability to support product demos to customers/end users\n",
        "      Ability to define the user experience to be incorporated into the User Design\n",
        "      Aptitude in creating user stories\n",
        "      Ability to creates market customer and competition research based on understanding of market trends partner ecosystems and competitive strategies\n",
        "       Capable of motivating the team to build and deliver impressive products\n",
        "\n",
        "\n",
        "Knowledge Examples:\n",
        "\n",
        "Knowledge Examples\n",
        "\n",
        "      Domain / Industry Knowledge:  Working knowledge of standard business processes within the relevant industry vertical and customer business domain\n",
        "      Technology Trends Knowledge: Demonstrates broad knowledge of technology trends related to multiple inter-related technologies\n",
        "      Proficient in user story writing\n",
        "      Knowledge of market trends partner ecosystems and competitive strategies\n",
        "      Proficient in product documentation\n",
        "      Expertise in people management\n",
        "     Knowledge of technology trends and architectures\"\n",
        "\"Role Proficiency:\n",
        "\n",
        "Understands customer requirements streamline DevOps practices and translate them into reference architecture for DevOps (CI/CD) and automation components by managing multiple scrum teams.\n",
        "\n",
        "\n",
        "\n",
        "Outcomes:\n",
        "\n",
        "     Interprets the DevOps Tool/feature/component design to develop/support the same in accordance with specifications\n",
        "     Adapts existing DevOps solutions and creates own DevOps solutions for new contexts\n",
        "     Codes debugs tests documents and communicates DevOps development stages/status of DevOps support issues\n",
        "     Selects appropriate technical options for development such as reusing improving or reconfiguration of existing components\n",
        "     Optimises efficiency cost and quality of DevOps process tools and technology development\n",
        "     Validates results with user representatives; integrates and commissions the overall solution\n",
        "     Assesses current state of DevOps maturity and advises clients on improving maturity and DevOps roadmap\n",
        "     Assess readiness of clients to adopt DevOps practices advising clients on appropriate change approaches and technology choices\n",
        "     Looks for patterns of struggle and experiments with new designs and new ways of applying existing designs to solve problems\n",
        "  Guides DevOps leads and engineers and observe how the processes are working in practice\n",
        "  Works towards reducing variations in practice by challenging status quo and tweaking processes and tools\n",
        "  Resolve architecture issues and deliver / own architecture of application solutions spanning across multiple technologies for projects of the following nature - high revenue projects / complex projects / large strategic maintenance projects\n",
        "  Manage multiple stakeholders and handle their expectations\n",
        "  Contribute to business development and organizational activities\n",
        "  Support Architect/Sr. Architect in drafting recommendations based on findings of Proof of Concept\n",
        "\n",
        "\n",
        "Measures of Outcomes:\n",
        "\n",
        "     Quality of Deliverables\n",
        "     Defect injection at various stages of lifecycle\n",
        "     SLA/KPI for onboarding projects or applications\n",
        "     Percentage achievement of specification/completeness/on-time delivery\n",
        "     # of reusable components / processes developed\n",
        "     Delivery efficiency (Adherence to UST defined principles)\n",
        "     Contribution to technology capability development (e.g. Training Webinars Blogs)\n",
        "     Customer feedback on overall technical quality (zero technology related escalations)\n",
        "     # of white papers/document assets contributed to\n",
        "  Feedback from Project Team/Program Management on project support\n",
        "  Error rate/completion rate at various stages of SDLC/PDLC\n",
        "  Uptime/System reliability metrics (if the design is not meeting with agreed SLA’s)\n",
        "  # of domain certification/ product certification obtained\n",
        " Adoption rates of CI/CD tools DevOps practices (efficiency improvement rate)\n",
        "\n",
        "\n",
        "Outputs Expected:\n",
        "\n",
        "Automated components :\n",
        "\n",
        "Deliver components that automat parts to install components/configure of software/tools in on  premises and on cloud\n",
        "Deliver components that automate parts of the build/deploy for applications\n",
        "\n",
        "\n",
        "Configured components:\n",
        "\n",
        "Configure tools and automation framework into the overall DevOps design\n",
        "\n",
        "\n",
        "Scripts:\n",
        "\n",
        "Supervise/Develop automation scripts (like Powershell/Shell/Python scripts) that automate installation/configuration/build/deployment tasks\n",
        "\n",
        "\n",
        "Training/SOPs :\n",
        "\n",
        "Create Training plans/SOPs to help DevOps Engineers with DevOps activities and to onboard users\n",
        "Create Training plans/SOPs to help technical deal with already existing CI/CD Pipelines and components; onboarding users\n",
        "\n",
        "\n",
        "Measure Process Efficiency/Effectiveness:\n",
        "\n",
        "Deployment frequency innovation and technology changes\n",
        "\n",
        "\n",
        "Operations:\n",
        "\n",
        "Change lead time/volume\n",
        "Failed deployments\n",
        "Defect volume and escape rate\n",
        "Meantime to detection and recovery\n",
        "\n",
        "\n",
        "Solution Definition & Design:\n",
        "\n",
        "Define Architecture for the small/mid-sized type of project\n",
        "Design the technical framework and implement the same\n",
        "Identify and conduct design of complex sub-components /module in collaboration with project team architects and client SME\n",
        "Present the detailed design documents to relevant stakeholders and seek feedback\n",
        "Undertake project specific Proof of Concepts activities to validate technical feasibility with guidance from the Application Architect\n",
        "Implement best optimized solution and resolve performance issues\n",
        "Support the team in the design of functional modules and review the deliverables\n",
        "Conduct code reviews\n",
        "\n",
        "\n",
        "Project Estimation:\n",
        "\n",
        "Provide support for project estimations on business proposals and support sprint level / component level estimates\n",
        "Articulate estimation methodology module level estimations for more standard projects with focus on estimation effort alone\n",
        "\n",
        "\n",
        "Measure Process Efficiently/Effectiveness:\n",
        "\n",
        "Measure and pay attention to efficiency/effectiveness of current process and make changes to make them more efficient/effective\n",
        "Facilitate development processes and operations\n",
        "Architecting overall comprehensive DevOps practice effectiveness\n",
        "\n",
        "\n",
        "Skill Exampl\"\n",
        "\"ures of Outcomes:\n",
        "\n",
        "NA\n",
        "\n",
        "\n",
        "\n",
        "Outputs Expected:\n",
        "\n",
        "Contractor:\n",
        "\n",
        "NA\n",
        "\n",
        "\n",
        "Skill Examples:\n",
        "\n",
        "NA\n",
        "\n",
        "\n",
        "\n",
        "Knowledge Examples:\n",
        "\n",
        "Knowledge ExamplesNA\"\n",
        "\"Role Proficiency:\n",
        "\n",
        "Act creatively to develop applications and select appropriate technical options optimizing application development maintenance and performance by employing design patterns and reusing proven solutions account for others' developmental activities\n",
        "\n",
        "\n",
        "\n",
        "Outcomes:\n",
        "\n",
        "     Interpret the application/feature/component design to develop the same in accordance with specifications.\n",
        "     Code debug test document and communicate product/component/feature development stages.\n",
        "     Validate results with user representatives; integrates and commissions the overall solution\n",
        "     Select appropriate technical options for development such as reusing improving or reconfiguration of existing components or creating own solutions\n",
        "     Optimises efficiency cost and quality.\n",
        "     Influence and improve customer satisfaction\n",
        " Set FAST goals for self/team; provide feedback to FAST goals of team members\n",
        "\n",
        "\n",
        "Measures of Outcomes:\n",
        "\n",
        "     Adherence to engineering process and standards (coding standards)\n",
        "     Adherence to project schedule / timelines\n",
        "     Number of technical issues uncovered during the execution of the project\n",
        "     Number of defects in the code\n",
        "     Number of defects post delivery\n",
        "     Number of non compliance issues\n",
        "  On time completion of mandatory compliance trainings\n",
        "\n",
        "\n",
        "Outputs Expected:\n",
        "\n",
        "Code:\n",
        "\n",
        "Code as per design\n",
        "Follow coding standards templates and checklists\n",
        "Review code – for team and peers\n",
        "\n",
        "\n",
        "Documentation:\n",
        "\n",
        "Create/review templates checklists guidelines standards for design/process/development\n",
        "Create/review deliverable documents. Design documentation r and requirements test cases/results\n",
        "\n",
        "\n",
        "Configure:\n",
        "\n",
        "Define and govern configuration management plan\n",
        "Ensure compliance from the team\n",
        "\n",
        "\n",
        "Test:\n",
        "\n",
        "Review and create unit test cases scenarios and execution\n",
        "Review test plan created by testing team\n",
        "Provide clarifications to the testing team\n",
        "\n",
        "\n",
        "Domain relevance:\n",
        "\n",
        "Advise Software Developers on design and development of features and components with a deep understanding of the business problem being addressed for the client.\n",
        "Learn more about the customer domain identifying opportunities to provide valuable addition to customers\n",
        "Complete relevant domain certifications\n",
        "\n",
        "\n",
        "Manage Project:\n",
        "\n",
        "Manage delivery of modules and/or manage user stories\n",
        "\n",
        "\n",
        "Manage Defects:\n",
        "\n",
        "Perform defect RCA and mitigation\n",
        "Identify defect trends and take proactive measures to improve quality\n",
        "\n",
        "\n",
        "Estimate:\n",
        "\n",
        "Create and provide input for effort estimation for projects\n",
        "\n",
        "\n",
        "Manage knowledge:\n",
        "\n",
        "Consume and contribute to project related documents share point libraries and client universities\n",
        "Review the reusable documents created by the team\n",
        "\n",
        "\n",
        "Release:\n",
        "\n",
        "Execute and monitor release process\n",
        "\n",
        "\n",
        "Design:\n",
        "\n",
        "Contribute to creation of design (HLD LLD SAD)/architecture for Applications/Features/Business Components/Data Models\n",
        "\n",
        "\n",
        "Interface with Customer:\n",
        "\n",
        "Clarify requirements and provide guidance to development team\n",
        "Present design options to customers\n",
        "Conduct product demos\n",
        "\n",
        "\n",
        "Manage Team:\n",
        "\n",
        "Set FAST goals and provide feedback\n",
        "Understand aspirations of team members and provide guidance opportunities etc\n",
        "Ensure team is engaged in project\n",
        "\n",
        "\n",
        "Certifications:\n",
        "\n",
        "Take relevant domain/technology certification\n",
        "\n",
        "\n",
        "Skill Examples:\n",
        "\n",
        "     Explain and communicate the design / development to the customer\n",
        "     Perform and evaluate test results against product specifications\n",
        "     Break down complex problems into logical components\n",
        "     Develop user interfaces business software components\n",
        "     Use data models\n",
        "     Estimate time and effort required for developing / debugging features / components\n",
        "     Perform and evaluate test in the customer or target environment\n",
        "     Make quick decisions on technical/project related challenges\n",
        "     Manage a Team mentor and handle people related issues in team\n",
        "  Maintain high motivation levels and positive dynamics in the team.\n",
        "  Interface with other teams designers and other parallel practices\n",
        "  Set goals for self and team. Provide feedback to team members\n",
        "  Create and articulate impactful technical presentations\n",
        "  Follow high level of business etiquette in emails and other business communication\n",
        "  Drive conference calls with customers addressing customer questions\n",
        "   Proactively ask for and offer help\n",
        "  Ability to work under pressure determine dependencies risks facilitate planning; handling multiple tasks.\n",
        "  Build confidence with customers by meeting the deliverables on time with quality.\n",
        "  Estimate time and effort resources required for developing / debugging features / components\n",
        "  Make on appropriate utilization of Software / Hardware’s.\n",
        "  Strong analytical and problem-solving abilities\n",
        "\n",
        "\n",
        "Knowledge Examples:\"\n",
        "\"Sr Cloud Network Engineer\n",
        "Key Responsibilities\n",
        "• Oversee the network onboarding process for new users and systems into Cloud environment\n",
        "• Provision and configure network resources in Cloud, ensuring compliance with security policies and government regulations.\n",
        "• Implement secure network architectures, including Virtual Private Clouds (VPCs), subnets, routing tables, and network access control lists across AWS, Azure, and other cloud platforms.\n",
        "• Configure and manage cloud networking services for secure connectivity between on-premises and cloud environments, such as AWS Direct Connect, Azure VPN Gateway, and transit gateways.\n",
        "• Implement network security controls, such as security groups, network firewalls, and web application firewalls to protect against unauthorized access and cyber threats.\n",
        "• Monitor network traffic and security logs using cloud services for flow logs, activity trails, and threat detection to identify and respond to potential security incidents.\n",
        "• Collaborate with cross-functional teams to ensure secure integration of applications and services into the cloud network infrastructure.\n",
        "• Conduct regular network assessments and audits to ensure compliance with internal and external requirements.\n",
        "• Develop and maintain comprehensive network security policies, procedures, and documentation in compliance with security standards.\n",
        "• Provide technical support and troubleshooting for Cloud network-related issues\n",
        "• Stay up-to-date with the latest cloud networking services, security features, and best practices across multiple platforms\n",
        "\n",
        "Automation Skills:\n",
        "• Proficiency in Python or Golang for automation\n",
        "• Strong expertise in Terraform automation with the ability to create custom templates and modules is a plus.\n",
        "• Hands-on experience in CI/CD implementation and gitlab\n",
        "• Experience with containerization would be a plus\n",
        "\n",
        "Qualifications\n",
        "• Assesses the candidate's experience with the network onboarding process and provisioning in cloud environments such as AWS and Azure.\n",
        "• Evaluates the candidate's experience with automation tools for network configuration and management.\n",
        "• Measures the candidate's hands-on experience with cloud networking services across AWS, Azure, and other major cloud providers.\n",
        "• Assesses the candidate's in-depth knowledge of network security principles, protocols, and best practices for secure network design and implementation.\n",
        "• Evaluates the candidate's knowledge of government network security standards and compliance requirements.\n",
        "• Measures the candidate's relevant certifications which indicate their proficiency and expertise in cloud\n",
        "\n",
        "\"\n",
        "\"Stakeholder Management and Overall Project Management.\n",
        "\n",
        "Job Description - 7-9 years of experience as a Technical Product Owner in a fast-paced software development environment.\n",
        "Experience in managing the development of complex software products, ideally in [, eCommerce, Lifesciences domain].\n",
        "Proven experience in working with engineering teams and a deep understanding of the software development lifecycle.\n",
        "Strong technical background, with a good understanding of software architecture, databases, APIs, and cloud technologies.\n",
        "Familiarity with Agile methodologies (Scrum, Kanban) and experience working in Agile product development teams.\n",
        "Proficiency in writing user stories, defining acceptance criteria, and managing product backlogs.\n",
        "Hands-on experience with product management tools (e.g., Jira, Confluence).\n",
        "Exceptional communication skills, both written and verbal, with the ability to explain complex technical concepts in a simple and understandable way.\n",
        "Proven ability to collaborate effectively with cross-functional teams.\n",
        "Strong negotiation and stakeholder management skills, able to balance competing priorities and drive consensus.\n",
        "Strong analytical and problem-solving skills with the ability to make data-driven decisions. Ability to balance short-term deliverables with long-term strategic goals.\n",
        "Understanding of product metrics and how to use them to optimize product performance and customer satisfaction.\n",
        "A background in development (e.g., experience as a software developer, systems engineer, etc.)\n",
        "\n",
        "\"\n",
        "\"Provide technical and business project leadership across functional boundaries for different phases of product development and support programs. This leadership will include projects pertaining to New Product Introduction, Line Qualification for new product launch and batch qualification for new product launch.\n",
        "\n",
        "Manage the production scale up of new Skin Care and other Personal Care consumer products\n",
        "\n",
        "Lead the Tech Transfer process of Skin Care and other Personal Care consumer products\n",
        "\n",
        "Guide cross functional teams; internal/external engineering and resolve inter-functional issues\n",
        "\n",
        "Provide documentation of the project and program activities and deliverables\n",
        "\n",
        "Ensure attainment of project and program schedules, budgets, procedures, and revenues by developing and auditing the budget and approval process\n",
        "\n",
        "Direct processes to promote and implement new product capability:\n",
        "•\tBid/quote process\n",
        "•\tEquipment purchase\n",
        "•\tProject planning\n",
        "•\tPilot batches\n",
        "•\tTrial batches\n",
        "•\tLine trials\n",
        "•\tSpecification and artwork development\n",
        "•\tStability validation protocols\n",
        "•\tProduction start-up\n",
        "\n",
        "Carry-out communication with Senior management on project and program status\n",
        "•\tCreate, maintain, and present written reporting on status, tests, costs, issues, and performance against established targets on a continuing basis\n",
        "\n",
        "Research business and technical issues to establish what is being done and where improvement is feasible\n",
        "\n",
        "Arrange proper system integration by overseeing the development of the systems integration and systems assurance test plans and procedures\n",
        "•\tanalyze the results\n",
        "\n",
        "Establish and communicate project and program schedules, objectives, priorities, and targets\n",
        "\n",
        "Oversee status of programs and projects\n",
        "•\tprovide technical interpretation and knowledge\n",
        "•\tensure adherence to policies, procedures, government regulations, and customer specifications\n",
        "\n",
        "This position is based in the Lancaster, PA area\n",
        "\"\n",
        "\"In this role, you will have the opportunity to support the Corrective and Preventive\n",
        "Action (CAPA) process from issue identification to closure and ensure adequate\n",
        "execution of the process and the quality of CAPA record content. You will be part of our\n",
        "Quality & Regulatory organization.\n",
        "\n",
        "Key Responsibilities:\n",
        "•\tProject Management: Project manage all CAPA activities from initiation to closure, ensuring timely and effective execution.\n",
        "•\tIssue Identification and Assessment: Identify and assess issues, ensuring accurate and thorough documentation.\n",
        "•\tCAPA Data Review: Review CAPA data sources and assist with root cause analysis and quality problem-solving.\n",
        "•\tRoot Cause Analysis: Participate in and/or lead root cause analysis activities to identify the underlying causes of issues.\n",
        "•\tCAPA Record Quality: Ensure the quality and completeness of CAPA records.\n",
        "•\tAudit and Review Board Representation: Support and prepare spokespersons in representing CAPAs during audits and CAPA Review Board meetings.\n",
        "•\tTimely CAPA Engineering Tasks: Perform timely, detailed CAPA engineering tasks like assessing issue descriptions and reviewing CAPA data sources.\n",
        "•\tProcess Improvement: Contribute to the continuous improvement of CAPA processes and procedures.\n",
        "•\tEnsuring Products Meet Standards: Ensuring that our products meet the highest standards.\n",
        "\"\n",
        "\n",
        "SO# is created for internal purpose\n",
        "Allocation for David Fraley.\n",
        "The ideal candidate will be skilled in:  Process discovery and optimization  Data analysis, visualization, and dashboarding  Identifying opportunities to improve our processes and systems, especially in finance domain. A strong business architecture mindset is a plus, with experience or familiarity in Various ERP system like Oracle and SAP. Expertise in various tools like  Process Mining tools  BizzDesign / Business Architecture tools  Power BI  Power Apps  Qualtrics Analysis  User journey mapping  Problem statement generation  Developing actionable plans\n",
        " New requirement\n",
        "NA\n",
        "Please look for lead developers with experience in Springboot, Java microservices, GraphQL with hands on experience on Python as well. Resource has to be in Atlanta.\n",
        "NA\n",
        "Contractor SO#\n",
        "NA\n",
        "Please provide Senior profiles with IOS/Android Mobile Automation Testing with Appium and Java expertise.\n",
        "SO# created to onboard Mosfaqus Salehin\n",
        "Mandatory Skills(Only 3-4)Wiz Security Platform or equivalent CNAPP solutionCross-platform securityContainer SecurityTerraformWork independentlyOptional SkillsKnowledge of Zero-Trust Design principlesManaging secrets (Vault or Hashicorp)\n",
        "NA\n",
        "SO Created to allocate Mona Sitlani UID 150942\n",
        "SO# is created to convert Sundar Munusuri- 15128\n",
        "SO# is created to convert 270106Raguram Veeraparakaramapandian\n",
        "NA\n",
        " creating new SO for J&amp;J with product owner JD.\n",
        "Based in Lancaster PA\n",
        "Preference is for resource to be near Pittsburgh, PA but remote is also an option\n",
        "\n",
        "\n",
        "\n",
        "Software Engineering,Software Developer,Full Stack\n",
        "Oracle,Sap,Process Mining,Power Bi\n",
        "Databricks,Spark Sql,Tableau\n",
        "SQL,PYTHON,DATA BRICKS,TELECOM EXPERIENCE\n",
        "Aws Services,Java Microservices,Graphql\n",
        "kubernetes,kubernetes fundamental,golang,Terraform\n",
        "Kubernetes,Aws Cloud,Golang\n",
        "Project Management,agile,jira\n",
        "Android,Ios,Appium Testing\n",
        "cloud security,cloud platform,AWS CLOUD\n",
        "Security,cross platform security,container security\n",
        "proudct,product manager,agile\n",
        "java,spring,microservices\n",
        "gitlab,devops,cloud security\n",
        "data,analyst,Data Analysis,AWS\n",
        "Kubernetes,Aws Cloud,Golang\n",
        "Project Management,Stakeholder Management,Scrum Master\n",
        "Timeline,Project Management,Excellent Communication\n",
        "Capa,Quality Assurance,Quality Management\n",
        "\n",
        "\n",
        "David Fraley 284050\n",
        "Naveen shortlisted, waiting for final confirmation from client.\n",
        "Technical Data Analyst  Vinesh/ RH ADOBE 3/20\n",
        "Sasmitha Das CI pending. Amarnath and Anish L2 to be scheduled.  (Nishant Panel) Vijay/ Beeline COMCAST Data Analyst\n",
        "Client Ref. Poorna Chandra L1  scheduled with Jyothsih Glider 4/8. Java/Python Developer Jyothish/ TMO - Deb/ Beeline\n",
        "Keerthi  submitted to Client 4/7.  2 L2 Interview to be set up Abin.24/3 : wating 4 L2 (sukesh to help on panel ) 21/3 : Durga Maruthi L2 to be scheduled,.Srujan Sama,Sravan Kumar Ayyagari ,Yedunandan Vitakula (L2 to be scheduled)  Replacement of Teja Sai Ganta (288113) TMO Deb/ Beeline 3/14 - Kiran Krishnan Coordinate for Panel. Frisco/ Remote - Punna Rao / Donald/ Bujail/ Sujith - Panel\n",
        "Beeline/ Vijay. 2/4 : Sathya Nagaraj submitted to Client 4/7.  Roman L3 to be scheduled with Sujith (Panel)   Vignana (L2 with Raja) - Ajay Pasunoor L1 Completed (need to set up with Panel) 25/3 : Sathya Nagaraj (L3 to be set up with sujith) , Pradeep Dasari L2 with Raja as on 25th  Glider L1 in progress 3/19. TMO Sr. Cloud Network Engineer Vijay/ Beeline 3/18. CWR - Raja and Sagar - Panel\n",
        "Anthony, Kiran and Dennis CI FB awaited.   Russ L2 with Sujith 4/7 .  Pradeep Murthy Declined.   CI on 3/14 awaiting Client confirmation 3/18.  Anthony Interview with Sujith 3/18.  Sheetal - backup.  Pradeep L1 with Sujith 3/6.   Jessica and Zaibi CI Reject on 3/5. Jessica CI 3/3 Awaiting CI FB and Zaibi  Khan CI 3/4.  - to be submitted to Client 2/28.    Shibu H1B Offshore, HM review. 2/26.    Arthur L1 Reject.  (TP) L1 on 2/24.  Sr Project Manager CMCMST Vijay/ Beeline 2/20, Shared TP list PMs , awaiting HM response 2/20\n",
        "Vijay/ Beeline 4/2 . Shanmugapriya Kaveripakkam Arunagiri OIP Tentative DOJ 4/8\n",
        "Vijay/ Beeline 3/14. BGV in progress. Updated SO with change in Bill Rate  $135.08 Mosfaqus Salehin Offer in progress 3/13 Tentative DOJ 3/24. (135.08)   Saju will revert on Actual bill rate to proceed as per Rate List.   New SO received 3/5. Vijay/ Beeline. Mosfaqus, Susai Chandran and Ashish CI scheduled 3/6.     Only 1 role as per HM. Client Cancelled other 2 roles.  Mosfaqus CI 1st pref. for CI .  pending. Sriram Ac Ref. L2 2/27.  (Vijay to schedule L1) Product Manager Sukesh/ Saju Vijay/ Beeline -  2/19\n",
        "Ramchand Tripuraneni  Joined 4/8. Awating Revised bill rate 21/3  : Ramkrishna  selected  Ramchand  CI on 3/20.     3 L2 in progress, Saju to check with Sujith (Panel) if Interview 2/22.  Awaiting Panel Slots 2/21.  Glider L1 in progress Sr. Cloud Security Engineer / Sukesh/ Saju 2/18 (Vijay/ Beeline 2/18) Frisco (only Harivijayan Panel, Panel slot challenge)  Sujith Surendran, Abin Mathew L2 Panel.\n",
        "Checking with Fixed Term Offer with Candidate. Conversion Dennis Kim[285154]  CWR to FTE RH/ Arun\n",
        "31/3  : Still awating doc from ac.   Mona Sitlani  .25/3 : Documents pending with Account (Saju)24/3 : Awating account documents , Updated SO Arun/ RH 3/17. CWR to FTE SO/RR type Replacement 3/17. Mona Sitlani 150942 - Candidate docs received 3/10. Awaiting A/c docs. Tentative DOJ 4th Apr'25.LCA Poting completed 3/13.  Candidate docs (awaiting New Passport ) . Conversion   LCA initiated. Arun/ RH 2/11, Offer accepted BGV inititated, Pending H1B docs from Candidate 2/18\n",
        "Offer Accepted Awaiting Candidate/ Account Specific Docs. Sundar Munusuri- 151228 Conversion Arun/ RH 4/2\n",
        "Raguram Veeraparakaramapandian’s. Case filed, Tentative DOJ 4/28.Received Receipt # 4/7.  LCA initiated 2/27. Awaiting Filing Status 3/19.  LCA posting end date 3/19. Accepted New Offer 2/24. LCA initiated 3/4. 10 days posting.  as on 3/4.  Awaiting Comp Aproval 2/10.      Awaiting Account Specific Docs. from Neha/ Venkat Account.     Offer Accpeted, Awaiting H1B Docs . Conversion on Hold. Career Archt. Ace title not available. Pending with Comp. Tentative DOJ 1/20/25.  Team.  Offer in Progress. Data Engineer.   Raguram Veeraparakaramapandian’s  RTMO Conversion. Tentative DOC Jan'25 Arun/ RH\n",
        "Duplicate SO FTE. Glider L1 in progress 3/19. TMO Sr. Cloud Network Engineer Arun/ RH 3/18. FTE\n",
        "Sowmyasree\n",
        "1 L1 scheduled\n",
        "AISHA QADEER SIDDIQU\n",
        "\n",
        "\n",
        "Allocation WIP/Confirmed\n",
        "Client feedback pending\n",
        "Client interview Scheduled\n",
        "Client interview Scheduled\n",
        "Client interview Scheduled\n",
        "Client interview Scheduled\n",
        "Client interview Scheduled\n",
        "Client interview Scheduled\n",
        "Fulfilled and Closed\n",
        "Fulfilled and Closed\n",
        "Fulfilled and Closed\n",
        "Conversion\n",
        "Conversion\n",
        "Conversion\n",
        "Conversion\n",
        "Duplicate SO\n",
        "Allocation WIP/Confirmed\n",
        "L1 Interview - Scheduled\n",
        "L1 Interview - Scheduled\n",
        "\n",
        "\n",
        "Allocation WIP\n",
        "Less Profile flow, Niche Skill with location and Budget constraints (MEDIUM)\n",
        "Less Profile flow\n",
        "SO is opened between 16-30 days, Additional Profiles needed, L1 rejection rates remain at 30–50%\n",
        "Less Profile flow, SO is opened between 16-30 days\n",
        "SO is opened between 16-30 days, L1 rejection rates remain at 30–50%\n",
        "SO is opened between 16-30 days, L1 rejection rates remain at 30–50%\n",
        "SO Opened for more than 30 days, Less Profile flow\n",
        "Fulfilled\n",
        "Fulfilled\n",
        "Fulfilled\n",
        "Conversion\n",
        "Conversion\n",
        "Conversion\n",
        "Conversion\n",
        "Less Profile flow, SO is opened between 16-30 days\n",
        "Allocation WIP\n",
        "SO Opened for more than 30 days, Niche Skill with location and Budget constraints (MEDIUM), Additional Profiles needed, L1 rejection rates remain at 30–50%\n",
        "Rejection rates remain between 30–50% due to niche skills, location, and budget constraints\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "CqPV2XKgNX4e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gliner polars rapidfuzz pyxlsb fastexcel python-calamine gliner-spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJVGeVvRdNNN",
        "outputId": "715526dd-f380-4907-eb2e-b7d135d7e85b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gliner\n",
            "  Downloading gliner-0.2.20-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (1.21.0)\n",
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting pyxlsb\n",
            "  Downloading pyxlsb-1.0.10-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting fastexcel\n",
            "  Downloading fastexcel-0.14.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting python-calamine\n",
            "  Downloading python_calamine-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting gliner-spacy\n",
            "  Downloading gliner_spacy-0.0.11-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gliner) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers>=4.38.2 in /usr/local/lib/python3.11/dist-packages (from gliner) (4.51.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.4 in /usr/local/lib/python3.11/dist-packages (from gliner) (0.31.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gliner) (4.67.1)\n",
            "Collecting onnxruntime (from gliner)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from gliner) (0.2.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from fastexcel) (18.1.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from python-calamine) (24.2)\n",
            "Requirement already satisfied: spacy>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from gliner-spacy) (3.8.5)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from gliner-spacy) (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from gliner-spacy) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from gliner-spacy) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (4.13.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (0.15.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->gliner-spacy) (3.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->gliner) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->gliner) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->gliner) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->gliner) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gliner-spacy) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gliner-spacy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gliner-spacy) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gliner-spacy) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gliner-spacy) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gliner-spacy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gliner-spacy) (2.9.0.post0)\n",
            "Collecting coloredlogs (from onnxruntime->gliner)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime->gliner) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime->gliner) (5.29.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn->gliner-spacy) (2.2.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.0.0->gliner-spacy) (1.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn->gliner-spacy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn->gliner-spacy) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.0->gliner-spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.0->gliner-spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.0->gliner-spacy) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->gliner-spacy) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.4->gliner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.4->gliner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.4->gliner) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.4->gliner) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.0.0->gliner-spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.0.0->gliner-spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.0.0->gliner-spacy) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.0.0->gliner-spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.0.0->gliner-spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.0.0->gliner-spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.0.0->gliner-spacy) (7.1.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->gliner)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy>=3.0.0->gliner-spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.0.0->gliner-spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.0.0->gliner-spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.0.0->gliner-spacy) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3.0.0->gliner-spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.0.0->gliner-spacy) (0.1.2)\n",
            "Downloading gliner-0.2.20-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyxlsb-1.0.10-py2.py3-none-any.whl (23 kB)\n",
            "Downloading fastexcel-0.14.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_calamine-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (886 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m886.0/886.0 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gliner_spacy-0.0.11-py3-none-any.whl (6.8 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyxlsb, rapidfuzz, python-calamine, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, fastexcel, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, onnxruntime, nvidia-cusolver-cu12, gliner, gliner-spacy\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed coloredlogs-15.0.1 fastexcel-0.14.0 gliner-0.2.20 gliner-spacy-0.0.11 humanfriendly-10.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.22.0 python-calamine-0.3.2 pyxlsb-1.0.10 rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading GLiNER for testing descriptive data\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "from gliner import GLiNER\n",
        "# model = GLiNER.from_pretrained(\n",
        "#     \"juampahc/gliner_multi-v2.1-onnx\",\n",
        "#     load_onnx_model=True,\n",
        "#     onnx_model_file=\"model.onnx\"\n",
        "# )\n",
        "model = GLiNER.from_pretrained(\"urchade/gliner_smallv2.1\")\n",
        "end = time.time()\n",
        "print(f'📈📈 Model loading time: {end - start:.2f} seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456,
          "referenced_widgets": [
            "71d09608b9f74c28af194836e28c9fe1",
            "0595668f0620478b88a8354d98d2bc42",
            "08fbc6dca92a4e45b6a7a66488a43dda",
            "fdf092491e01455d99582af6cdfa465a",
            "be34161cbadd4b6cab78771d6744d5e9",
            "38178e990df44562a35ee61f8639f04c",
            "367ab2a540ce47928a8eaf1c142d7be5",
            "730accd4ef774f8c9daf126af3f53574",
            "3df20ad8c0084f6daa5a345093f4362c",
            "f7a19cb8542b423e960d316cad7ecb73",
            "d529d71ea2de440e9dc8b32aa6c613a2",
            "f3ae9fb8cd7c4582b20e4148c02adbea",
            "cb314908f241479f971abe806931a7eb",
            "c11ddc68d0cd4a45b1835563bba3edca",
            "b47249abc0fd4f08ab285aedec884158",
            "06d93f0c39ae4dbf8b50375c3a04c5a1",
            "f078ca9a4ad445158c2ed18343217e09",
            "290c8e0b14434679b180bf13b69fcdae",
            "a0e8ba17273b48769137922e3bc2a634",
            "83e095b2298942f49db94602b0389a63",
            "d3e6d3c69b23427b9612b7afc78cc9c7",
            "11485bfb3e484901a1d1fca519c447a5",
            "c9332a63910c4df2860d9511224e259a",
            "dffe9f5b3b30404ab72adb492f9c8739",
            "77fa2799e7e44fcd9726a25192efe39e",
            "e570d3a327614f4b9d02573881da0675",
            "cd3196041c3f43ae8020da08e0db7c3f",
            "dfc60e96ee484ea4bfb1045033088c8d",
            "ff31e15f19fe466f9deb31ead87424a1",
            "11b1d4c87c994e2aa10a6977ac7f3665",
            "fccd74014fc1429590df0f1526a7c8ce",
            "af8a84f659f145cab77deff4aa66804e",
            "e50f2a1810574d4497c8f8c892604fe4",
            "b73c881f4ef244b19cb2646c6f8aacf9",
            "203ca95f620d485195757be5225707d4",
            "16fd8aeeabcb4c8fbb4e1eee4afb2fcb",
            "c14f7dcc9eaf4affa3d39572a2d35ccf",
            "850aacbf29e84234a7a54d8880dcbbef",
            "05f2e30d4da646b2a127ebf06e88ecce",
            "724c3eb7661247f2ab4dfd2ae0fd5e9f",
            "e40291fae30a45efb4c11648f0f02ede",
            "218a51ee8d444e63a5433b07cb897c94",
            "eaf360fa61314c1c9135139dba28f943",
            "b24184c7a28a48328f2479321c789684",
            "a7611afdc0b44676a1d72e71997f1f80",
            "6466a51387fd49c5a84064875ba4187d",
            "d08f586229b64ff1bcd92985d5ac5ccd",
            "d2ccf78355d8475c99c960947e427a71",
            "b09945c542a44c7f86dafecf787c4c7d",
            "c7b1b1ab400547da8a637511fa539927",
            "4e230b39853c432abfb931b0954f85af",
            "a45e47148fa440409f06b505ac0f77d7",
            "f0db0461373c49e4ae5787aacce2fbdb",
            "93010d60ab9142a391f22a7d543bb71a",
            "f7f921ea4ba74cdfb36b88fce17f4f04",
            "c9b53ab4686d4f18a0e8afe627ad64bd",
            "99a62c12179848099d7bc12562d1a165",
            "55dbb0c358ea4786bdb5c7327175fc5f",
            "3ce77979aecc4c0cbdbbe1e838ef3c18",
            "d0cf01dca0104c3ebb9a2ecd50735aff",
            "c4ae2342619a4b76bea0a7b3a546a279",
            "8dfa6d0dccea4109b9ed2e78da740c35",
            "1a14cdea77114acbbd9b49f950d89bfa",
            "d6f7440abce94959a74045f1600066df",
            "d37feb15fc824d19ac56b24bde386fbb",
            "d2c6343f0e5d42c697ea9e8241e6af1f",
            "dcb106e10cc14ca889e598ef9947427a",
            "021a3e56c49c4784aa0f865b581521a3",
            "1d6f91feb0b8403e9f1832191b2a0ae8",
            "1219bcae90034662922b1997591ebf7f",
            "975b610e8bea4400b13d8346b946bf4b",
            "7812fba11f004484851c6fff87993aa3",
            "27b676a1c06c4d499b7292cb0693c677",
            "75546e2a04d94e1a85859eba930153de",
            "b7d2bcea68ec4c86bea25b59fb7bc387",
            "ae48b3d1a1144c83a2cc4a31e453ba89",
            "b408c884d4da4f2e91ae14da762c0999",
            "db13751be38c4be7b995be5f4532a774",
            "4202da98a084422fbd44526ea9d88f6e",
            "3b32b11d3c8743a588510b799a584b67",
            "d053e9465e5646ab972c185690f6d949",
            "c23bd7a3a17b458185408bf7020f593c",
            "4878543d041748058a969b0c685ef7c9",
            "187ce256ae9f45f0aa9f5a47b012cb52",
            "8c6578572b2740a794419c08749e6257",
            "9d77e93a5f6744958917b3e7d8f70f51",
            "87f65e87b1be4031bb43cea88c7e87c4",
            "af1a00b894e64e219212e9dcd520f06c"
          ]
        },
        "id": "yIXIzKB0OA7T",
        "outputId": "5b72f960-7f76-46d3-aded-3174fd58f316"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71d09608b9f74c28af194836e28c9fe1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/611M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3ae9fb8cd7c4582b20e4148c02adbea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "gliner_config.json:   0%|          | 0.00/477 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9332a63910c4df2860d9511224e259a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/4.76k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b73c881f4ef244b19cb2646c6f8aacf9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7611afdc0b44676a1d72e71997f1f80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9b53ab4686d4f18a0e8afe627ad64bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dcb106e10cc14ca889e598ef9947427a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db13751be38c4be7b995be5f4532a774"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈📈 Model loading time: 34.61 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunking for descriptive data using GLiNER\n",
        "def chunk_text(text, max_len=2048, overlap=48):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    text_len = len(text)\n",
        "    while start < text_len:\n",
        "        end = min(start + max_len, text_len)\n",
        "        chunks.append((text[start:end], start))\n",
        "        if end == text_len:\n",
        "            break\n",
        "        start = end - overlap\n",
        "    return chunks\n",
        "\n",
        "def merge_entities(chunked_entities):\n",
        "    merged = []\n",
        "    seen = set()\n",
        "    for ents, offset in chunked_entities:\n",
        "        for e in ents:\n",
        "            start = e['start'] + offset\n",
        "            end = e['end'] + offset\n",
        "            key = (e['text'], start, end, e['label'])\n",
        "            if key not in seen:\n",
        "                seen.add(key)\n",
        "                merged.append({\n",
        "                    'text': e['text'],\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'label': e['label']\n",
        "                })\n",
        "    return merged\n",
        "\n",
        "labels = [\"Name of Person\", \"Organization\", \"Location\", \"TravelRoute\", \"ID\"]\n",
        "\n",
        "chunks = chunk_text(string, max_len=1024, overlap=50)\n",
        "print(f\"✂️ Total chunks created: {len(chunks)}\")\n",
        "\n",
        "chunked_entities = []\n",
        "start_time = time.time()\n",
        "\n",
        "for i, (chunk, offset) in enumerate(chunks):\n",
        "    ents = model.predict_entities(chunk, labels, flat_ner=True, threshold=0.5)\n",
        "    chunked_entities.append((ents, offset))\n",
        "    print(f\"✅ Processed chunk {i+1}/{len(chunks)} with {len(ents)} entities\")\n",
        "\n",
        "merged_entities = merge_entities(chunked_entities)\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"🔍 Merged Detected Entities:\")\n",
        "for ent in merged_entities:\n",
        "    print(f\"🔹 '{ent['text']}' → 🏷️ {ent['label']} 📍({ent['start']}-{ent['end']})\")\n",
        "\n",
        "print(f\"\\n⏱️ Total Inference Time: {end_time - start_time:.4f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmhqW_4SL7J4",
        "outputId": "28edc007-dec2-43b4-fb8d-9170dc01343d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✂️ Total chunks created: 54\n",
            "✅ Processed chunk 1/54 with 0 entities\n",
            "✅ Processed chunk 2/54 with 4 entities\n",
            "✅ Processed chunk 3/54 with 9 entities\n",
            "✅ Processed chunk 4/54 with 5 entities\n",
            "✅ Processed chunk 5/54 with 6 entities\n",
            "✅ Processed chunk 6/54 with 1 entities\n",
            "✅ Processed chunk 7/54 with 1 entities\n",
            "✅ Processed chunk 8/54 with 2 entities\n",
            "✅ Processed chunk 9/54 with 2 entities\n",
            "✅ Processed chunk 10/54 with 1 entities\n",
            "✅ Processed chunk 11/54 with 9 entities\n",
            "✅ Processed chunk 12/54 with 0 entities\n",
            "✅ Processed chunk 13/54 with 4 entities\n",
            "✅ Processed chunk 14/54 with 1 entities\n",
            "✅ Processed chunk 15/54 with 0 entities\n",
            "✅ Processed chunk 16/54 with 2 entities\n",
            "✅ Processed chunk 17/54 with 3 entities\n",
            "✅ Processed chunk 18/54 with 4 entities\n",
            "✅ Processed chunk 19/54 with 0 entities\n",
            "✅ Processed chunk 20/54 with 2 entities\n",
            "✅ Processed chunk 21/54 with 5 entities\n",
            "✅ Processed chunk 22/54 with 7 entities\n",
            "✅ Processed chunk 23/54 with 4 entities\n",
            "✅ Processed chunk 24/54 with 2 entities\n",
            "✅ Processed chunk 25/54 with 3 entities\n",
            "✅ Processed chunk 26/54 with 0 entities\n",
            "✅ Processed chunk 27/54 with 0 entities\n",
            "✅ Processed chunk 28/54 with 0 entities\n",
            "✅ Processed chunk 29/54 with 0 entities\n",
            "✅ Processed chunk 30/54 with 2 entities\n",
            "✅ Processed chunk 31/54 with 0 entities\n",
            "✅ Processed chunk 32/54 with 0 entities\n",
            "✅ Processed chunk 33/54 with 0 entities\n",
            "✅ Processed chunk 34/54 with 0 entities\n",
            "✅ Processed chunk 35/54 with 0 entities\n",
            "✅ Processed chunk 36/54 with 3 entities\n",
            "✅ Processed chunk 37/54 with 5 entities\n",
            "✅ Processed chunk 38/54 with 5 entities\n",
            "✅ Processed chunk 39/54 with 5 entities\n",
            "✅ Processed chunk 40/54 with 0 entities\n",
            "✅ Processed chunk 41/54 with 4 entities\n",
            "✅ Processed chunk 42/54 with 0 entities\n",
            "✅ Processed chunk 43/54 with 0 entities\n",
            "✅ Processed chunk 44/54 with 1 entities\n",
            "✅ Processed chunk 45/54 with 2 entities\n",
            "✅ Processed chunk 46/54 with 5 entities\n",
            "✅ Processed chunk 47/54 with 4 entities\n",
            "✅ Processed chunk 48/54 with 15 entities\n",
            "✅ Processed chunk 49/54 with 7 entities\n",
            "✅ Processed chunk 50/54 with 17 entities\n",
            "✅ Processed chunk 51/54 with 8 entities\n",
            "✅ Processed chunk 52/54 with 6 entities\n",
            "✅ Processed chunk 53/54 with 2 entities\n",
            "✅ Processed chunk 54/54 with 2 entities\n",
            "🔍 Merged Detected Entities:\n",
            "🔹 'Oracle' → 🏷️ Organization 📍(1210-1216)\n",
            "🔹 'SAP' → 🏷️ Organization 📍(1221-1224)\n",
            "🔹 'Salesforce.com' → 🏷️ Organization 📍(1621-1635)\n",
            "🔹 'Dynamics 365' → 🏷️ Organization 📍(1639-1651)\n",
            "🔹 'SFDC' → 🏷️ Organization 📍(2052-2056)\n",
            "🔹 'SFDC' → 🏷️ Organization 📍(2218-2222)\n",
            "🔹 'Sales' → 🏷️ Organization 📍(2409-2414)\n",
            "🔹 'Marketing' → 🏷️ Organization 📍(2428-2437)\n",
            "🔹 'Marketing' → 🏷️ Organization 📍(2488-2497)\n",
            "🔹 'Sales' → 🏷️ Organization 📍(2502-2507)\n",
            "🔹 'Salesforce.com' → 🏷️ Organization 📍(2528-2542)\n",
            "🔹 'Engineering teams' → 🏷️ Organization 📍(2643-2660)\n",
            "🔹 'SFDC' → 🏷️ Organization 📍(2869-2873)\n",
            "🔹 'Engineering teams' → 🏷️ Organization 📍(3183-3200)\n",
            "🔹 'PdMs' → 🏷️ Organization 📍(3218-3222)\n",
            "🔹 'PdM’s' → 🏷️ Organization 📍(3350-3355)\n",
            "🔹 'PdM’s' → 🏷️ Organization 📍(3560-3565)\n",
            "🔹 'reputable institution' → 🏷️ Organization 📍(3706-3727)\n",
            "🔹 'Databricks' → 🏷️ Organization 📍(4032-4042)\n",
            "🔹 'Tableau' → 🏷️ Organization 📍(4057-4064)\n",
            "🔹 'SAP' → 🏷️ Organization 📍(4798-4801)\n",
            "🔹 'MS Dynamics' → 🏷️ Organization 📍(4808-4819)\n",
            "🔹 'Salesforce' → 🏷️ Organization 📍(4823-4833)\n",
            "🔹 'Databricks' → 🏷️ Organization 📍(4852-4862)\n",
            "🔹 'Google' → 🏷️ Organization 📍(5755-5761)\n",
            "🔹 'esign' → 🏷️ Organization 📍(5844-5849)\n",
            "🔹 'GitHub' → 🏷️ Organization 📍(7569-7575)\n",
            "🔹 'GitLab' → 🏷️ Organization 📍(7580-7586)\n",
            "🔹 'CircleCI' → 🏷️ Organization 📍(7998-8006)\n",
            "🔹 'GitLab' → 🏷️ Organization 📍(8011-8017)\n",
            "🔹 'AWS' → 🏷️ Location 📍(9240-9243)\n",
            "🔹 'AWS' → 🏷️ Organization 📍(9846-9849)\n",
            "🔹 'Azure' → 🏷️ Organization 📍(9853-9858)\n",
            "🔹 'Cloud' → 🏷️ Location 📍(10016-10021)\n",
            "🔹 'Cloud' → 🏷️ Location 📍(10132-10137)\n",
            "🔹 'Cloud' → 🏷️ Location 📍(10197-10202)\n",
            "🔹 'AWS' → 🏷️ Organization 📍(10423-10426)\n",
            "🔹 'Azure' → 🏷️ Organization 📍(10428-10433)\n",
            "🔹 'AWS' → 🏷️ Organization 📍(10587-10590)\n",
            "🔹 'Azure' → 🏷️ Organization 📍(10607-10612)\n",
            "🔹 'AWS' → 🏷️ Organization 📍(12007-12010)\n",
            "🔹 'Azure' → 🏷️ Organization 📍(12015-12020)\n",
            "🔹 'AWS' → 🏷️ Organization 📍(12210-12213)\n",
            "🔹 'Azure' → 🏷️ Organization 📍(12215-12220)\n",
            "🔹 'Scrum teams' → 🏷️ Organization 📍(12694-12705)\n",
            "🔹 'Appium' → 🏷️ Organization 📍(14972-14978)\n",
            "🔹 'Appium' → 🏷️ Organization 📍(15315-15321)\n",
            "🔹 'Appium' → 🏷️ Organization 📍(15899-15905)\n",
            "🔹 'Jenkins' → 🏷️ Organization 📍(16033-16040)\n",
            "🔹 'GitLab CI' → 🏷️ Organization 📍(16042-16051)\n",
            "🔹 'Appium' → 🏷️ Organization 📍(16826-16832)\n",
            "🔹 'Appium' → 🏷️ Organization 📍(17198-17204)\n",
            "🔹 'Appium' → 🏷️ Organization 📍(17350-17356)\n",
            "🔹 'Appium' → 🏷️ Organization 📍(17386-17392)\n",
            "🔹 'development teams' → 🏷️ Organization 📍(18806-18823)\n",
            "🔹 'DevOps' → 🏷️ Organization 📍(18825-18831)\n",
            "🔹 'NIST' → 🏷️ Organization 📍(19674-19678)\n",
            "🔹 'CIS' → 🏷️ Organization 📍(19680-19683)\n",
            "🔹 'ISO' → 🏷️ Organization 📍(19685-19688)\n",
            "🔹 'AWS' → 🏷️ Organization 📍(20251-20254)\n",
            "🔹 'Microsoft' → 🏷️ Organization 📍(20275-20284)\n",
            "🔹 'AWS' → 🏷️ Organization 📍(20569-20572)\n",
            "🔹 'Azure' → 🏷️ Organization 📍(20574-20579)\n",
            "🔹 'GCP' → 🏷️ Organization 📍(20585-20588)\n",
            "🔹 'AWS' → 🏷️ Organization 📍(20657-20660)\n",
            "🔹 'Azure' → 🏷️ Organization 📍(20669-20674)\n",
            "🔹 'NIST' → 🏷️ Organization 📍(20907-20911)\n",
            "🔹 'CIS' → 🏷️ Organization 📍(20913-20916)\n",
            "🔹 'CSP' → 🏷️ Organization 📍(22165-22168)\n",
            "🔹 'AWS Security Hub' → 🏷️ Organization 📍(22190-22206)\n",
            "🔹 'Azure Security Center' → 🏷️ Organization 📍(22208-22229)\n",
            "🔹 'GCP Security Command Center' → 🏷️ Organization 📍(22234-22261)\n",
            "🔹 'Hashicorp' → 🏷️ Organization 📍(22637-22646)\n",
            "🔹 'Product & Platforms Division' → 🏷️ Organization 📍(23210-23238)\n",
            "🔹 'Product Team' → 🏷️ Organization 📍(23863-23875)\n",
            "🔹 'Product Design Technology & Data Science' → 🏷️ Organization 📍(23897-23937)\n",
            "🔹 'Product Team' → 🏷️ Organization 📍(24323-24335)\n",
            "🔹 'clients' → 🏷️ Organization 📍(28354-28361)\n",
            "🔹 'clients' → 🏷️ Organization 📍(28428-28435)\n",
            "🔹 'testing team' → 🏷️ Organization 📍(34379-34391)\n",
            "🔹 'testing team' → 🏷️ Organization 📍(34422-34434)\n",
            "🔹 'Software Developers' → 🏷️ Organization 📍(34463-34482)\n",
            "🔹 'team' → 🏷️ Organization 📍(35196-35200)\n",
            "🔹 'team' → 🏷️ Organization 📍(35464-35468)\n",
            "🔹 'Team' → 🏷️ Organization 📍(35536-35540)\n",
            "🔹 'team' → 🏷️ Organization 📍(35605-35609)\n",
            "🔹 'team' → 🏷️ Organization 📍(35664-35668)\n",
            "🔹 'Team' → 🏷️ Organization 📍(36291-36295)\n",
            "🔹 'team' → 🏷️ Organization 📍(36339-36343)\n",
            "🔹 'team' → 🏷️ Organization 📍(36407-36411)\n",
            "🔹 'team' → 🏷️ Organization 📍(36506-36510)\n",
            "🔹 'team' → 🏷️ Organization 📍(36532-36536)\n",
            "🔹 'Cloud' → 🏷️ Location 📍(37336-37341)\n",
            "🔹 'AWS' → 🏷️ Organization 📍(37627-37630)\n",
            "🔹 'Azure' → 🏷️ Organization 📍(37632-37637)\n",
            "🔹 'AWS' → 🏷️ Organization 📍(37791-37794)\n",
            "🔹 'Azure' → 🏷️ Organization 📍(37811-37816)\n",
            "🔹 'AWS' → 🏷️ Organization 📍(39211-39214)\n",
            "🔹 'Azure' → 🏷️ Organization 📍(39219-39224)\n",
            "🔹 'AWS' → 🏷️ Organization 📍(39414-39417)\n",
            "🔹 'Azure' → 🏷️ Organization 📍(39419-39424)\n",
            "🔹 'internal/external engineering' → 🏷️ Organization 📍(41895-41924)\n",
            "🔹 'Lancaster, PA area' → 🏷️ Location 📍(43261-43279)\n",
            "🔹 'Quality & Regulatory organization' → 🏷️ Organization 📍(43536-43569)\n",
            "🔹 'CAPA' → 🏷️ Organization 📍(43837-43841)\n",
            "🔹 'CAPA' → 🏷️ Organization 📍(44075-44079)\n",
            "🔹 'CAPA' → 🏷️ Organization 📍(44510-44514)\n",
            "🔹 'SO#' → 🏷️ ID 📍(44637-44640)\n",
            "🔹 'David Fraley' → 🏷️ Name of Person 📍(44688-44700)\n",
            "🔹 'Oracle' → 🏷️ Organization 📍(45029-45035)\n",
            "🔹 'SAP' → 🏷️ Organization 📍(45040-45043)\n",
            "🔹 'Atlanta' → 🏷️ Location 📍(45441-45448)\n",
            "🔹 'Mosfaqus Salehin' → 🏷️ Name of Person 📍(45600-45616)\n",
            "🔹 'Mona Sitlani' → 🏷️ Name of Person 📍(45881-45893)\n",
            "🔹 'UID 150942' → 🏷️ ID 📍(45894-45904)\n",
            "🔹 'Sundar Munusuri' → 🏷️ Name of Person 📍(45931-45946)\n",
            "🔹 'JD' → 🏷️ Name of Person 📍(46068-46070)\n",
            "🔹 'Lancaster PA' → 🏷️ Location 📍(46081-46093)\n",
            "🔹 'Pittsburgh, PA' → 🏷️ Location 📍(46132-46146)\n",
            "🔹 'Oracle' → 🏷️ Organization 📍(46230-46236)\n",
            "🔹 'Sap' → 🏷️ Organization 📍(46237-46240)\n",
            "🔹 'PYTHON' → 🏷️ Organization 📍(46298-46304)\n",
            "🔹 'DATA BRICKS' → 🏷️ Organization 📍(46305-46316)\n",
            "🔹 'Aws Services' → 🏷️ Organization 📍(46336-46348)\n",
            "🔹 'Aws Cloud' → 🏷️ Organization 📍(46438-46447)\n",
            "🔹 'AWS' → 🏷️ Organization 📍(46542-46545)\n",
            "🔹 'AWS' → 🏷️ Organization 📍(46716-46719)\n",
            "🔹 'Aws Cloud' → 🏷️ Organization 📍(46731-46740)\n",
            "🔹 'ADOBE' → 🏷️ Organization 📍(47018-47023)\n",
            "🔹 'Beeline' → 🏷️ Organization 📍(47117-47124)\n",
            "🔹 'Beeline' → 🏷️ Organization 📍(47257-47264)\n",
            "🔹 'TMO' → 🏷️ Organization 📍(47537-47540)\n",
            "🔹 'Beeline' → 🏷️ Organization 📍(47546-47553)\n",
            "🔹 'Beeline' → 🏷️ Organization 📍(47658-47665)\n",
            "🔹 'Sathya Nagaraj' → 🏷️ Name of Person 📍(47680-47694)\n",
            "🔹 'Sujith' → 🏷️ Name of Person 📍(47751-47757)\n",
            "🔹 'TMO' → 🏷️ Organization 📍(47970-47973)\n",
            "🔹 'Vijay/ Beeline' → 🏷️ Organization 📍(48001-48015)\n",
            "🔹 'CWR' → 🏷️ Organization 📍(48022-48025)\n",
            "🔹 'Raja' → 🏷️ Name of Person 📍(48028-48032)\n",
            "🔹 'Anthony' → 🏷️ Name of Person 📍(48051-48058)\n",
            "🔹 'CI FB' → 🏷️ Organization 📍(48077-48082)\n",
            "🔹 'Sujith' → 🏷️ Name of Person 📍(48107-48113)\n",
            "🔹 'Anthony' → 🏷️ Name of Person 📍(48195-48202)\n",
            "🔹 'Sujith' → 🏷️ Name of Person 📍(48218-48224)\n",
            "🔹 'Jessica' → 🏷️ Name of Person 📍(48281-48288)\n",
            "🔹 'Jessica' → 🏷️ Name of Person 📍(48317-48324)\n",
            "🔹 'CI FB' → 🏷️ Organization 📍(48341-48346)\n",
            "🔹 'Shibu H1B Offshore' → 🏷️ Organization 📍(48409-48427)\n",
            "🔹 'Vijay/ Beeline' → 🏷️ Organization 📍(48512-48526)\n",
            "🔹 'Vijay/ Beeline' → 🏷️ Organization 📍(48580-48594)\n",
            "🔹 'Vijay/ Beeline' → 🏷️ Organization 📍(48660-48674)\n",
            "🔹 'Mosfaqus' → 🏷️ Organization 📍(48743-48751)\n",
            "🔹 'Vijay/ Beeline' → 🏷️ Organization 📍(48903-48917)\n",
            "🔹 'Mosfaqus' → 🏷️ Organization 📍(48919-48927)\n",
            "🔹 'Mosfaqus' → 🏷️ Organization 📍(49033-49041)\n",
            "🔹 'Vijay' → 🏷️ Organization 📍(49151-49156)\n",
            "🔹 'Beeline' → 🏷️ Organization 📍(49158-49165)\n",
            "🔹 'Ramchand Tripuraneni' → 🏷️ Name of Person 📍(49174-49194)\n",
            "🔹 'Beeline' → 🏷️ Organization 📍(49468-49475)\n",
            "🔹 'Mona Sitlani' → 🏷️ Name of Person 📍(49712-49724)\n",
            "🔹 'Mona Sitlani' → 🏷️ Name of Person 📍(49872-49884)\n",
            "🔹 'DOJ' → 🏷️ Organization 📍(49953-49956)\n",
            "🔹 'Arun/ RH' → 🏷️ Organization 📍(50242-50250)\n",
            "🔹 'DOJ' → 🏷️ Organization 📍(50311-50314)\n",
            "🔹 'Account' → 🏷️ Organization 📍(50579-50586)\n",
            "🔹 'TMO' → 🏷️ Organization 📍(50900-50903)\n",
            "🔹 'AISHA QADEER' → 🏷️ Name of Person 📍(50976-50988)\n",
            "🔹 'location' → 🏷️ Location 📍(52044-52052)\n",
            "🔹 'location' → 🏷️ Location 📍(52209-52217)\n",
            "\n",
            "⏱️ Total Inference Time: 27.1243 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the pipeling of GLiNER with Spacy\n",
        "\n",
        "import spacy\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "custom_config = {\n",
        "    \"gliner_model\": \"urchade/gliner_small-v2.1\",\n",
        "    \"chunk_size\": 2048,\n",
        "    \"labels\": [\"Name of Person\", \"Organization\", \"Location\", \"TravelRoute\", \"ID\"],\n",
        "    \"style\": \"ent\"\n",
        "}\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "nlp.add_pipe(\"gliner_spacy\")\n",
        "end = time.time()\n",
        "\n",
        "print(f'Time taken to load and set pipeline: {end - start:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "ed2e98fed2014e78814d04d8a35a4b97",
            "383c14dd7b6c4d489b604ba5593bf9c5",
            "b7dd62455b374eb4a592fb125276b9d6",
            "90da5641662b41bf95cc24d9f18eb65b",
            "a2a6e8a885564a5ea22271c85c69c03a",
            "a7801f966f7e4d02b5c475333eb25f87",
            "46d1c2ae3bdc40879e84052fcad4ebdb",
            "4b4b1ee7d73545438ac55d0189e9fc95",
            "7432601a5e5741c7b69034688651d8ac",
            "90b95a8874524138809322d0619438d4",
            "51dd40365fcd4173b0354b080420db58"
          ]
        },
        "id": "C4wmMV_qTiUE",
        "outputId": "f7fff74a-99a1-49e6-8cdc-709189a7af85"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed2e98fed2014e78814d04d8a35a4b97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to load and set pipeline: 9.29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "statement = \"\"\"David Fraley 284050\n",
        "Naveen shortlisted, waiting for final confirmation from client.\n",
        "Technical Data Analyst  Vinesh/ RH ADOBE 3/20\n",
        "Sasmitha Das CI pending. Amarnath and Anish L2 to be scheduled.  (Nishant Panel) Vijay/ Beeline COMCAST Data Analyst\n",
        "Client Ref. Poorna Chandra L1  scheduled with Jyothsih Glider 4/8. Java/Python Developer Jyothish/ TMO - Deb/ Beeline\n",
        "Keerthi  submitted to Client 4/7.  2 L2 Interview to be set up Abin.24/3 : wating 4 L2 (sukesh to help on panel ) 21/3 : Durga Maruthi L2 to be scheduled,.Srujan Sama,Sravan Kumar Ayyagari ,Yedunandan Vitakula (L2 to be scheduled)  Replacement of Teja Sai Ganta (288113) TMO Deb/ Beeline 3/14 - Kiran Krishnan Coordinate for Panel. Frisco/ Remote - Punna Rao / Donald/ Bujail/ Sujith - Panel\n",
        "Beeline/ Vijay. 2/4 : Sathya Nagaraj submitted to Client 4/7.  Roman L3 to be scheduled with Sujith (Panel)   Vignana (L2 with Raja) - Ajay Pasunoor L1 Completed (need to set up with Panel) 25/3 : Sathya Nagaraj (L3 to be set up with sujith) , Pradeep Dasari L2 with Raja as on 25th  Glider L1 in progress 3/19. TMO Sr. Cloud Network Engineer Vijay/ Beeline 3/18. CWR - Raja and Sagar - Panel\n",
        "Anthony, Kiran and Dennis CI FB awaited.   Russ L2 with Sujith 4/7 .  Pradeep Murthy Declined.   CI on 3/14 awaiting Client confirmation 3/18.  Anthony Interview with Sujith 3/18.  Sheetal - backup.  Pradeep L1 with Sujith 3/6.   Jessica and Zaibi CI Reject on 3/5. Jessica CI 3/3 Awaiting CI FB and Zaibi  Khan CI 3/4.  - to be submitted to Client 2/28.    Shibu H1B Offshore, HM review. 2/26.    Arthur L1 Reject.  (TP) L1 on 2/24.  Sr Project Manager CMCMST Vijay/ Beeline 2/20, Shared TP list PMs , awaiting HM response 2/20\n",
        "Vijay/ Beeline 4/2 . Shanmugapriya Kaveripakkam Arunagiri OIP Tentative DOJ 4/8\n",
        "Vijay/ Beeline 3/14. BGV in progress. Updated SO with change in Bill Rate  $135.08 Mosfaqus Salehin Offer in progress 3/13 Tentative DOJ 3/24. (135.08)   Saju will revert on Actual bill rate to proceed as per Rate List.   New SO received 3/5. Vijay/ Beeline. Mosfaqus, Susai Chandran and Ashish CI scheduled 3/6.     Only 1 role as per HM. Client Cancelled other 2 roles.  Mosfaqus CI 1st pref. for CI .  pending. Sriram Ac Ref. L2 2/27.  (Vijay to schedule L1) Product Manager Sukesh/ Saju Vijay/ Beeline -  2/19\n",
        "Ramchand Tripuraneni  Joined 4/8. Awating Revised bill rate 21/3  : Ramkrishna  selected  Ramchand  CI on 3/20.     3 L2 in progress, Saju to check with Sujith (Panel) if Interview 2/22.  Awaiting Panel Slots 2/21.  Glider L1 in progress Sr. Cloud Security Engineer / Sukesh/ Saju 2/18 (Vijay/ Beeline 2/18) Frisco (only Harivijayan Panel, Panel slot challenge)  Sujith Surendran, Abin Mathew L2 Panel.\n",
        "Checking with Fixed Term Offer with Candidate. Conversion Dennis Kim[285154]  CWR to FTE RH/ Arun\n",
        "31/3  : Still awating doc from ac.   Mona Sitlani  .25/3 : Documents pending with Account (Saju)24/3 : Awating account documents , Updated SO Arun/ RH 3/17. CWR to FTE SO/RR type Replacement 3/17. Mona Sitlani 150942 - Candidate docs received 3/10. Awaiting A/c docs. Tentative DOJ 4th Apr'25.LCA Poting completed 3/13.  Candidate docs (awaiting New Passport ) . Conversion   LCA initiated. Arun/ RH 2/11, Offer accepted BGV inititated, Pending H1B docs from Candidate 2/18\n",
        "Offer Accepted Awaiting Candidate/ Account Specific Docs. Sundar Munusuri- 151228 Conversion Arun/ RH 4/2\n",
        "Raguram Veeraparakaramapandian’s. Case filed, Tentative DOJ 4/28.Received Receipt # 4/7.  LCA initiated 2/27. Awaiting Filing Status 3/19.  LCA posting end date 3/19. Accepted New Offer 2/24. LCA initiated 3/4. 10 days posting.  as on 3/4.  Awaiting Comp Aproval 2/10.      Awaiting Account Specific Docs. from Neha/ Venkat Account.     Offer Accpeted, Awaiting H1B Docs . Conversion on Hold. Career Archt. Ace title not available. Pending with Comp. Tentative DOJ 1/20/25.  Team.  Offer in Progress. Data Engineer.   Raguram Veeraparakaramapandian’s  RTMO Conversion. Tentative DOC Jan'25 Arun/ RH\n",
        "Duplicate SO FTE. Glider L1 in progress 3/19. TMO Sr. Cloud Network Engineer Arun/ RH 3/18. FTE\n",
        "Sowmyasree\n",
        "1 L1 scheduled\n",
        "AISHA QADEER SIDDIQU\"\"\"\n",
        "sent = model.predict_entities(statement, ['Person', 'Organization'])\n",
        "for entity in sent:\n",
        "  print(f'{entity[\"text\"]} - {entity[\"label\"]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHcrDaMRg75_",
        "outputId": "d425540b-2fd9-46e4-da66-88ca81e6c07e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 961 has been truncated to 384\n",
            "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "David Fraley - Person\n",
            "Naveen - Person\n",
            "Vinesh - Person\n",
            "RH ADOBE - Organization\n",
            "Sasmitha Das - Person\n",
            "Amarnath - Person\n",
            "Beeline - Organization\n",
            "Poorna Chandra - Person\n",
            "Jyothish - Person\n",
            "TMO - Organization\n",
            "Beeline - Organization\n",
            "Keerthi - Person\n",
            "sukesh - Person\n",
            "Durga Maruthi - Person\n",
            "Srujan Sama - Person\n",
            "Sravan Kumar Ayyagari - Person\n",
            "Yedunandan Vitakula - Person\n",
            "Teja Sai Ganta - Person\n",
            "TMO - Organization\n",
            "Beeline - Organization\n",
            "Kiran Krishnan - Person\n",
            "Punna Rao - Person\n",
            "Sujith - Person\n",
            "Beeline - Organization\n",
            "Sathya Nagaraj - Person\n",
            "Sujith - Person\n",
            "Ajay Pasunoor - Person\n",
            "Sathya Nagaraj - Person\n",
            "Pradeep Dasari - Person\n",
            "TMO - Organization\n",
            "Beeline - Organization\n",
            "Raja - Person\n",
            "Sagar - Person\n",
            "Anthony - Person\n",
            "Kiran - Person\n",
            "CI FB - Organization\n",
            "Sujith - Person\n",
            "Pradeep Murthy - Person\n",
            "Anthony - Person\n",
            "Sujith - Person\n",
            "Sheetal - Person\n",
            "Sujith - Person\n",
            "Jessica - Person\n",
            "Jessica - Person\n",
            "CI FB - Organization\n",
            "Zaibi  Khan - Person\n",
            "CMCMST - Organization\n",
            "Beeline - Organization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "doc = nlp(string)\n",
        "end = time.time()\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, '--->', ent.label_)\n",
        "\n",
        "print(f'🥇🥇Total process timing: {end - start:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pQNuo5TSj7o",
        "outputId": "0bb9e948-edc5-4f31-a0ec-531c02cede14"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🥇🥇Total process timing: 132.18\n",
            "Cybersecurity Project Manager ---> person\n",
            "organization ---> organization\n",
            "technical teams ---> person\n",
            "stakeholders ---> person\n",
            "Agile PM ---> person\n",
            "Technical Data Analyst ---> person\n",
            "Sales users ---> person\n",
            "Salesforce.com ---> organization\n",
            "Dynamics 365 ---> organization\n",
            "Sales and Finance ---> organization\n",
            "Customer ---> person\n",
            "business teams ---> organization\n",
            "SFDC ---> organization\n",
            "SFDC ---> organization\n",
            "enterprise ---> organization\n",
            "users ---> person\n",
            "Salesforce.com ---> organization\n",
            "Dynamics ---> organization\n",
            "Product Managers ---> person\n",
            "Engineering teams ---> organization\n",
            "SFDC ---> organization\n",
            "Dynamics ---> organization\n",
            "managers ---> person\n",
            "Engineering teams ---> organization\n",
            "PdMs ---> organization\n",
            "PdM ---> organization\n",
            "PdM ---> organization\n",
            "Engineering teams ---> organization\n",
            "Preferred candidates ---> person\n",
            "institution ---> school\n",
            "BSA ---> organization\n",
            "Databricks ---> organization\n",
            "Power BI ---> organization\n",
            "Tableau ---> organization\n",
            "self-starter ---> person\n",
            "SAP/HANA ---> organization\n",
            "MS Dynamics ---> organization\n",
            "Salesforce ---> organization\n",
            "ADLS ---> organization\n",
            "Hadoop ---> organization\n",
            "Databricks ---> organization\n",
            "Kafka ---> organization\n",
            "Lead II ---> person\n",
            "senior leadership ---> person\n",
            "IT ---> organization\n",
            "Data Analyst ---> person\n",
            "Data Scientist ---> person\n",
            "Telecom eCommerce Omni channel ---> organization\n",
            "LLM ---> school\n",
            "AWS ---> organization\n",
            "Azure ---> organization\n",
            "Google ---> organization\n",
            "cross-functional teams ---> organization\n",
            "product managers ---> person\n",
            "designers ---> person\n",
            "QA engineers ---> person\n",
            "Git ---> organization\n",
            "GitHub ---> organization\n",
            "GitLab ---> organization\n",
            "Cloud Platforms ---> organization\n",
            "cloud platforms ---> organization\n",
            "AWS ---> organization\n",
            "GCP ---> organization\n",
            "Azure ---> organization\n",
            "CircleCI ---> organization\n",
            "Kubernetes ---> organization\n",
            "Kafka ---> organization\n",
            "AWS SQS ---> organization\n",
            "AWS ---> organization\n",
            "Azure ---> organization\n",
            "GCP ---> organization\n",
            "devops ---> organization\n",
            "Kubernetes ---> organization\n",
            "AWS ---> organization\n",
            "Azure ---> organization\n",
            "GCPExperience ---> organization\n",
            "Sr Cloud Network Engineer ---> person\n",
            "Cloud ---> organization\n",
            "AWS ---> organization\n",
            "Azure ---> organization\n",
            "AWS ---> organization\n",
            "Azure ---> organization\n",
            "security groups ---> organization\n",
            "cloud services ---> organization\n",
            "cross-functional teams ---> organization\n",
            "candidate ---> person\n",
            "AWS ---> organization\n",
            "Azure ---> organization\n",
            "candidate ---> person\n",
            "candidate ---> person\n",
            "AWS ---> organization\n",
            "Azure ---> organization\n",
            "cloud providers ---> organization\n",
            "candidate ---> person\n",
            "candidate ---> person\n",
            "government ---> organization\n",
            "candidate ---> person\n",
            "Project Manager ---> person\n",
            "SCRUM teams ---> organization\n",
            "SCRUM ---> organization\n",
            "external stakeholders ---> person\n",
            "product teams ---> organization\n",
            "senior leaders ---> person\n",
            "PI Planning ---> organization\n",
            "Product Owner ---> person\n",
            "Scrum of Scrum ---> organization\n",
            "Scrum ---> organization\n",
            "stakeholders ---> person\n",
            "IT ---> organization\n",
            "Project Manager ---> person\n",
            "Scrum Master ---> person\n",
            "project teams ---> organization\n",
            "team player ---> person\n",
            "stakeholders ---> person\n",
            "technical teams ---> person\n",
            "business stakeholders ---> person\n",
            "fintech ---> organization\n",
            "payment industry ---> organization\n",
            "Appium ---> organization\n",
            "Java ---> organization\n",
            "Appium ---> organization\n",
            "Appium ---> organization\n",
            "CI/CD ---> organization\n",
            "Jenkins ---> organization\n",
            "GitLab CI ---> organization\n",
            "developers ---> person\n",
            "development team ---> organization\n",
            "cross-functional teams ---> organization\n",
            "developers ---> person\n",
            "product managers ---> person\n",
            "SDETs ---> person\n",
            "junior testers ---> person\n",
            "engineers ---> person\n",
            "Appium ---> organization\n",
            "Appium ---> organization\n",
            "Appium ---> organization\n",
            "Jira ---> organization\n",
            "cross-functional teams ---> organization\n",
            "Product Manager ---> person\n",
            "cloud security solutions ---> organization\n",
            "engineers ---> person\n",
            "development teams ---> organization\n",
            "DevOps ---> person\n",
            "stakeholders ---> person\n",
            "team ---> person\n",
            "AWS ---> organization\n",
            "Azure ---> organization\n",
            "GCP ---> organization\n",
            "NIST ---> organization\n",
            "CIS ---> organization\n",
            "ISO ---> organization\n",
            "Information Security ---> organization\n",
            "AWS Certified Security ---> organization\n",
            "Azure Security ---> organization\n",
            "Engineer ---> person\n",
            "AWS ---> organization\n",
            "Azure ---> organization\n",
            "GCP ---> organization\n",
            "AWS ---> organization\n",
            "Azure ---> organization\n",
            "NIST ---> organization\n",
            "CIS ---> organization\n",
            "ISO ---> organization\n",
            "Sr. Cloud Security Engineer ---> person\n",
            "Wiz Security ---> organization\n",
            "CNAPP ---> organization\n",
            "CSP ---> organization\n",
            "AWS Security Hub ---> organization\n",
            "Azure Security Center ---> organization\n",
            "GCP Security Command Center ---> organization\n",
            "Gitops ---> organization\n",
            "Vault ---> organization\n",
            "Hashicorp ---> organization\n",
            "Managers ---> person\n",
            "Managers ---> person\n",
            "Product Managers ---> person\n",
            "Product & Platforms Division ---> organization\n",
            "Product Value Roadmap ---> organization\n",
            "product team ---> organization\n",
            "Product Managers ---> person\n",
            "Product Leadership ---> person\n",
            "Product Team ---> organization\n",
            "Product Design Technology & Data Science ---> organization\n",
            "Product Managers ---> person\n",
            "Senior Product Managers ---> person\n",
            "Product OKR ---> organization\n",
            "Product OKR ---> organization\n",
            "Product ---> person\n",
            "Senior Product Managers ---> person\n",
            "users ---> person\n",
            "product designers ---> person\n",
            "market ---> organization\n",
            "partner ecosystems ---> organization\n",
            "users ---> person\n",
            "marketplace ---> organization\n",
            "customer ---> person\n",
            "business ---> organization\n",
            "GTM ---> organization\n",
            "great people ---> person\n",
            "organization ---> organization\n",
            "product management ---> organization\n",
            "customers ---> person\n",
            "end users ---> person\n",
            "User Design ---> organization\n",
            "customer ---> person\n",
            "partner ecosystems ---> organization\n",
            "team ---> person\n",
            "DevOps ---> organization\n",
            "scrum teams ---> organization\n",
            "DevOps Tool ---> organization\n",
            "DevOps ---> organization\n",
            "DevOps ---> organization\n",
            "DevOps ---> organization\n",
            "DevOps ---> organization\n",
            "user representatives ---> person\n",
            "clients ---> person\n",
            "DevOps ---> organization\n",
            "clients ---> person\n",
            "DevOps ---> organization\n",
            "clients ---> person\n",
            "DevOps leads ---> person\n",
            "engineers ---> person\n",
            "stakeholders ---> person\n",
            "Architect ---> person\n",
            "Sr. Architect ---> person\n",
            "UST ---> organization\n",
            "Customer ---> person\n",
            "Project Team ---> organization\n",
            "Program Management ---> organization\n",
            "SDLC ---> organization\n",
            "PDLC ---> organization\n",
            "DevOps ---> organization\n",
            "DevOps ---> organization\n",
            "DevOps Engineers ---> person\n",
            "users ---> person\n",
            "CI/CD ---> organization\n",
            "users ---> person\n",
            "SME ---> organization\n",
            "stakeholders ---> person\n",
            "Application ---> school\n",
            "Architect ---> person\n",
            "team ---> organization\n",
            "DevOps ---> organization\n",
            "Contractor ---> person\n",
            "user representatives ---> person\n",
            "FAST ---> organization\n",
            "team members ---> person\n",
            "team ---> person\n",
            "team ---> person\n",
            "team ---> person\n",
            "Software Developers ---> person\n",
            "client ---> person\n",
            "customer ---> person\n",
            "customers ---> person\n",
            "Project ---> organization\n",
            "modules ---> organization\n",
            "share point libraries ---> organization\n",
            "universities ---> school\n",
            "team ---> person\n",
            "Customer ---> person\n",
            "development team ---> person\n",
            "customers ---> person\n",
            "Team ---> person\n",
            "team members ---> person\n",
            "team ---> person\n",
            "customer ---> person\n",
            "customer ---> person\n",
            "Team ---> organization\n",
            "mentor ---> person\n",
            "team ---> organization\n",
            "team ---> organization\n",
            "designers ---> person\n",
            "self ---> person\n",
            "team ---> organization\n",
            "team members ---> person\n",
            "customers ---> person\n",
            "customers ---> person\n",
            "Sr Cloud Network Engineer ---> person\n",
            "users ---> person\n",
            "Cloud ---> organization\n",
            "Cloud ---> organization\n",
            "AWS ---> organization\n",
            "Azure ---> organization\n",
            "AWS Direct Connect ---> organization\n",
            "Azure VPN Gateway ---> organization\n",
            "transit gateways ---> organization\n",
            "cloud services ---> organization\n",
            "cloud network infrastructure ---> organization\n",
            "candidate ---> person\n",
            "AWS ---> organization\n",
            "Azure ---> organization\n",
            "candidate ---> person\n",
            "candidate ---> person\n",
            "AWS ---> organization\n",
            "Azure ---> organization\n",
            "cloud providers ---> organization\n",
            "candidate ---> person\n",
            "candidate ---> person\n",
            "government ---> organization\n",
            "candidate ---> person\n",
            "Technical Product Owner ---> person\n",
            "eCommerce ---> organization\n",
            "Lifesciences ---> organization\n",
            "engineering teams ---> organization\n",
            "Jira ---> organization\n",
            "cross-functional teams ---> organization\n",
            "software developer ---> person\n",
            "systems engineer ---> person\n",
            "consumer products ---> organization\n",
            "internal/external engineering ---> organization\n",
            "Senior management ---> person\n",
            "Corrective and Preventive\n",
            "Action ---> organization\n",
            "CAPA ---> organization\n",
            "CAPA ---> organization\n",
            "Quality & Regulatory ---> organization\n",
            "CAPA ---> organization\n",
            "CAPA ---> organization\n",
            "CAPA ---> organization\n",
            "CAPA ---> organization\n",
            "spokespersons ---> person\n",
            "CAPAs ---> organization\n",
            "CAPA ---> organization\n",
            "CAPA ---> organization\n",
            "CAPA ---> organization\n",
            "CAPA ---> organization\n",
            "CAPA ---> organization\n",
            "SO ---> person\n",
            "David Fraley ---> person\n",
            "Oracle ---> organization\n",
            "SAP ---> organization\n",
            "Power BI ---> organization\n",
            "Power Apps ---> organization\n",
            "Qualtrics ---> organization\n",
            "lead developers ---> person\n",
            "SO ---> organization\n",
            "Mosfaqus Salehin ---> person\n",
            "CNAPP ---> organization\n",
            "Vault ---> organization\n",
            "Hashicorp ---> organization\n",
            "Mona Sitlani ---> person\n",
            "270106Raguram Veeraparakaramapandian ---> person\n",
            "NA ---> organization\n",
            "J&amp;J ---> organization\n",
            "JD ---> person\n",
            "Software Engineering ---> school\n",
            "Software Developer ---> person\n",
            "Oracle ---> organization\n",
            "Sap ---> organization\n",
            "Process Mining ---> organization\n",
            "TELECOM EXPERIENCE ---> organization\n",
            "Aws Cloud ---> organization\n",
            "product manager ---> person\n",
            "gitlab ---> organization\n",
            "AWS\n",
            "Kubernetes ---> organization\n",
            "Aws Cloud ---> organization\n",
            "David Fraley ---> person\n",
            "Naveen ---> person\n",
            "ADOBE ---> organization\n",
            "Sasmitha Das ---> person\n",
            "Amarnath ---> person\n",
            "Anish ---> person\n",
            "Nishant Panel ---> person\n",
            "COMCAST ---> organization\n",
            "Poorna Chandra ---> person\n",
            "Jyothsih ---> person\n",
            "Client ---> organization\n",
            "sukesh ---> person\n",
            "Durga Maruthi ---> person\n",
            "Srujan Sama ---> person\n",
            "Sravan Kumar ---> person\n",
            "Ayyagari ---> school\n",
            "Yedunandan Vitakula ---> school\n",
            "Teja Sai Ganta ---> person\n",
            "Beeline ---> organization\n",
            "Kiran Krishnan ---> person\n",
            "Punna Rao ---> person\n",
            "Sujith ---> person\n",
            "Vijay ---> person\n",
            "Sathya Nagaraj ---> person\n",
            "Sujith ---> person\n",
            "Vignana ---> organization\n",
            "Raja ---> person\n",
            "Ajay Pasunoor ---> person\n",
            "Sathya Nagaraj ---> person\n",
            "sujith ---> person\n",
            "Pradeep Dasari ---> person\n",
            "Raja ---> person\n",
            "TMO ---> organization\n",
            "Beeline ---> organization\n",
            "CWR ---> organization\n",
            "Raja ---> person\n",
            "Sagar ---> person\n",
            "Anthony ---> person\n",
            "Kiran ---> person\n",
            "Dennis ---> person\n",
            "CI FB ---> organization\n",
            "Russ ---> person\n",
            "Sujith ---> person\n",
            "Pradeep Murthy ---> person\n",
            "CI ---> organization\n",
            "Anthony ---> person\n",
            "Sujith ---> person\n",
            "Sheetal ---> person\n",
            "Pradeep ---> person\n",
            "Sujith ---> person\n",
            "Jessica ---> person\n",
            "CI ---> organization\n",
            "Jessica ---> person\n",
            "CI FB ---> organization\n",
            "Zaibi  Khan ---> person\n",
            "Client ---> organization\n",
            "Shibu H1B Offshore ---> organization\n",
            "Arthur ---> person\n",
            "Sr Project Manager ---> person\n",
            "CMCMST ---> organization\n",
            "Beeline ---> organization\n",
            "Beeline ---> organization\n",
            "Shanmugapriya ---> person\n",
            "Kaveripakkam ---> person\n",
            "OIP ---> organization\n",
            "DOJ ---> organization\n",
            "Beeline ---> organization\n",
            "BGV ---> organization\n",
            "SO ---> organization\n",
            "Mosfaqus Salehin ---> person\n",
            "DOJ ---> organization\n",
            "Saju ---> person\n",
            "Beeline ---> organization\n",
            "Mosfaqus ---> person\n",
            "Susai Chandran ---> person\n",
            "Ashish CI ---> person\n",
            "HM ---> organization\n",
            "Client ---> organization\n",
            "Mosfaqus ---> organization\n",
            "CI ---> organization\n",
            "Sriram ---> person\n",
            "Vijay ---> person\n",
            "Saju ---> person\n",
            "Beeline ---> organization\n",
            "Ramchand Tripuraneni ---> person\n",
            "Awating ---> organization\n",
            "Ramkrishna ---> person\n",
            "Ramchand  CI ---> organization\n",
            "Saju ---> person\n",
            "Sujith ---> person\n",
            "Saju ---> person\n",
            "Beeline ---> organization\n",
            "Frisco ---> organization\n",
            "Harivijayan Panel ---> organization\n",
            "Sujith Surendran ---> person\n",
            "Abin Mathew ---> person\n",
            "Candidate ---> person\n",
            "CWR ---> organization\n",
            "Mona Sitlani ---> person\n",
            "SO Arun/ RH ---> organization\n",
            "CWR ---> organization\n",
            "FTE ---> organization\n",
            "Mona Sitlani ---> person\n",
            "DOJ ---> organization\n",
            "LCA ---> organization\n",
            "Arun/ RH ---> organization\n",
            "BGV ---> organization\n",
            "Candidate ---> person\n",
            "Arun/ RH ---> organization\n",
            "Raguram Veeraparakaramapandian ---> person\n",
            "DOJ ---> organization\n",
            "LCA ---> organization\n",
            "LCA ---> organization\n",
            "LCA ---> organization\n",
            "Neha/ Venkat ---> person\n",
            "DOJ ---> organization\n",
            "Raguram Veeraparakaramapandian ---> person\n",
            "RTMO ---> organization\n",
            "Arun/ RH ---> organization\n",
            "TMO ---> organization\n",
            "Arun/ RH ---> organization\n",
            "SIDDIQU ---> organization\n",
            "SO ---> organization\n",
            "SO ---> organization\n",
            "SO ---> organization\n",
            "SO ---> organization\n",
            "SO ---> organization\n",
            "SO ---> organization\n",
            "SO ---> organization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "# model = GLiNER.from_pretrained(\"urchade/gliner_small-v2.1\")\n",
        "\n",
        "labels = [\"Person\", \"Organization\", \"Location\", \"TravelRoute\", \"ID\"]\n",
        "\n",
        "def chunk_text(text, max_len=2048, overlap=48):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    text_len = len(text)\n",
        "    while start < text_len:\n",
        "        end = min(start + max_len, text_len)\n",
        "        chunks.append((text[start:end], start))\n",
        "        if end == text_len:\n",
        "            break\n",
        "        start = end - overlap\n",
        "    return chunks\n",
        "\n",
        "def merge_entities(chunked_entities):\n",
        "    merged = []\n",
        "    seen = set()\n",
        "    for ents, offset in chunked_entities:\n",
        "        for e in ents:\n",
        "            start = e[\"start\"] + offset\n",
        "            end = e[\"end\"] + offset\n",
        "            key = (e[\"text\"], start, end, e[\"label\"])\n",
        "            if key not in seen:\n",
        "                seen.add(key)\n",
        "                merged.append({\n",
        "                    \"text\": e[\"text\"],\n",
        "                    \"start\": start,\n",
        "                    \"end\": end,\n",
        "                    \"label\": e[\"label\"]\n",
        "                })\n",
        "    return merged\n",
        "\n",
        "def process_chunk(args):\n",
        "    chunk, offset = args\n",
        "    ents = model.predict_entities(chunk, labels, flat_ner=True, threshold=0.5)\n",
        "    return (ents, offset)\n",
        "\n",
        "\n",
        "chunks = chunk_text(string, max_len=512, overlap=12)\n",
        "print(f\"✂️ Total chunks: {len(chunks)}\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "with Pool(processes=min(cpu_count(), 4)) as pool:\n",
        "    chunked_entities = pool.map(process_chunk, chunks)\n",
        "\n",
        "merged_entities = merge_entities(chunked_entities)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"🔍 Merged Detected Entities:\")\n",
        "for ent in merged_entities:\n",
        "    print(f\"🔹 '{ent['text']}' → 🏷️ {ent['label']} 📍({ent['start']}-{ent['end']})\")\n",
        "\n",
        "print(f\"\\n⏱️ Total Inference Time: {end_time - start_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "aCc-yVfsXJhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfGR2XLTY5ec",
        "outputId": "27587280-86f8-4346-af0a-04dc191069b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing non-nouuns and sending them to GLiNER\n",
        "# GLiNER Model:- urchade/gliner_small-v2.1\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import spacy\n",
        "from gliner import GLiNER\n",
        "\n",
        "start_spacy = time.time()\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "end_spacy = time.time()\n",
        "\n",
        "start_gliner = time.time()\n",
        "model = GLiNER.from_pretrained(\"urchade/gliner_small-v2.1\")\n",
        "end_gliner = time.time()\n",
        "\n",
        "patterns = {\n",
        "    'email': r'\\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\\b',\n",
        "    'phone': r'\\b(?:\\+?\\d{1,3}[-.\\s]?)?(?:\\(?\\d{2,4}\\)?[-.\\s]?)?\\d{3,4}[-.\\s]?\\d{4}\\b',\n",
        "    'id': r'\\b[A-Z]{5}[0-9]{4}[A-Z]\\b'\n",
        "}\n",
        "\n",
        "gliner_labels = [\"Person\", \"Organization\", \"Location\", \"ID\"]\n",
        "\n",
        "def time_it(func):\n",
        "  def wrapper(*args, **kwargs):\n",
        "    start = time.time()\n",
        "    result = func(*args, **kwargs)\n",
        "    end = time.time()\n",
        "    print(f'⏱️ {func.__name__} took {end - start:.2f} seconds')\n",
        "    return result\n",
        "  return wrapper\n",
        "\n",
        "@time_it\n",
        "def keep_nouns_with_positions(text):\n",
        "    doc = nlp(text)\n",
        "    noun_tokens = []\n",
        "    original_positions = []\n",
        "    for token in doc:\n",
        "        if token.pos_ in ['PROPN']:\n",
        "            noun_tokens.append(token.text)\n",
        "            original_positions.append((token.idx, token.idx + len(token.text)))\n",
        "    noun_text = ' '.join(noun_tokens)\n",
        "    return noun_text, original_positions\n",
        "\n",
        "@time_it\n",
        "def chunk_text(text, max_len=2048, overlap=48):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    text_len = len(text)\n",
        "    while start < text_len:\n",
        "        end = min(start + max_len, text_len)\n",
        "        chunks.append((text[start:end], start))\n",
        "        if end == text_len:\n",
        "            break\n",
        "        start = end - overlap\n",
        "    return chunks\n",
        "\n",
        "def map_positions(ents, noun_positions, chunk_offset):\n",
        "    mapped_ents = []\n",
        "    for ent in ents:\n",
        "        ent_start = ent['start']\n",
        "        ent_end = ent['end']\n",
        "        start_char = None\n",
        "        for orig_start, orig_end in noun_positions:\n",
        "            if orig_start <= ent_start < orig_end:\n",
        "                start_char = orig_start + (ent_start - orig_start)\n",
        "                break\n",
        "        if start_char is None:\n",
        "            start_char = ent_start\n",
        "        end_char = None\n",
        "        for orig_start, orig_end in noun_positions:\n",
        "            if orig_start < ent_end <= orig_end:\n",
        "                end_char = orig_start + (ent_end - orig_start)\n",
        "                break\n",
        "        if end_char is None:\n",
        "            end_char = ent_end\n",
        "\n",
        "        mapped_ents.append({\n",
        "            'text': ent['text'],\n",
        "            'start': start_char + chunk_offset,\n",
        "            'end': end_char + chunk_offset,\n",
        "            'label': ent['label']\n",
        "        })\n",
        "    return mapped_ents\n",
        "\n",
        "@time_it\n",
        "def extract_entities(text):\n",
        "    regex_entities = []\n",
        "    for label, pattern in patterns.items():\n",
        "        for match in re.finditer(pattern, text):\n",
        "            regex_entities.append({\n",
        "                'text': match.group(),\n",
        "                'start': match.start(),\n",
        "                'end': match.end(),\n",
        "                'label': label\n",
        "            })\n",
        "\n",
        "    noun_text, noun_positions = keep_nouns_with_positions(text)\n",
        "\n",
        "    with open('filtered_nouns_text.txt', 'w', encoding='utf-8') as f:\n",
        "        for token in noun_text.split():\n",
        "            f.write(token + '\\n')\n",
        "\n",
        "\n",
        "    chunks = chunk_text(noun_text, max_len=512, overlap=12)\n",
        "\n",
        "    gliner_entities = []\n",
        "    for chunk_text_part, offset in chunks:\n",
        "        ents = model.predict_entities(chunk_text_part, gliner_labels, flat_ner=True, threshold=0.5)\n",
        "        mapped = map_positions(ents, noun_positions, offset)\n",
        "        gliner_entities.extend(mapped)\n",
        "\n",
        "    all_entities = regex_entities + gliner_entities\n",
        "    all_entities.sort(key=lambda x: x['start'])\n",
        "\n",
        "    return all_entities\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    start_total = time.time()\n",
        "    entities = extract_entities(string)\n",
        "    end_total = time.time()\n",
        "\n",
        "    print(f\"🕒 SpaCy loading time: {end_spacy - start_spacy:.2f} seconds\")\n",
        "    print(f\"🕒 GLiNER loading time: {end_gliner - start_gliner:.2f} seconds\")\n",
        "    print(f\"🕒 Total processing time: {end_total - start_total:.2f} seconds\")\n",
        "\n",
        "    with open('extracted_entities.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump({'entities': entities}, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "    for ent in entities:\n",
        "        print(f\"🔹 {ent['label'].upper()}: '{ent['text']}' [{ent['start']}:{ent['end']}]\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "17e67ab57f67417e910565f354c03bab",
            "840ceea2592d45079d61e418f7d8a7af",
            "2f89a0c10b8441c4afb8cd31b2b026a2",
            "9eb1fed76e494d6b88283a04ecd37275",
            "7aec09f474d64c4a9e0d71de3b453dad",
            "1be9985e5942448da3faa1003ecfb669",
            "b11909a41af24fadb90059da4826fb36",
            "834089aef47a45da9ca68e9732dd0d67",
            "e0193453ed2644c1886d187a1f354a06",
            "9adb04a683864875984435004ab7857e",
            "069ec5b3301a4a998794071ce26f1493"
          ]
        },
        "id": "lyGJC_mpZHoh",
        "outputId": "f08547b5-57e2-43e5-a83e-b07b89ea2aa8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17e67ab57f67417e910565f354c03bab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ keep_nouns_with_positions took 1.63 seconds\n",
            "⏱️ chunk_text took 0.00 seconds\n",
            "⏱️ extract_entities took 11.64 seconds\n",
            "🕒 SpaCy loading time: 0.63 seconds\n",
            "🕒 GLiNER loading time: 5.09 seconds\n",
            "🕒 Total processing time: 11.64 seconds\n",
            "🔹 ORGANIZATION: 'Oracle' [105:111]\n",
            "🔹 ORGANIZATION: 'SAP' [112:115]\n",
            "🔹 PERSON: 'Technical Data Analyst' [220:242]\n",
            "🔹 ORGANIZATION: 'Salesforce.com' [252:266]\n",
            "🔹 ORGANIZATION: 'Dynamics' [267:275]\n",
            "🔹 ORGANIZATION: 'Dynamics' [299:307]\n",
            "🔹 ORGANIZATION: 'SFDC' [308:312]\n",
            "🔹 ORGANIZATION: 'Dynamics' [313:321]\n",
            "🔹 ORGANIZATION: 'SAP' [322:325]\n",
            "🔹 ORGANIZATION: 'Salesforce.com' [371:385]\n",
            "🔹 ORGANIZATION: 'Dynamics' [386:394]\n",
            "🔹 ORGANIZATION: 'SFDC' [412:416]\n",
            "🔹 ORGANIZATION: 'Dynamics' [417:425]\n",
            "🔹 ORGANIZATION: 'Tableau' [570:577]\n",
            "🔹 ORGANIZATION: 'Salesforce' [599:609]\n",
            "🔹 ID: 'Lead II' [644:651]\n",
            "🔹 PERSON: 'Data Analyst' [684:696]\n",
            "🔹 PERSON: 'Data Scientist' [697:711]\n",
            "🔹 LOCATION: 'Telecom' [733:740]\n",
            "🔹 ORGANIZATION: 'Databricks' [781:791]\n",
            "🔹 ORGANIZATION: 'Tableau' [825:832]\n",
            "🔹 LOCATION: 'AWS' [900:903]\n",
            "🔹 LOCATION: 'Azure' [904:909]\n",
            "🔹 ORGANIZATION: 'Google' [910:916]\n",
            "🔹 ORGANIZATION: 'GitLab' [1240:1246]\n",
            "🔹 ORGANIZATION: 'JUnit' [1261:1266]\n",
            "🔹 LOCATION: 'AWS' [1283:1286]\n",
            "🔹 LOCATION: 'GCP' [1287:1290]\n",
            "🔹 LOCATION: 'Azure' [1291:1296]\n",
            "🔹 ORGANIZATION: 'GitLab' [1350:1356]\n",
            "🔹 LOCATION: 'AWS' [1521:1524]\n",
            "🔹 LOCATION: 'AWS' [1651:1654]\n",
            "🔹 LOCATION: 'Azure' [1655:1660]\n",
            "🔹 LOCATION: 'GCP' [1661:1664]\n",
            "🔹 LOCATION: 'Azure' [1804:1809]\n",
            "🔹 LOCATION: 'GCPExperience' [1810:1823]\n",
            "🔹 PERSON: 'Sr Cloud Network Engineer' [1830:1855]\n",
            "🔹 LOCATION: 'AWS' [1895:1898]\n",
            "🔹 LOCATION: 'Azure' [1899:1904]\n",
            "🔹 LOCATION: 'AWS' [1905:1908]\n",
            "🔹 LOCATION: 'Azure' [1924:1929]\n",
            "🔹 ORGANIZATION: 'AWS Azure' [2012:2021]\n",
            "🔹 LOCATION: 'AWS' [2032:2035]\n",
            "🔹 LOCATION: 'Azure' [2036:2041]\n",
            "🔹 PERSON: 'Project Manager' [2052:2067]\n",
            "🔹 PERSON: 'Product Owner' [2209:2222]\n",
            "🔹 ORGANIZATION: 'IT' [2300:2302]\n",
            "🔹 PERSON: 'Project Manager' [2313:2328]\n",
            "🔹 PERSON: 'Scrum Master' [2329:2341]\n",
            "🔹 PERSON: 'Scrum Master' [2394:2406]\n",
            "🔹 PERSON: 'PMP' [2407:2410]\n",
            "🔹 PERSON: 'Senior Software Development Engineer' [2411:2447]\n",
            "🔹 ORGANIZATION: 'Appium' [2521:2527]\n",
            "🔹 LOCATION: 'iOS' [2638:2641]\n",
            "🔹 LOCATION: 'Android' [2642:2649]\n",
            "🔹 ORGANIZATION: 'Appium' [2650:2656]\n",
            "🔹 ORGANIZATION: 'Jenkins' [2678:2685]\n",
            "🔹 ORGANIZATION: 'GitLab' [2686:2692]\n",
            "🔹 ORGANIZATION: 'Appium' [2814:2820]\n",
            "🔹 ORGANIZATION: 'Appium' [2872:2878]\n",
            "🔹 ORGANIZATION: 'Appium' [2908:2914]\n",
            "🔹 ORGANIZATION: 'Appium' [2925:2931]\n",
            "🔹 LOCATION: 'iOS' [2932:2935]\n",
            "🔹 LOCATION: 'AWS' [3226:3229]\n",
            "🔹 LOCATION: 'Azure GCP' [3230:3239]\n",
            "🔹 ORGANIZATION: 'Microsoft' [3310:3319]\n",
            "🔹 PERSON: 'Certified Azure Security Engineer' [3320:3353]\n",
            "🔹 PERSON: 'CISSP' [3406:3411]\n",
            "🔹 LOCATION: 'AWS' [3412:3415]\n",
            "🔹 LOCATION: 'Azure' [3416:3421]\n",
            "🔹 LOCATION: 'GCP' [3422:3425]\n",
            "🔹 LOCATION: 'AWS Shield' [3426:3436]\n",
            "🔹 ORGANIZATION: 'Azure Security Center' [3437:3458]\n",
            "🔹 ORGANIZATION: 'Cloud Security Wiz' [3551:3569]\n",
            "🔹 ORGANIZATION: 'CNAPP' [3579:3584]\n",
            "🔹 ORGANIZATION: 'CSP' [3626:3629]\n",
            "🔹 ORGANIZATION: 'AWS Security Hub' [3630:3646]\n",
            "🔹 ORGANIZATION: 'Azure Security Center' [3647:3668]\n",
            "🔹 ORGANIZATION: 'Hashicorp' [3752:3761]\n",
            "🔹 PERSON: 'Product Managers' [3836:3852]\n",
            "🔹 PERSON: 'Product Managers' [3992:4008]\n",
            "🔹 PERSON: 'Product Managers' [4099:4115]\n",
            "🔹 PERSON: 'Senior Product Managers' [4116:4139]\n",
            "🔹 PERSON: 'Senior Product Managers' [4316:4339]\n",
            "🔹 ORGANIZATION: 'DevOps' [4879:4885]\n",
            "🔹 PERSON: 'Application Architect' [5333:5354]\n",
            "🔹 PERSON: 'Contractor' [5475:5485]\n",
            "🔹 ORGANIZATION: 'Software Developers' [5727:5746]\n",
            "🔹 ORGANIZATION: 'Team' [5892:5896]\n",
            "🔹 ORGANIZATION: 'Team' [5975:5979]\n",
            "🔹 PERSON: 'Sr Cloud Network Engineer' [6017:6042]\n",
            "🔹 ORGANIZATION: 'AWS' [6092:6095]\n",
            "🔹 LOCATION: 'Azure' [6111:6116]\n",
            "🔹 ORGANIZATION: 'AWS' [6199:6202]\n",
            "🔹 ORGANIZATION: 'Azure' [6203:6208]\n",
            "🔹 ORGANIZATION: 'AWS' [6219:6222]\n",
            "🔹 ORGANIZATION: 'Azure' [6223:6228]\n",
            "🔹 PERSON: 'Technical Product Owner' [6305:6328]\n",
            "🔹 LOCATION: 'Lancaster PA' [6656:6668]\n",
            "🔹 ORGANIZATION: 'CAPA' [6687:6691]\n",
            "🔹 ORGANIZATION: 'CAPA' [6692:6696]\n",
            "🔹 ORGANIZATION: 'CAPA' [6755:6759]\n",
            "🔹 ORGANIZATION: 'CAPA' [6779:6783]\n",
            "🔹 ORGANIZATION: 'CAPA' [6799:6803]\n",
            "🔹 ORGANIZATION: 'CAPA' [6819:6823]\n",
            "🔹 ORGANIZATION: 'CAPA' [6860:6864]\n",
            "🔹 ORGANIZATION: 'CAPA' [6910:6914]\n",
            "🔹 ORGANIZATION: 'CAPA' [6915:6919]\n",
            "🔹 ORGANIZATION: 'CAPA' [6942:6946]\n",
            "🔹 PERSON: 'David Fraley' [6982:6994]\n",
            "🔹 ORGANIZATION: 'ERP' [7008:7011]\n",
            "🔹 ORGANIZATION: 'Oracle' [7012:7018]\n",
            "🔹 ORGANIZATION: 'SAP' [7019:7022]\n",
            "🔹 ORGANIZATION: 'Springboot' [7126:7136]\n",
            "🔹 LOCATION: 'Atlanta' [7166:7173]\n",
            "🔹 ORGANIZATION: 'Appium' [7213:7219]\n",
            "🔹 ORGANIZATION: 'Hashicorp' [7330:7339]\n",
            "🔹 PERSON: 'Mona Sitlani' [7346:7358]\n",
            "🔹 ID: 'UID' [7359:7362]\n",
            "🔹 PERSON: 'Sundar Munusuri' [7366:7381]\n",
            "🔹 PERSON: 'Veeraparakaramapandian' [7386:7408]\n",
            "🔹 LOCATION: 'Lancaster PA' [7426:7438]\n",
            "🔹 LOCATION: 'Pittsburgh PA' [7450:7463]\n",
            "🔹 ORGANIZATION: 'Oracle' [7522:7528]\n",
            "🔹 ORGANIZATION: 'Tableau' [7578:7585]\n",
            "🔹 LOCATION: 'AWS' [7764:7767]\n",
            "🔹 LOCATION: 'AWS' [7797:7800]\n",
            "🔹 PERSON: 'David Fraley' [7978:7990]\n",
            "🔹 PERSON: 'Naveen' [7991:7997]\n",
            "🔹 ORGANIZATION: 'ADOBE' [8032:8037]\n",
            "🔹 PERSON: 'Sasmitha Das' [8038:8050]\n",
            "🔹 ORGANIZATION: 'Beeline' [8084:8091]\n",
            "🔹 ORGANIZATION: 'COMCAST' [8092:8099]\n",
            "🔹 PERSON: 'Poorna Chandra' [8124:8138]\n",
            "🔹 PERSON: 'Jyothsih' [8139:8147]\n",
            "🔹 PERSON: 'Jyothish' [8177:8185]\n",
            "🔹 ORGANIZATION: 'Deb/ Beeline' [8191:8203]\n",
            "🔹 PERSON: 'Keerthi' [8204:8211]\n",
            "🔹 PERSON: 'Durga Maruthi' [8219:8232]\n",
            "🔹 PERSON: 'Sravan Kumar' [8245:8257]\n",
            "🔹 PERSON: 'Teja Sai Ganta' [8299:8313]\n",
            "🔹 ORGANIZATION: 'TMO' [8314:8317]\n",
            "🔹 ORGANIZATION: 'Deb/ Beeline' [8318:8330]\n",
            "🔹 PERSON: 'Kiran Krishnan' [8331:8345]\n",
            "🔹 LOCATION: 'Frisco' [8363:8369]\n",
            "🔹 ORGANIZATION: 'Beeline' [8417:8424]\n",
            "🔹 PERSON: 'Vijay' [8426:8431]\n",
            "🔹 PERSON: 'Sathya Nagaraj' [8432:8446]\n",
            "🔹 PERSON: 'Roman L3' [8454:8462]\n",
            "🔹 PERSON: 'Vignana Raja' [8476:8488]\n",
            "🔹 PERSON: 'Ajay Pasunoor' [8489:8502]\n",
            "🔹 PERSON: 'Sathya Nagaraj' [8519:8533]\n",
            "🔹 PERSON: 'Pradeep Dasari' [8544:8558]\n",
            "🔹 ORGANIZATION: 'Vijay/ Beeline' [8603:8617]\n",
            "🔹 ORGANIZATION: 'CWR' [8618:8621]\n",
            "🔹 PERSON: 'Anthony' [8639:8646]\n",
            "🔹 ORGANIZATION: 'CI FB' [8660:8665]\n",
            "🔹 PERSON: 'Russ Sujith' [8666:8677]\n",
            "🔹 PERSON: 'Pradeep Murthy' [8682:8696]\n",
            "🔹 PERSON: 'Pradeep Sujith' [8747:8761]\n",
            "🔹 PERSON: 'Jessica Zaibi' [8762:8775]\n",
            "🔹 PERSON: 'Jessica' [8786:8793]\n",
            "🔹 LOCATION: 'Offshore' [8831:8839]\n",
            "🔹 ORGANIZATION: 'CMCMST' [8882:8888]\n",
            "🔹 ORGANIZATION: 'Vijay/ Beeline' [8889:8903]\n",
            "🔹 ORGANIZATION: 'Vijay/ Beeline' [8918:8932]\n",
            "🔹 ORGANIZATION: 'DOJ' [8984:8987]\n",
            "🔹 ORGANIZATION: 'Vijay/ Beeline' [8988:9002]\n",
            "🔹 ORGANIZATION: 'Mosfaqus' [9016:9024]\n",
            "🔹 ORGANIZATION: 'DOJ' [9049:9052]\n",
            "🔹 ORGANIZATION: 'Vijay/ Beeline' [9075:9089]\n",
            "🔹 ORGANIZATION: 'Mosfaqus' [9090:9098]\n",
            "🔹 PERSON: 'Susai Chandran' [9099:9113]\n",
            "🔹 ORGANIZATION: 'Mosfaqus' [9134:9142]\n",
            "🔹 ORGANIZATION: 'Vijay' [9170:9175]\n",
            "🔹 PERSON: 'Sukesh' [9192:9198]\n",
            "🔹 PERSON: 'Saju' [9200:9204]\n",
            "🔹 ORGANIZATION: 'Vijay/ Beeline' [9205:9219]\n",
            "🔹 PERSON: 'Ramchand Tripuraneni' [9220:9240]\n",
            "🔹 PERSON: 'Ramchand' [9267:9275]\n",
            "🔹 PERSON: 'Saju Sujith' [9279:9290]\n",
            "🔹 PERSON: 'Sukesh' [9353:9359]\n",
            "🔹 PERSON: 'Saju' [9361:9365]\n",
            "🔹 ORGANIZATION: 'Vijay/ Beeline' [9371:9385]\n",
            "🔹 PERSON: 'Sujith' [9417:9423]\n",
            "🔹 PERSON: 'Abin Mathew' [9434:9445]\n",
            "🔹 PERSON: 'Dennis Kim' [9465:9475]\n",
            "🔹 PERSON: 'Mona Sitlani' [9507:9519]\n",
            "🔹 PERSON: 'Arun' [9547:9551]\n",
            "🔹 PERSON: 'Mona Sitlani' [9576:9588]\n",
            "🔹 ORGANIZATION: 'DOJ' [9601:9604]\n",
            "🔹 PERSON: 'Arun' [9650:9654]\n",
            "🔹 PERSON: 'Sundar Munusuri' [9735:9750]\n",
            "🔹 PERSON: 'Arun' [9763:9767]\n",
            "🔹 PERSON: 'Veeraparakaramapandian' [9780:9802]\n",
            "🔹 ORGANIZATION: 'DOJ' [9813:9816]\n",
            "🔹 PERSON: 'Venkat' [9918:9924]\n",
            "🔹 ORGANIZATION: 'DOJ' [9978:9981]\n",
            "🔹 PERSON: 'Raguram' [10010:10017]\n",
            "🔹 PERSON: 'Veeraparakaramapandian' [10018:10040]\n",
            "🔹 PERSON: 'Arun' [10068:10072]\n",
            "🔹 PERSON: 'Arun' [10130:10134]\n",
            "🔹 PERSON: 'Sowmyasree' [10143:10153]\n",
            "🔹 PERSON: 'AISHA QADEER' [10154:10166]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing non-nouuns and sending them to GLiNER\n",
        "# GLiNER Model:- gliner-community/gliner_small-v2.5\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import spacy\n",
        "from gliner import GLiNER\n",
        "\n",
        "start_spacy = time.time()\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "end_spacy = time.time()\n",
        "\n",
        "start_gliner = time.time()\n",
        "model = GLiNER.from_pretrained(\"gliner-community/gliner_small-v2.5\")\n",
        "end_gliner = time.time()\n",
        "\n",
        "patterns = {\n",
        "    'email': r'\\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\\b',\n",
        "    'phone': r'\\b(?:\\+?\\d{1,3}[-.\\s]?)?(?:\\(?\\d{2,4}\\)?[-.\\s]?)?\\d{3,4}[-.\\s]?\\d{4}\\b',\n",
        "    'id': r'\\b[A-Z]{5}[0-9]{4}[A-Z]\\b'\n",
        "}\n",
        "\n",
        "gliner_labels = [\"Person\", \"Organization\", \"Location\", \"ID\"]\n",
        "\n",
        "def time_it(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f'⏱️ {func.__name__} took {end - start:.2f} seconds')\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "@time_it\n",
        "def keep_nouns_with_positions(text):\n",
        "    doc = nlp(text)\n",
        "    noun_tokens = []\n",
        "    original_positions = []\n",
        "    for token in doc:\n",
        "        if token.pos_ == 'PROPN':\n",
        "            noun_tokens.append(token.text)\n",
        "            original_positions.append((token.idx, token.idx + len(token.text)))\n",
        "    noun_text = ' '.join(noun_tokens)\n",
        "    return noun_text, original_positions\n",
        "\n",
        "@time_it\n",
        "def chunk_text(text, max_len=512, overlap=48):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    text_len = len(text)\n",
        "    while start < text_len:\n",
        "        end = min(start + max_len, text_len)\n",
        "        chunks.append((text[start:end], start))\n",
        "        if end == text_len:\n",
        "            break\n",
        "        start = end - overlap\n",
        "    return chunks\n",
        "\n",
        "def map_positions(ents, noun_positions, chunk_offset):\n",
        "    mapped_ents = []\n",
        "    for ent in ents:\n",
        "        ent_start = ent['start']\n",
        "        ent_end = ent['end']\n",
        "        start_char = None\n",
        "        for orig_start, orig_end in noun_positions:\n",
        "            if orig_start <= ent_start < orig_end:\n",
        "                start_char = orig_start + (ent_start - orig_start)\n",
        "                break\n",
        "        if start_char is None:\n",
        "            start_char = ent_start\n",
        "        end_char = None\n",
        "        for orig_start, orig_end in noun_positions:\n",
        "            if orig_start < ent_end <= orig_end:\n",
        "                end_char = orig_start + (ent_end - orig_start)\n",
        "                break\n",
        "        if end_char is None:\n",
        "            end_char = ent_end\n",
        "\n",
        "        mapped_ents.append({\n",
        "            'text': ent['text'],\n",
        "            'start': start_char + chunk_offset,\n",
        "            'end': end_char + chunk_offset,\n",
        "            'label': ent['label']\n",
        "        })\n",
        "    return mapped_ents\n",
        "\n",
        "@time_it\n",
        "def extract_entities(text):\n",
        "    regex_entities = []\n",
        "    for label, pattern in patterns.items():\n",
        "        for match in re.finditer(pattern, text):\n",
        "            regex_entities.append({\n",
        "                'text': match.group(),\n",
        "                'start': match.start(),\n",
        "                'end': match.end(),\n",
        "                'label': label\n",
        "            })\n",
        "\n",
        "    noun_text, noun_positions = keep_nouns_with_positions(text)\n",
        "\n",
        "    with open('filtered_nouns_text.txt', 'w', encoding='utf-8') as f:\n",
        "        for token in noun_text.split():\n",
        "            f.write(token + '\\n')\n",
        "\n",
        "    chunks = chunk_text(noun_text, max_len=600, overlap=20)\n",
        "\n",
        "    gliner_entities = []\n",
        "    for i, (chunk, offset) in enumerate(chunks):\n",
        "        ents = model.predict_entities(chunk, gliner_labels, flat_ner=True, threshold=0.5)\n",
        "        print(f\"✅ Processed chunk {i+1}/{len(chunks)} with {len(ents)} entities\")\n",
        "        mapped = map_positions(ents, noun_positions, offset)\n",
        "        gliner_entities.extend(mapped)\n",
        "\n",
        "    all_entities = regex_entities + gliner_entities\n",
        "    all_entities.sort(key=lambda x: x['start'])\n",
        "\n",
        "    return all_entities\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start_total = time.time()\n",
        "    entities = extract_entities(string)\n",
        "    end_total = time.time()\n",
        "\n",
        "    print(f\"\\n🕒 SpaCy loading time: {end_spacy - start_spacy:.2f} seconds\")\n",
        "    print(f\"🕒 GLiNER loading time: {end_gliner - start_gliner:.2f} seconds\")\n",
        "\n",
        "    with open('extracted_entities.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump({'entities': entities}, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "    for ent in entities:\n",
        "        print(f\"🔹 {ent['label'].upper()}: '{ent['text']}' [{ent['start']}:{ent['end']}]\")\n",
        "\n",
        "    print(f\"🕒 Total processing time: {end_total - start_total:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "58ad7894b16f49b585519be272b7c2b4",
            "8a75d11db93744f18a55fe2f7445191f",
            "8af10283d4ca4563a40db9d9a28d9f7e",
            "dab8b64a9d83424eac0255f4589aa27e",
            "c2176dfaa036460790eba45f47cce6c3",
            "a9f60fb7c3304659a11faa15ae6a4f04",
            "6b570a3fe3d44c27ba08143afd626850",
            "148c3d7ac068472fba72f69590189cde",
            "2f0bc96ce5694abf9f790df97589a6ce",
            "0abae6ce4e6d4ca4ab9b9b351d0f4e14",
            "b0f86ed35f5f458e8c6689430d55e1ba"
          ]
        },
        "id": "Z9Ivm4Jw28eW",
        "outputId": "1e94aa38-99f6-4fc4-f43f-fe11930bde1a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58ad7894b16f49b585519be272b7c2b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ keep_nouns_with_positions took 3.19 seconds\n",
            "⏱️ chunk_text took 0.00 seconds\n",
            "✅ Processed chunk 1/19 with 2 entities\n",
            "✅ Processed chunk 2/19 with 4 entities\n",
            "✅ Processed chunk 3/19 with 0 entities\n",
            "✅ Processed chunk 4/19 with 6 entities\n",
            "✅ Processed chunk 5/19 with 7 entities\n",
            "✅ Processed chunk 6/19 with 8 entities\n",
            "✅ Processed chunk 7/19 with 4 entities\n",
            "✅ Processed chunk 8/19 with 3 entities\n",
            "✅ Processed chunk 9/19 with 0 entities\n",
            "✅ Processed chunk 10/19 with 4 entities\n",
            "✅ Processed chunk 11/19 with 5 entities\n",
            "✅ Processed chunk 12/19 with 1 entities\n",
            "✅ Processed chunk 13/19 with 12 entities\n",
            "✅ Processed chunk 14/19 with 9 entities\n",
            "✅ Processed chunk 15/19 with 25 entities\n",
            "✅ Processed chunk 16/19 with 15 entities\n",
            "✅ Processed chunk 17/19 with 15 entities\n",
            "✅ Processed chunk 18/19 with 7 entities\n",
            "✅ Processed chunk 19/19 with 0 entities\n",
            "⏱️ extract_entities took 19.19 seconds\n",
            "\n",
            "🕒 SpaCy loading time: 1.61 seconds\n",
            "🕒 GLiNER loading time: 8.81 seconds\n",
            "🔹 ORGANIZATION: 'Salesforce.com' [252:266]\n",
            "🔹 ORGANIZATION: 'Salesforce.com' [371:385]\n",
            "🔹 ORGANIZATION: 'Salesforce' [599:609]\n",
            "🔹 ID: 'Lead II' [644:651]\n",
            "🔹 LOCATION: 'Telecom' [733:740]\n",
            "🔹 ORGANIZATION: 'Google' [910:916]\n",
            "🔹 ORGANIZATION: 'AWS' [1895:1898]\n",
            "🔹 ORGANIZATION: 'AWS' [1905:1908]\n",
            "🔹 ORGANIZATION: 'AWS' [2012:2015]\n",
            "🔹 ORGANIZATION: 'AWS' [2032:2035]\n",
            "🔹 PERSON: 'Product Owner' [2209:2222]\n",
            "🔹 ORGANIZATION: 'IT' [2300:2302]\n",
            "🔹 PERSON: 'Manager' [2321:2328]\n",
            "🔹 ORGANIZATION: 'Appium' [2458:2464]\n",
            "🔹 ORGANIZATION: 'Appium' [2521:2527]\n",
            "🔹 ORGANIZATION: 'Appium' [2650:2656]\n",
            "🔹 ORGANIZATION: 'Appium' [2814:2820]\n",
            "🔹 ORGANIZATION: 'Appium' [2872:2878]\n",
            "🔹 ORGANIZATION: 'Appium' [2908:2914]\n",
            "🔹 ORGANIZATION: 'AWS' [3226:3229]\n",
            "🔹 ORGANIZATION: 'AWS' [3287:3290]\n",
            "🔹 ORGANIZATION: 'Microsoft' [3310:3319]\n",
            "🔹 PERSON: 'CISSP' [3406:3411]\n",
            "🔹 ORGANIZATION: 'AWS' [3412:3415]\n",
            "🔹 LOCATION: 'Azure GCP' [3416:3425]\n",
            "🔹 ORGANIZATION: 'AWS' [3426:3429]\n",
            "🔹 ORGANIZATION: 'Azure Security Center' [3437:3458]\n",
            "🔹 PERSON: 'Sr Cloud Security Engineer' [3524:3550]\n",
            "🔹 ORGANIZATION: 'CNAPP' [3579:3584]\n",
            "🔹 ORGANIZATION: 'CSP' [3626:3629]\n",
            "🔹 ORGANIZATION: 'Product Platforms' [3862:3879]\n",
            "🔹 ID: 'nology' [4060:4066]\n",
            "🔹 ID: 'IP' [4424:4426]\n",
            "🔹 ID: 'Kn' [4658:4660]\n",
            "🔹 PERSON: 'Application Architect' [5333:5354]\n",
            "🔹 ORGANIZATION: 'DevOps' [5435:5441]\n",
            "🔹 ID: 'Number' [5624:5630]\n",
            "🔹 ID: 'Number' [5631:5637]\n",
            "🔹 ORGANIZATION: 'AWS' [6082:6085]\n",
            "🔹 ORGANIZATION: 'AWS' [6092:6095]\n",
            "🔹 ORGANIZATION: 'AWS' [6199:6202]\n",
            "🔹 ORGANIZATION: 'AWS' [6219:6222]\n",
            "🔹 PERSON: 'Technical Product Owner' [6305:6328]\n",
            "🔹 LOCATION: 'Lancaster PA' [6656:6668]\n",
            "🔹 PERSON: 'David Fraley' [6982:6994]\n",
            "🔹 ORGANIZATION: 'Oracle' [7012:7018]\n",
            "🔹 ORGANIZATION: 'BizzDesign' [7038:7048]\n",
            "🔹 LOCATION: 'Atlanta' [7166:7173]\n",
            "🔹 ORGANIZATION: 'Hashicorp' [7330:7339]\n",
            "🔹 PERSON: 'Mona Sitlani' [7346:7358]\n",
            "🔹 ID: 'UID' [7359:7362]\n",
            "🔹 PERSON: 'Sundar Munusuri' [7366:7381]\n",
            "🔹 LOCATION: 'PA' [7436:7438]\n",
            "🔹 LOCATION: 'Pittsburgh PA' [7450:7463]\n",
            "🔹 ORGANIZATION: 'Oracle' [7522:7528]\n",
            "🔹 ORGANIZATION: 'Power Bi Dat' [7548:7560]\n",
            "🔹 ORGANIZATION: 'AWS CLOUD Security Data Analysis AWS' [7764:7800]\n",
            "🔹 PERSON: 'Naveen' [7991:7997]\n",
            "🔹 PERSON: 'Vinesh' [8021:8027]\n",
            "🔹 PERSON: 'Sasmitha Das' [8038:8050]\n",
            "🔹 PERSON: 'Nishant' [8063:8070]\n",
            "🔹 PERSON: 'Vijay' [8077:8082]\n",
            "🔹 PERSON: 'Beeline' [8084:8091]\n",
            "🔹 PERSON: 'Poorna Chandra' [8124:8138]\n",
            "🔹 PERSON: 'Poorna Chandra' [8124:8138]\n",
            "🔹 PERSON: 'J' [8139:8140]\n",
            "🔹 PERSON: 'Jyothsih' [8139:8147]\n",
            "🔹 ORGANIZATION: 'TMO Deb/ Beeline' [8187:8203]\n",
            "🔹 PERSON: 'Sravan Kumar' [8245:8257]\n",
            "🔹 PERSON: 'Teja Sai Ganta' [8299:8313]\n",
            "🔹 ORGANIZATION: 'TMO Deb/ Beeline' [8314:8330]\n",
            "🔹 PERSON: 'Kiran Krishnan' [8331:8345]\n",
            "🔹 LOCATION: 'Frisco' [8363:8369]\n",
            "🔹 LOCATION: 'Remote' [8371:8377]\n",
            "🔹 PERSON: 'Punna Rao' [8378:8387]\n",
            "🔹 ORGANIZATION: 'Beeline' [8417:8424]\n",
            "🔹 PERSON: 'Vijay' [8426:8431]\n",
            "🔹 PERSON: 'Sathya Nagaraj' [8432:8446]\n",
            "🔹 PERSON: 'Roman L3 Sujith' [8454:8469]\n",
            "🔹 PERSON: 'Vignana Raja' [8476:8488]\n",
            "🔹 PERSON: 'Ajay Pasunoor' [8489:8502]\n",
            "🔹 PERSON: 'Sathya Nagaraj' [8519:8533]\n",
            "🔹 ORGANIZATION: 'Beeline' [8610:8617]\n",
            "🔹 PERSON: 'Raja Sagar' [8622:8632]\n",
            "🔹 PERSON: 'Kiran Dennis' [8647:8659]\n",
            "🔹 ORGANIZATION: 'CI FB' [8660:8665]\n",
            "🔹 PERSON: 'Russ Sujith' [8666:8677]\n",
            "🔹 ID: '4/7' [8678:8681]\n",
            "🔹 PERSON: 'Pradeep Murthy' [8682:8696]\n",
            "🔹 ORGANIZATION: 'Anthony Inter' [8707:8720]\n",
            "🔹 PERSON: 'Anthony' [8707:8714]\n",
            "🔹 PERSON: 'Sujith' [8725:8731]\n",
            "🔹 PERSON: 'Sheetal' [8732:8739]\n",
            "🔹 PERSON: 'Sujith' [8755:8761]\n",
            "🔹 PERSON: 'Jessica' [8786:8793]\n",
            "🔹 ID: 'L1' [8850:8852]\n",
            "🔹 PERSON: 'Kaveripakkam' [8947:8959]\n",
            "🔹 PERSON: 'Arunagiri OIP Tentative DOJ Vijay/ Beeline SO Bill Rate Mosfaqus Salehin' [8960:9032]\n",
            "🔹 ORGANIZATION: 'DOJ' [9049:9052]\n",
            "🔹 PERSON: 'Susai Chandran' [9099:9113]\n",
            "🔹 PERSON: 'Ashish' [9114:9120]\n",
            "🔹 ORGANIZATION: 'HM' [9124:9126]\n",
            "🔹 PERSON: 'Ramchand Tripuraneni' [9220:9240]\n",
            "🔹 PERSON: 'Ramkrishna Ramchand' [9256:9275]\n",
            "🔹 PERSON: 'Saju Sujith' [9279:9290]\n",
            "🔹 PERSON: 'aju Sujith' [9280:9290]\n",
            "🔹 PERSON: 'Saju' [9361:9365]\n",
            "🔹 PERSON: 'Vijay' [9371:9376]\n",
            "🔹 PERSON: 'Beeline Frisco Harivijayan' [9378:9404]\n",
            "🔹 PERSON: 'Abin Mathew' [9434:9445]\n",
            "🔹 PERSON: 'Dennis Kim' [9465:9475]\n",
            "🔹 ID: '285154' [9476:9482]\n",
            "🔹 PERSON: 'Mona Sitlani' [9507:9519]\n",
            "🔹 PERSON: 'Saju' [9534:9538]\n",
            "🔹 PERSON: 'Mona Sitlani' [9576:9588]\n",
            "🔹 ORGANIZATION: 'DOJ' [9601:9604]\n",
            "🔹 ID: 'New Passport' [9633:9645]\n",
            "🔹 PERSON: 'Raguram Veeraparakaramapandian' [9772:9802]\n",
            "🔹 ORGANIZATION: 'DOJ' [9813:9816]\n",
            "🔹 LOCATION: 'CA' [9860:9862]\n",
            "🔹 ORGANIZATION: 'LCA Com' [9873:9880]\n",
            "🔹 ORGANIZATION: 'LCA' [9873:9876]\n",
            "🔹 PERSON: 'Venkat' [9918:9924]\n",
            "🔹 ORGANIZATION: 'DOJ' [9978:9981]\n",
            "🔹 PERSON: 'Raguram Veeraparakaramapandian' [10010:10040]\n",
            "🔹 PERSON: 'Glider' [10091:10097]\n",
            "🔹 PERSON: 'Sowmyasree AISHA QADEER' [10143:10166]\n",
            "🕒 Total processing time: 19.19 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering out person name (Removing the false +ve from GLiNER O/P)\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import spacy\n",
        "from gliner import GLiNER\n",
        "from transformers import pipeline\n",
        "\n",
        "start_spacy = time.time()\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "end_spacy = time.time()\n",
        "\n",
        "start_gliner = time.time()\n",
        "model = GLiNER.from_pretrained(\"gliner-community/gliner_small-v2.5\")\n",
        "end_gliner = time.time()\n",
        "\n",
        "start_zero_shot = time.time()\n",
        "zero_shot = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "zero_shot_labels = [\"person name\", \"job title\"]\n",
        "end_zero_shot = time.time()\n",
        "\n",
        "classifier_cache = {}\n",
        "\n",
        "patterns = {\n",
        "    'email': r'\\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\\b',\n",
        "    'phone': r'\\b(?:\\+?\\d{1,3}[-.\\s]?)?(?:\\(?\\d{2,4}\\)?[-.\\s]?)?\\d{3,4}[-.\\s]?\\d{4}\\b',\n",
        "    'id': r'\\b[A-Z]{5}[0-9]{4}[A-Z]\\b'\n",
        "}\n",
        "\n",
        "gliner_labels = [\"Person\", \"Organization\", \"Location\", \"ID\"]\n",
        "\n",
        "def time_it(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        print(f'⏱️ {func.__name__} took {time.time() - start:.2f} seconds')\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "@time_it\n",
        "def keep_nouns_with_positions(text):\n",
        "    doc = nlp(text)\n",
        "    noun_tokens = []\n",
        "    original_positions = []\n",
        "    for token in doc:\n",
        "        if token.pos_ == 'PROPN':\n",
        "            noun_tokens.append(token.text)\n",
        "            original_positions.append((token.idx, token.idx + len(token.text)))\n",
        "    noun_text = ' '.join(noun_tokens)\n",
        "    return noun_text, original_positions\n",
        "\n",
        "@time_it\n",
        "def chunk_text(text, max_len=512, overlap=48):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = min(start + max_len, len(text))\n",
        "        chunks.append((text[start:end], start))\n",
        "        if end == len(text):\n",
        "            break\n",
        "        start = end - overlap\n",
        "    return chunks\n",
        "\n",
        "def map_positions(ents, noun_positions, chunk_offset):\n",
        "    mapped_ents = []\n",
        "    for ent in ents:\n",
        "        ent_start = ent['start']\n",
        "        ent_end = ent['end']\n",
        "        start_char = None\n",
        "        for orig_start, orig_end in noun_positions:\n",
        "            if orig_start <= ent_start < orig_end:\n",
        "                start_char = orig_start + (ent_start - orig_start)\n",
        "                break\n",
        "        if start_char is None:\n",
        "            start_char = ent_start\n",
        "\n",
        "        end_char = None\n",
        "        for orig_start, orig_end in noun_positions:\n",
        "            if orig_start < ent_end <= orig_end:\n",
        "                end_char = orig_start + (ent_end - orig_start)\n",
        "                break\n",
        "        if end_char is None:\n",
        "            end_char = ent_end\n",
        "\n",
        "        mapped_ents.append({\n",
        "            'text': ent['text'],\n",
        "            'start': start_char + chunk_offset,\n",
        "            'end': end_char + chunk_offset,\n",
        "            'label': ent['label']\n",
        "        })\n",
        "    return mapped_ents\n",
        "\n",
        "def classify_with_cache(text):\n",
        "    if text in classifier_cache:\n",
        "        return classifier_cache[text]\n",
        "    result = zero_shot(text, candidate_labels=zero_shot_labels)\n",
        "    top_label = result[\"labels\"][0]\n",
        "    classifier_cache[text] = top_label\n",
        "    return top_label\n",
        "\n",
        "def filter_person_entities_with_classifier(entities):\n",
        "    filtered = []\n",
        "    for ent in entities:\n",
        "        if ent[\"label\"] != \"Person\":\n",
        "            filtered.append(ent)\n",
        "        else:\n",
        "            top_label = classify_with_cache(ent[\"text\"])\n",
        "            if top_label == \"person name\":\n",
        "                filtered.append(ent)\n",
        "            else:\n",
        "                print(f\"❌ Rejected as job title: {ent['text']}\")\n",
        "    return filtered\n",
        "\n",
        "@time_it\n",
        "def extract_entities(text):\n",
        "    regex_entities = []\n",
        "    for label, pattern in patterns.items():\n",
        "        for match in re.finditer(pattern, text):\n",
        "            regex_entities.append({\n",
        "                'text': match.group(),\n",
        "                'start': match.start(),\n",
        "                'end': match.end(),\n",
        "                'label': label\n",
        "            })\n",
        "\n",
        "    noun_text, noun_positions = keep_nouns_with_positions(text)\n",
        "    chunks = chunk_text(noun_text, max_len=512, overlap=12)\n",
        "\n",
        "    gliner_entities = []\n",
        "    for i, (chunk, offset) in enumerate(chunks):\n",
        "        ents = model.predict_entities(chunk, gliner_labels, flat_ner=True, threshold=0.25)\n",
        "        print(f\"✅ Processed chunk {i+1}/{len(chunks)} with {len(ents)} entities\")\n",
        "        mapped = map_positions(ents, noun_positions, offset)\n",
        "        gliner_entities.extend(mapped)\n",
        "\n",
        "    gliner_entities = filter_person_entities_with_classifier(gliner_entities)\n",
        "\n",
        "    all_entities = regex_entities + gliner_entities\n",
        "    all_entities.sort(key=lambda x: x['start'])\n",
        "\n",
        "    return all_entities\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start_total = time.time()\n",
        "    entities = extract_entities(string)\n",
        "    end_total = time.time()\n",
        "\n",
        "    print(f\"\\n🕒 SpaCy loading time: {end_spacy - start_spacy:.2f} seconds\")\n",
        "    print(f\"🕒 GLiNER loading time: {end_gliner - start_gliner:.2f} seconds\")\n",
        "    print(f\"🕒 Zero Shot Classifier loading time: {end_zero_shot - start_zero_shot:.2f} seconds\")\n",
        "\n",
        "    with open('filtered_entity_mapping.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump({'entities': entities}, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "    for ent in entities:\n",
        "        print(f\"🔹 {ent['label'].upper()}: '{ent['text']}' [{ent['start']}:{ent['end']}]\")\n",
        "\n",
        "    print(f\"🕒 Total processing time: {end_total - start_total:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "QTHzJHJ4gExn",
        "outputId": "cd0b752a-b6f3-432a-bd7a-2692b6f3bfd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0700a95c5a9843df80ef33c1dd94e30f",
            "4861665f9b484d5ca4af358b4bc64332",
            "9ea7491244844d829529a2ede96f2fb8",
            "c35dc5f23cb04ef0a46bb96f986d4164",
            "c6620db6e64a4542a93c558c4fcb2e38",
            "f9882e8e6da542edba9045f9798251da",
            "ce8d51a24e174c4bb695964c6be0563f",
            "4489815bb5c44258bc9463072365dc6f",
            "7a8bff8efa5a4b28831c1a76604e35d2",
            "c4644a20048f404495eb47795f4f12fa",
            "019095bbb84f4cb9be460d3ab2da1d8a"
          ]
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0700a95c5a9843df80ef33c1dd94e30f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ keep_nouns_with_positions took 1.99 seconds\n",
            "⏱️ chunk_text took 0.00 seconds\n",
            "✅ Processed chunk 1/22 with 9 entities\n",
            "✅ Processed chunk 2/22 with 9 entities\n",
            "✅ Processed chunk 3/22 with 5 entities\n",
            "✅ Processed chunk 4/22 with 13 entities\n",
            "✅ Processed chunk 5/22 with 10 entities\n",
            "✅ Processed chunk 6/22 with 9 entities\n",
            "✅ Processed chunk 7/22 with 15 entities\n",
            "✅ Processed chunk 8/22 with 9 entities\n",
            "✅ Processed chunk 9/22 with 6 entities\n",
            "✅ Processed chunk 10/22 with 4 entities\n",
            "✅ Processed chunk 11/22 with 9 entities\n",
            "✅ Processed chunk 12/22 with 5 entities\n",
            "✅ Processed chunk 13/22 with 11 entities\n",
            "✅ Processed chunk 14/22 with 2 entities\n",
            "✅ Processed chunk 15/22 with 18 entities\n",
            "✅ Processed chunk 16/22 with 7 entities\n",
            "✅ Processed chunk 17/22 with 31 entities\n",
            "✅ Processed chunk 18/22 with 31 entities\n",
            "✅ Processed chunk 19/22 with 32 entities\n",
            "✅ Processed chunk 20/22 with 18 entities\n",
            "✅ Processed chunk 21/22 with 9 entities\n",
            "✅ Processed chunk 22/22 with 1 entities\n",
            "❌ Rejected as job title: Cybersecurity\n",
            "❌ Rejected as job title: Technical Data Analyst\n",
            "❌ Rejected as job title: Product Managers\n",
            "❌ Rejected as job title: IT Data Analyst\n",
            "❌ Rejected as job title: Data Scientist\n",
            "❌ Rejected as job title: Sr Cloud Network Engineer\n",
            "❌ Rejected as job title: Project Manager\n",
            "❌ Rejected as job title: Product Owner\n",
            "❌ Rejected as job title: Project Manager\n",
            "❌ Rejected as job title: Senior Software Development Engineer\n",
            "❌ Rejected as job title: Product Manager\n",
            "❌ Rejected as job title: CISSP\n",
            "❌ Rejected as job title: Sr Cloud Security Engineer\n",
            "❌ Rejected as job title: Managers\n",
            "❌ Rejected as job title: Product Managers\n",
            "❌ Rejected as job title: Senior Product Managers\n",
            "❌ Rejected as job title: Senior Product Managers\n",
            "❌ Rejected as job title: Support Architect\n",
            "❌ Rejected as job title: Sr . Architect\n",
            "❌ Rejected as job title: Application Architect\n",
            "❌ Rejected as job title: Contractor\n",
            "❌ Rejected as job title: Sr Cloud Network Engineer\n",
            "❌ Rejected as job title: Technical Product Owner\n",
            "❌ Rejected as job title: CWR\n",
            "❌ Rejected as job title: Glider\n",
            "⏱️ extract_entities took 108.61 seconds\n",
            "\n",
            "🕒 SpaCy loading time: 0.67 seconds\n",
            "🕒 GLiNER loading time: 7.62 seconds\n",
            "🕒 Zero Shot Classifier loading time: 1.81 seconds\n",
            "🔹 ORGANIZATION: 'BizzDesign' [131:141]\n",
            "🔹 ORGANIZATION: 'Salesforce.com' [252:266]\n",
            "🔹 ORGANIZATION: 'Sales Finance' [276:289]\n",
            "🔹 ID: 'DBX' [330:333]\n",
            "🔹 ORGANIZATION: 'Salesforce.com' [371:385]\n",
            "🔹 ID: 'Hyper' [507:512]\n",
            "🔹 ORGANIZATION: 'PdM' [518:521]\n",
            "🔹 ORGANIZATION: 'MS Dynamics' [587:598]\n",
            "🔹 ORGANIZATION: 'Salesforce' [599:609]\n",
            "🔹 ID: 'Lead II' [644:651]\n",
            "🔹 LOCATION: 'Telecom' [733:740]\n",
            "🔹 ID: 'AL' [865:867]\n",
            "🔹 ORGANIZATION: 'Google' [910:916]\n",
            "🔹 ID: 'ration' [1000:1006]\n",
            "🔹 LOCATION: 'Cloud Platforms' [1267:1282]\n",
            "🔹 ORGANIZATION: 'CircleCI' [1341:1349]\n",
            "🔹 LOCATION: 'Cloud Native' [1484:1496]\n",
            "🔹 ID: 'ernetes' [1500:1507]\n",
            "🔹 ORGANIZATION: 'Queu' [1508:1512]\n",
            "🔹 ORGANIZATION: 'AWS' [1521:1524]\n",
            "🔹 LOCATION: 'GCP' [1661:1664]\n",
            "🔹 PERSON: 'Pulumi' [1675:1681]\n",
            "🔹 LOCATION: 'Azure' [1804:1809]\n",
            "🔹 LOCATION: 'GCPExperience' [1810:1823]\n",
            "🔹 ID: 'Key' [1856:1859]\n",
            "🔹 ORGANIZATION: 'AWS' [1895:1898]\n",
            "🔹 LOCATION: 'Azure' [1899:1904]\n",
            "🔹 ORGANIZATION: 'AWS' [1905:1908]\n",
            "🔹 LOCATION: 'Azure' [1924:1929]\n",
            "🔹 LOCATION: 'VPN' [1930:1933]\n",
            "🔹 ORGANIZATION: 'CI' [2007:2009]\n",
            "🔹 ORGANIZATION: 'AWS Azure' [2012:2021]\n",
            "🔹 ORGANIZATION: 'AWS Azure' [2032:2041]\n",
            "🔹 ORGANIZATION: 'IT' [2300:2302]\n",
            "🔹 ID: 'Appium Java' [2458:2469]\n",
            "🔹 ID: 'Android' [2470:2477]\n",
            "🔹 ID: 't' [2500:2501]\n",
            "🔹 ORGANIZATION: 'Appium' [2521:2527]\n",
            "🔹 LOCATION: 'Android' [2642:2649]\n",
            "🔹 ORGANIZATION: 'Appium' [2650:2656]\n",
            "🔹 ORGANIZATION: 'Appium' [2814:2820]\n",
            "🔹 ORGANIZATION: 'Appium' [2872:2878]\n",
            "🔹 ORGANIZATION: 'Appium' [2908:2914]\n",
            "🔹 ORGANIZATION: 'Appium' [2925:2931]\n",
            "🔹 ID: 'sting' [3000:3005]\n",
            "🔹 PERSON: 'Androi' [3006:3012]\n",
            "🔹 LOCATION: 'Cloud' [3201:3206]\n",
            "🔹 ORGANIZATION: 'AWS' [3226:3229]\n",
            "🔹 LOCATION: 'Azure GCP' [3230:3239]\n",
            "🔹 ORGANIZATION: 'NIST' [3240:3244]\n",
            "🔹 ORGANIZATION: 'AWS' [3287:3290]\n",
            "🔹 ORGANIZATION: 'Microsoft' [3310:3319]\n",
            "🔹 LOCATION: 'Azure' [3330:3335]\n",
            "🔹 ORGANIZATION: 'AWS' [3412:3415]\n",
            "🔹 LOCATION: 'Azure GCP' [3416:3425]\n",
            "🔹 LOCATION: 'AWS Shield' [3426:3436]\n",
            "🔹 ORGANIZATION: 'Azure Security Center' [3437:3458]\n",
            "🔹 ORGANIZATION: 'NIST' [3472:3476]\n",
            "🔹 ORGANIZATION: 'CNAPP' [3579:3584]\n",
            "🔹 ORGANIZATION: 'CSP' [3626:3629]\n",
            "🔹 ORGANIZATION: 'AWS' [3630:3633]\n",
            "🔹 ORGANIZATION: 'GCP' [3669:3672]\n",
            "🔹 ORGANIZATION: 'Hashicorp' [3752:3761]\n",
            "🔹 ORGANIZATION: 'Product Platforms' [3862:3879]\n",
            "🔹 ORGANIZATION: 'Division' [3880:3888]\n",
            "🔹 ORGANIZATION: 'Pro' [4009:4012]\n",
            "🔹 ORGANIZATION: 'Product' [4009:4016]\n",
            "🔹 ID: 'GTM IP' [4420:4426]\n",
            "🔹 ID: 'ploy' [4500:4504]\n",
            "🔹 ID: 'livery' [5000:5006]\n",
            "🔹 ID: 'UST T' [5007:5012]\n",
            "🔹 ORGANIZATION: 'UST' [5007:5010]\n",
            "🔹 ORGANIZATION: 'Project Team' [5044:5056]\n",
            "🔹 ORGANIZATION: 'DevOps' [5186:5192]\n",
            "🔹 ID: 'NA' [5486:5488]\n",
            "🔹 ID: 'NA' [5504:5506]\n",
            "🔹 ID: 'NA' [5504:5506]\n",
            "🔹 PERSON: 'Knowl' [5507:5512]\n",
            "🔹 ID: 'Number' [5624:5630]\n",
            "🔹 ID: 'Number' [5631:5637]\n",
            "🔹 ORGANIZATION: 'Team' [5892:5896]\n",
            "🔹 ORGANIZATION: 'Team' [5975:5979]\n",
            "🔹 ID: 'owledge' [6000:6007]\n",
            "🔹 ID: 'Key' [6043:6046]\n",
            "🔹 ORGANIZATION: 'AWS' [6082:6085]\n",
            "🔹 ORGANIZATION: 'AWS' [6092:6095]\n",
            "🔹 ORGANIZATION: 'Azure' [6111:6116]\n",
            "🔹 ORGANIZATION: 'AWS' [6199:6202]\n",
            "🔹 ORGANIZATION: 'AWS' [6219:6222]\n",
            "🔹 ORGANIZATION: 'Azure' [6223:6228]\n",
            "🔹 ID: 'G' [6511:6512]\n",
            "🔹 LOCATION: 'Lancaster PA' [6656:6668]\n",
            "🔹 PERSON: 'David Fraley' [6982:6994]\n",
            "🔹 ORGANIZATION: 'Oracle' [7012:7018]\n",
            "🔹 ORGANIZATION: 'BizzDesign' [7038:7048]\n",
            "🔹 ORGANIZATION: 'Power BI' [7071:7079]\n",
            "🔹 ORGANIZATION: 'Springboot' [7126:7136]\n",
            "🔹 LOCATION: 'Atlanta' [7166:7173]\n",
            "🔹 LOCATION: 'NA' [7180:7182]\n",
            "🔹 ORGANIZATION: 'Appium' [7213:7219]\n",
            "🔹 PERSON: 'Mosfaqus Salehin' [7225:7241]\n",
            "🔹 ORGANIZATION: 'Mandatory Security Platform CNAPP solutionCross SkillsKnowledge Zero Trust Design Vault' [7242:7329]\n",
            "🔹 ORGANIZATION: 'Hashicorp' [7330:7339]\n",
            "🔹 PERSON: 'Mona Sitlani' [7346:7358]\n",
            "🔹 ID: 'UID' [7359:7362]\n",
            "🔹 PERSON: 'Sundar Munusuri' [7366:7381]\n",
            "🔹 PERSON: 'Veeraparakaramapandian' [7386:7408]\n",
            "🔹 LOCATION: 'NA' [7409:7411]\n",
            "🔹 LOCATION: 'PA' [7436:7438]\n",
            "🔹 LOCATION: 'Pittsburgh PA' [7450:7463]\n",
            "🔹 PERSON: 'F' [7511:7512]\n",
            "🔹 ORGANIZATION: 'Oracle' [7522:7528]\n",
            "🔹 ORGANIZATION: 'Power Bi Databricks' [7548:7567]\n",
            "🔹 LOCATION: 'TELECOM' [7609:7616]\n",
            "🔹 ORGANIZATION: 'Aws Services' [7628:7640]\n",
            "🔹 ORGANIZATION: 'AWS CLOUD Security Data Analysis AWS' [7764:7800]\n",
            "🔹 PERSON: 'David Fraley' [7978:7990]\n",
            "🔹 PERSON: 'Naveen' [7991:7997]\n",
            "🔹 PERSON: 'Vinesh' [8021:8027]\n",
            "🔹 ORGANIZATION: 'RH ADOBE' [8029:8037]\n",
            "🔹 PERSON: 'Sasmitha Das' [8038:8050]\n",
            "🔹 PERSON: 'Amarnath Nishant' [8054:8070]\n",
            "🔹 PERSON: 'Vijay' [8077:8082]\n",
            "🔹 ORGANIZATION: 'Beeline' [8084:8091]\n",
            "🔹 ORGANIZATION: 'COMCAST' [8092:8099]\n",
            "🔹 PERSON: 'Poorna Chandra' [8124:8138]\n",
            "🔹 PERSON: 'Jyothsih' [8139:8147]\n",
            "🔹 ID: 'Glider' [8148:8154]\n",
            "🔹 ORGANIZATION: 'TMO Deb/ Beeline' [8187:8203]\n",
            "🔹 PERSON: 'Keerthi' [8204:8211]\n",
            "🔹 PERSON: 'Durga Maruthi' [8219:8232]\n",
            "🔹 ID: 'Srujan' [8233:8239]\n",
            "🔹 ID: 'Sama' [8240:8244]\n",
            "🔹 PERSON: 'Sravan Kumar' [8245:8257]\n",
            "🔹 PERSON: 'Ayyagari' [8258:8266]\n",
            "🔹 ID: 'Vitakula' [8278:8286]\n",
            "🔹 PERSON: 'Teja Sai Ganta' [8299:8313]\n",
            "🔹 ORGANIZATION: 'TMO Deb/ Beeline' [8314:8330]\n",
            "🔹 PERSON: 'Kiran Krishnan' [8331:8345]\n",
            "🔹 LOCATION: 'Frisco' [8363:8369]\n",
            "🔹 LOCATION: 'Remote' [8371:8377]\n",
            "🔹 PERSON: 'Punna Rao' [8378:8387]\n",
            "🔹 ID: 'Donald' [8388:8394]\n",
            "🔹 PERSON: 'Bujail/ Sujith' [8396:8410]\n",
            "🔹 ORGANIZATION: 'Beeline' [8417:8424]\n",
            "🔹 PERSON: 'Vijay Sathya Nagaraj' [8426:8446]\n",
            "🔹 PERSON: 'Roman L3 Sujith' [8454:8469]\n",
            "🔹 PERSON: 'Vignana Raja' [8476:8488]\n",
            "🔹 PERSON: 'Ajay Pasunoor' [8489:8502]\n",
            "🔹 PERSON: 'Sathya Nagaraj' [8519:8533]\n",
            "🔹 ID: 'L3' [8534:8536]\n",
            "🔹 ID: 'sujith' [8537:8543]\n",
            "🔹 PERSON: 'Pradeep Dasari' [8544:8558]\n",
            "🔹 ID: 'Raja Glider' [8559:8570]\n",
            "🔹 ORGANIZATION: 'TMO' [8571:8574]\n",
            "🔹 ORGANIZATION: 'Vijay/ Beeline' [8603:8617]\n",
            "🔹 ORGANIZATION: 'CWR' [8618:8621]\n",
            "🔹 PERSON: 'Raja Sagar' [8622:8632]\n",
            "🔹 PERSON: 'Anthony Kiran Dennis' [8639:8659]\n",
            "🔹 ORGANIZATION: 'CI FB' [8660:8665]\n",
            "🔹 PERSON: 'Russ Sujith 4/7 Pradeep Murthy' [8666:8696]\n",
            "🔹 PERSON: 'Anthony' [8707:8714]\n",
            "🔹 PERSON: 'Sujith' [8725:8731]\n",
            "🔹 PERSON: 'Sheetal' [8732:8739]\n",
            "🔹 PERSON: 'Jessica Zaibi' [8762:8775]\n",
            "🔹 PERSON: 'Jessica' [8786:8793]\n",
            "🔹 ORGANIZATION: 'CI' [8794:8796]\n",
            "🔹 ID: 'L1' [8850:8852]\n",
            "🔹 ORGANIZATION: 'TP' [8860:8862]\n",
            "🔹 ORGANIZATION: 'CMCMST' [8882:8888]\n",
            "🔹 ORGANIZATION: 'Vijay/ Beeline' [8889:8903]\n",
            "🔹 ORGANIZATION: 'TP PMs' [8911:8917]\n",
            "🔹 ORGANIZATION: 'Vijay/ Beeline' [8918:8932]\n",
            "🔹 PERSON: 'Kaveripakkam' [8947:8959]\n",
            "🔹 PERSON: 'Arunagiri' [8960:8969]\n",
            "🔹 ID: 'OIP' [8970:8973]\n",
            "🔹 ORGANIZATION: 'DOJ' [8984:8987]\n",
            "🔹 ORGANIZATION: 'Vijay/ Beeline' [8988:9002]\n",
            "🔹 ID: 'ne' [9000:9002]\n",
            "🔹 ORGANIZATION: 'SO' [9003:9005]\n",
            "🔹 ORGANIZATION: 'SO' [9003:9005]\n",
            "🔹 PERSON: 'Bill R' [9006:9012]\n",
            "🔹 ORGANIZATION: 'Mosfaqus' [9016:9024]\n",
            "🔹 PERSON: 'Salehin' [9025:9032]\n",
            "🔹 ORGANIZATION: 'DOJ' [9049:9052]\n",
            "🔹 PERSON: 'Saju' [9053:9057]\n",
            "🔹 ORGANIZATION: 'SO' [9072:9074]\n",
            "🔹 ORGANIZATION: 'Vijay/ Beeline' [9075:9089]\n",
            "🔹 ORGANIZATION: 'Mosfaqus' [9090:9098]\n",
            "🔹 PERSON: 'Susai Chandran' [9099:9113]\n",
            "🔹 PERSON: 'Ashish' [9114:9120]\n",
            "🔹 ORGANIZATION: 'CI' [9121:9123]\n",
            "🔹 ORGANIZATION: 'HM' [9124:9126]\n",
            "🔹 ORGANIZATION: 'Mosfaqus' [9134:9142]\n",
            "🔹 ORGANIZATION: 'CI' [9143:9145]\n",
            "🔹 PERSON: 'Sriram' [9153:9159]\n",
            "🔹 ORGANIZATION: 'Vijay' [9170:9175]\n",
            "🔹 PERSON: 'Ramchand Tripuraneni' [9220:9240]\n",
            "🔹 PERSON: 'Ramkrishna Ramchand' [9256:9275]\n",
            "🔹 PERSON: 'Saju Sujith' [9279:9290]\n",
            "🔹 ID: 'Slots Glider' [9313:9325]\n",
            "🔹 PERSON: 'Sukesh' [9353:9359]\n",
            "🔹 PERSON: 'Frisco Harivijayan' [9386:9404]\n",
            "🔹 PERSON: 'Sujith' [9417:9423]\n",
            "🔹 PERSON: 'Abin Mathew' [9434:9445]\n",
            "🔹 ID: 'L2' [9446:9448]\n",
            "🔹 PERSON: 'Dennis Kim' [9465:9475]\n",
            "🔹 ID: '285154' [9476:9482]\n",
            "🔹 ID: 'CWR' [9483:9486]\n",
            "🔹 ID: 'FTE' [9487:9490]\n",
            "🔹 ID: 'Arun doc ac' [9495:9506]\n",
            "🔹 ID: 'Mona' [9507:9511]\n",
            "🔹 PERSON: 'Mona Sitlani' [9507:9519]\n",
            "🔹 PERSON: 'Saju' [9534:9538]\n",
            "🔹 PERSON: 'Arun' [9547:9551]\n",
            "🔹 PERSON: 'Mona Sitlani' [9576:9588]\n",
            "🔹 ORGANIZATION: 'DOJ' [9601:9604]\n",
            "🔹 ID: 'New Passport' [9633:9645]\n",
            "🔹 PERSON: 'Arun' [9650:9654]\n",
            "🔹 PERSON: 'Sundar Munusuri' [9735:9750]\n",
            "🔹 PERSON: 'Arun' [9763:9767]\n",
            "🔹 PERSON: 'RH Raguram' [9769:9779]\n",
            "🔹 PERSON: 'Veeraparakaramapandian' [9780:9802]\n",
            "🔹 ORGANIZATION: 'DOJ' [9813:9816]\n",
            "🔹 ID: 'Receipt #' [9831:9840]\n",
            "🔹 PERSON: 'Neha' [9912:9916]\n",
            "🔹 PERSON: 'Venkat' [9918:9924]\n",
            "🔹 ORGANIZATION: 'DOJ' [9978:9981]\n",
            "🔹 PERSON: 'Ra' [10010:10012]\n",
            "🔹 ID: 'Raguram' [10010:10017]\n",
            "🔹 PERSON: 'Veeraparakaramapandian' [10018:10040]\n",
            "🔹 ID: 'DOC' [10057:10060]\n",
            "🔹 PERSON: 'Arun' [10068:10072]\n",
            "🔹 ID: 'TMO' [10098:10101]\n",
            "🔹 PERSON: 'Arun' [10130:10134]\n",
            "🔹 PERSON: 'Sowmyasree AISHA QADEER' [10143:10166]\n",
            "🔹 ID: 'SIDDIQU' [10167:10174]\n",
            "🔹 ID: 'le' [10500:10502]\n",
            "🕒 Total processing time: 108.61 seconds\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b86935e033f45e8821f842319557b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8d712f7fcca450b915c5bd629eaaa78",
              "IPY_MODEL_351a1d4ee69d4a58a21ac446d8c5ea84",
              "IPY_MODEL_5c8624920c644775817727136ca0db6a"
            ],
            "layout": "IPY_MODEL_97b2694d02a6439a8c3b7b1345d061a8"
          }
        },
        "c8d712f7fcca450b915c5bd629eaaa78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db8e85859e1c47a69cada275aed39680",
            "placeholder": "​",
            "style": "IPY_MODEL_8eba7d076b8043eba79d5bb5f553ffd2",
            "value": "Fetching 4 files: 100%"
          }
        },
        "351a1d4ee69d4a58a21ac446d8c5ea84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbed5108ccf04c11b969d071f1aae3f0",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8dd104bc9e54c4caa9169b96bb14a1d",
            "value": 4
          }
        },
        "5c8624920c644775817727136ca0db6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d4be75b6c684b8ca02f19971d69a940",
            "placeholder": "​",
            "style": "IPY_MODEL_8b53f325ddab43c68f96860706b0510a",
            "value": " 4/4 [00:00&lt;00:00, 168.74it/s]"
          }
        },
        "97b2694d02a6439a8c3b7b1345d061a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db8e85859e1c47a69cada275aed39680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eba7d076b8043eba79d5bb5f553ffd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbed5108ccf04c11b969d071f1aae3f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8dd104bc9e54c4caa9169b96bb14a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d4be75b6c684b8ca02f19971d69a940": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b53f325ddab43c68f96860706b0510a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c5714475a1f417aa6cce8b42672d3bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc647359cee94638bc823355289eaa8c",
              "IPY_MODEL_8adec450c04d4f44a0bce1a3b1efa8cb",
              "IPY_MODEL_31ba377d1fa347cba7e7f49927b259b3"
            ],
            "layout": "IPY_MODEL_bc0d52fedfba47288fc58d288fde9d4c"
          }
        },
        "fc647359cee94638bc823355289eaa8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f4ace23a7b24597937aed301f8e934d",
            "placeholder": "​",
            "style": "IPY_MODEL_4d2dfc514e0649dbb716716dbb3ca6f6",
            "value": "Fetching 4 files: 100%"
          }
        },
        "8adec450c04d4f44a0bce1a3b1efa8cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_915ab422976442489c11b5dd800ec28b",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa06cf577e2b45adb239507ace0ec15e",
            "value": 4
          }
        },
        "31ba377d1fa347cba7e7f49927b259b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ead7f86e05d41a7b16666b75880eba2",
            "placeholder": "​",
            "style": "IPY_MODEL_cfb8dd89dd4243d5804b2275fa2484a0",
            "value": " 4/4 [00:00&lt;00:00, 290.52it/s]"
          }
        },
        "bc0d52fedfba47288fc58d288fde9d4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f4ace23a7b24597937aed301f8e934d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d2dfc514e0649dbb716716dbb3ca6f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "915ab422976442489c11b5dd800ec28b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa06cf577e2b45adb239507ace0ec15e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ead7f86e05d41a7b16666b75880eba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfb8dd89dd4243d5804b2275fa2484a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a9c4e7c415642fd879075edf5efcc4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07d4ac7c6f6e4aa4956d5915b44f9315",
              "IPY_MODEL_038dad85288a444f8cc2683388602da4",
              "IPY_MODEL_4a51e5dc9f264b029c826926e9eaa1d6"
            ],
            "layout": "IPY_MODEL_086a164794744099b21a33c4d9dd0a61"
          }
        },
        "07d4ac7c6f6e4aa4956d5915b44f9315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02f23c1704684efb9d8f0a84788341cc",
            "placeholder": "​",
            "style": "IPY_MODEL_9b4e28f9d5c74bc788a62451175c1854",
            "value": "Fetching 5 files: 100%"
          }
        },
        "038dad85288a444f8cc2683388602da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9650a0b658244b45a49a34934075f80f",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f50ecb80884c47faaf3513154873e2ba",
            "value": 5
          }
        },
        "4a51e5dc9f264b029c826926e9eaa1d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_641b3431f72c402f8446b99a64f95d95",
            "placeholder": "​",
            "style": "IPY_MODEL_7ff55eeda5ac41c5899ddc24c7042586",
            "value": " 5/5 [00:00&lt;00:00, 179.45it/s]"
          }
        },
        "086a164794744099b21a33c4d9dd0a61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02f23c1704684efb9d8f0a84788341cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b4e28f9d5c74bc788a62451175c1854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9650a0b658244b45a49a34934075f80f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f50ecb80884c47faaf3513154873e2ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "641b3431f72c402f8446b99a64f95d95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ff55eeda5ac41c5899ddc24c7042586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20533d86030b4ccfb538cefdb3787e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eddc9c32ef0545aaaecfbff03d196dbc",
              "IPY_MODEL_014ccbc715974ad987e316949326d9c7",
              "IPY_MODEL_eb4b35721bd941ed8121f81a87f68219"
            ],
            "layout": "IPY_MODEL_9924900b79ba4ffb82dca4c69198428d"
          }
        },
        "eddc9c32ef0545aaaecfbff03d196dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a4d663f21064321bdc4cdd16e2a6701",
            "placeholder": "​",
            "style": "IPY_MODEL_b9dc732bddcd4df2af8cc53ec71880df",
            "value": "Fetching 10 files: 100%"
          }
        },
        "014ccbc715974ad987e316949326d9c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d55b3c526b054e7e915f8ba072e54342",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1598aef765a14914b8654811a61c49b2",
            "value": 10
          }
        },
        "eb4b35721bd941ed8121f81a87f68219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a8e7b9df80a4dbab7c52638311891b5",
            "placeholder": "​",
            "style": "IPY_MODEL_55eecc50c08d4592bf9020488847d6e8",
            "value": " 10/10 [00:00&lt;00:00, 181.51it/s]"
          }
        },
        "9924900b79ba4ffb82dca4c69198428d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a4d663f21064321bdc4cdd16e2a6701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9dc732bddcd4df2af8cc53ec71880df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d55b3c526b054e7e915f8ba072e54342": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1598aef765a14914b8654811a61c49b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a8e7b9df80a4dbab7c52638311891b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55eecc50c08d4592bf9020488847d6e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "431ddacf7baf4c9aad18c98310c0f126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7801ee466004777b6edb8d95662d8d6",
              "IPY_MODEL_add29d58d15e41eea764ebf248f82087",
              "IPY_MODEL_dd9aa95389a54fb1b746b967b1ad625a"
            ],
            "layout": "IPY_MODEL_718b7baac2414d8296d7c500236b63a1"
          }
        },
        "c7801ee466004777b6edb8d95662d8d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f33710b4a2f94b7f83307d411adee18d",
            "placeholder": "​",
            "style": "IPY_MODEL_9f6e2e44a9e044e49e3cfd8cf246c101",
            "value": "Fetching 10 files: 100%"
          }
        },
        "add29d58d15e41eea764ebf248f82087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00a75900e1d24f259ae80fc997bf13bb",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efea51bb228e4ece94003cb03b89fe2f",
            "value": 10
          }
        },
        "dd9aa95389a54fb1b746b967b1ad625a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b00796c78fa64fc686cdcaeb949f60ae",
            "placeholder": "​",
            "style": "IPY_MODEL_6aaf39d7cda041ddbdda53243fe3868b",
            "value": " 10/10 [00:07&lt;00:00,  1.74s/it]"
          }
        },
        "718b7baac2414d8296d7c500236b63a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f33710b4a2f94b7f83307d411adee18d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f6e2e44a9e044e49e3cfd8cf246c101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00a75900e1d24f259ae80fc997bf13bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efea51bb228e4ece94003cb03b89fe2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b00796c78fa64fc686cdcaeb949f60ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aaf39d7cda041ddbdda53243fe3868b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2451decc84104fc1902423c262b43bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a86bf731f70c4391b537672891dd7d6b",
              "IPY_MODEL_902e355f5205411e94d861353a823214",
              "IPY_MODEL_67852404bbed47198233248f2ad4d753"
            ],
            "layout": "IPY_MODEL_b1d7861a40bc4555b886d3463f0c122e"
          }
        },
        "a86bf731f70c4391b537672891dd7d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4424049a88543c79acd923ef0a7c104",
            "placeholder": "​",
            "style": "IPY_MODEL_cc0006e363a94486853a111b7123083f",
            "value": ".gitattributes: 100%"
          }
        },
        "902e355f5205411e94d861353a823214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55c4fc4f67d7411d9e644a38c9d446a6",
            "max": 1519,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e641e0e1b0974745b3af7359d1794fb1",
            "value": 1519
          }
        },
        "67852404bbed47198233248f2ad4d753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f45a444d330148a7b8aaad946cf05fb1",
            "placeholder": "​",
            "style": "IPY_MODEL_1637d557a0164900be43faf54f3327da",
            "value": " 1.52k/1.52k [00:00&lt;00:00, 51.3kB/s]"
          }
        },
        "b1d7861a40bc4555b886d3463f0c122e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4424049a88543c79acd923ef0a7c104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc0006e363a94486853a111b7123083f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55c4fc4f67d7411d9e644a38c9d446a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e641e0e1b0974745b3af7359d1794fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f45a444d330148a7b8aaad946cf05fb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1637d557a0164900be43faf54f3327da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c50163c5eab4fd2b80c6c4bd4cdc63d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_071f950a7343404798f80234738bf746",
              "IPY_MODEL_c9a758068dca4a5591a143908a066340",
              "IPY_MODEL_69cccb4e381c4ff994feaf55919313fe"
            ],
            "layout": "IPY_MODEL_70f046c576b845e29f54b1c5ce9b96b3"
          }
        },
        "071f950a7343404798f80234738bf746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80fdddea27fe492882b7d38c7b8b6690",
            "placeholder": "​",
            "style": "IPY_MODEL_90132f24bfa240cf951b81ca45ee28b0",
            "value": "added_tokens.json: 100%"
          }
        },
        "c9a758068dca4a5591a143908a066340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09e632803abc4310932b228f2d3ed00a",
            "max": 65,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e6c7921295147c7ace40a93e2596a9b",
            "value": 65
          }
        },
        "69cccb4e381c4ff994feaf55919313fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13a5aa7ab8264e35ae3aa4912054cf10",
            "placeholder": "​",
            "style": "IPY_MODEL_0637283b566d4dd2938a3b5d3f80b2fa",
            "value": " 65.0/65.0 [00:00&lt;00:00, 730B/s]"
          }
        },
        "70f046c576b845e29f54b1c5ce9b96b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80fdddea27fe492882b7d38c7b8b6690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90132f24bfa240cf951b81ca45ee28b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09e632803abc4310932b228f2d3ed00a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e6c7921295147c7ace40a93e2596a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13a5aa7ab8264e35ae3aa4912054cf10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0637283b566d4dd2938a3b5d3f80b2fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0acbf0abdcef4cbfb4f66ace31e36275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3dbe3b7fcf044ebbad73217069523fd0",
              "IPY_MODEL_accb8a9dfcbb4758b0ed847bf904e3d4",
              "IPY_MODEL_c89c41adf0f34b59b4f5524f2cbc22cc"
            ],
            "layout": "IPY_MODEL_ed22396ae4aa4e46a040f773643967e9"
          }
        },
        "3dbe3b7fcf044ebbad73217069523fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6524da4f56a410c811001d48e840a0e",
            "placeholder": "​",
            "style": "IPY_MODEL_dd5275a17cbc496da10162b28a6caa5b",
            "value": "README.md: 100%"
          }
        },
        "accb8a9dfcbb4758b0ed847bf904e3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17c8f17dc8a044b1b0f003c679d44b21",
            "max": 23327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e72deba0269482693e1030aaac58fc3",
            "value": 23327
          }
        },
        "c89c41adf0f34b59b4f5524f2cbc22cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bd07d77f004441b9a7539a3593316d7",
            "placeholder": "​",
            "style": "IPY_MODEL_5b3bdbd35331457e939e66c7c9688a40",
            "value": " 23.3k/23.3k [00:00&lt;00:00, 220kB/s]"
          }
        },
        "ed22396ae4aa4e46a040f773643967e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6524da4f56a410c811001d48e840a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd5275a17cbc496da10162b28a6caa5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17c8f17dc8a044b1b0f003c679d44b21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e72deba0269482693e1030aaac58fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bd07d77f004441b9a7539a3593316d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b3bdbd35331457e939e66c7c9688a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "938df6a5704343d3911c850cc15e6050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4e2510182da469faa74a02a76e5574a",
              "IPY_MODEL_36392021543d4bfd80189c6eb0933887",
              "IPY_MODEL_e2622760982645b6b621615507c45d22"
            ],
            "layout": "IPY_MODEL_5d34e471388f478cabd83dd8212cb06b"
          }
        },
        "c4e2510182da469faa74a02a76e5574a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ebe22b5e9c542c1b929c5f9437a7779",
            "placeholder": "​",
            "style": "IPY_MODEL_ef91a26beedf417b9cccde970bde4aeb",
            "value": "spm.model: 100%"
          }
        },
        "36392021543d4bfd80189c6eb0933887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d47c3c87bd9c46a99ca8bd1d9d91199e",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5809388a25a245f3964c1c4644cda90a",
            "value": 2464616
          }
        },
        "e2622760982645b6b621615507c45d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_144d1966e5014363a501bc0c4675e5e1",
            "placeholder": "​",
            "style": "IPY_MODEL_5077c0a3b64647a9a169e9acda4c9c49",
            "value": " 2.46M/2.46M [00:00&lt;00:00, 6.46MB/s]"
          }
        },
        "5d34e471388f478cabd83dd8212cb06b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ebe22b5e9c542c1b929c5f9437a7779": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef91a26beedf417b9cccde970bde4aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d47c3c87bd9c46a99ca8bd1d9d91199e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5809388a25a245f3964c1c4644cda90a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "144d1966e5014363a501bc0c4675e5e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5077c0a3b64647a9a169e9acda4c9c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3497a330051b4915ae28924af75e8361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e387e15645d496ea89b7c70e4afc80e",
              "IPY_MODEL_04a86873f4db498fa9610bf8bab020f4",
              "IPY_MODEL_64f78865e98a4a5faf867b06c99bb910"
            ],
            "layout": "IPY_MODEL_0666f6191be84d4ba61e0c67bb508a0e"
          }
        },
        "9e387e15645d496ea89b7c70e4afc80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fd12b1fd72b4436add34c8a046ff988",
            "placeholder": "​",
            "style": "IPY_MODEL_1d387b74eb0948f287537b5aad701caa",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "04a86873f4db498fa9610bf8bab020f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_966d8ae99a694b72b1eea0b30ea23794",
            "max": 970,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1275077389149d28877f0b6e196619d",
            "value": 970
          }
        },
        "64f78865e98a4a5faf867b06c99bb910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac839ae06fb340a68ee10cf79bc717f1",
            "placeholder": "​",
            "style": "IPY_MODEL_e337f0b0367842f3962d5dfaf4c29f22",
            "value": " 970/970 [00:00&lt;00:00, 7.08kB/s]"
          }
        },
        "0666f6191be84d4ba61e0c67bb508a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fd12b1fd72b4436add34c8a046ff988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d387b74eb0948f287537b5aad701caa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "966d8ae99a694b72b1eea0b30ea23794": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1275077389149d28877f0b6e196619d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac839ae06fb340a68ee10cf79bc717f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e337f0b0367842f3962d5dfaf4c29f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea980712284d426eaf60cb79e36019b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_489b75973b9a4a549cb2e2fb99bfacc8",
              "IPY_MODEL_af4f5bcf37d94fd5bdd5040cd1c1fa73",
              "IPY_MODEL_d34fd1cc1ed440b8a8f3c14b67ed4135"
            ],
            "layout": "IPY_MODEL_a1a8aeaf19f5474a9c6a63f56693604f"
          }
        },
        "489b75973b9a4a549cb2e2fb99bfacc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_484f7e35d4464c7da567d2d5cea872eb",
            "placeholder": "​",
            "style": "IPY_MODEL_bb9e3e6cd162417b8ed1dd46861a1d6c",
            "value": "models_comparison.png: 100%"
          }
        },
        "af4f5bcf37d94fd5bdd5040cd1c1fa73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b014ca6369546f0a6db0657a7792a92",
            "max": 156208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df347ad839594991880b57b5bd115c0c",
            "value": 156208
          }
        },
        "d34fd1cc1ed440b8a8f3c14b67ed4135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_899778de26cc46d99c17e27f5abf8c40",
            "placeholder": "​",
            "style": "IPY_MODEL_bab722e82b26458699ea0496eadf4fd0",
            "value": " 156k/156k [00:00&lt;00:00, 1.02MB/s]"
          }
        },
        "a1a8aeaf19f5474a9c6a63f56693604f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "484f7e35d4464c7da567d2d5cea872eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb9e3e6cd162417b8ed1dd46861a1d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b014ca6369546f0a6db0657a7792a92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df347ad839594991880b57b5bd115c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "899778de26cc46d99c17e27f5abf8c40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bab722e82b26458699ea0496eadf4fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a59c8eb4d7eb4adab4f9093e89e12c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f09cb3c2e746446f9dd0bf308ea022f5",
              "IPY_MODEL_88e4a4a5ee8f4151add8afc965ad3f14",
              "IPY_MODEL_f5b8709a2cec4220acb07b3f474498f4"
            ],
            "layout": "IPY_MODEL_e5fb6aa2d10e47df83f2f607a8d1e4f9"
          }
        },
        "f09cb3c2e746446f9dd0bf308ea022f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_421d3c059c31403b94d1902fc294dd38",
            "placeholder": "​",
            "style": "IPY_MODEL_ec4bde669dc94d5e9a9fecca0f58ca44",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "88e4a4a5ee8f4151add8afc965ad3f14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_421f8eeadb194522b7295e47ddc06fc5",
            "max": 664140326,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf9c0886588541f3a2415841f9eeeb41",
            "value": 664140326
          }
        },
        "f5b8709a2cec4220acb07b3f474498f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21fac192c6474be999daf1c4612e3f52",
            "placeholder": "​",
            "style": "IPY_MODEL_26af9c1c36a844afbe28391b49cd41af",
            "value": " 664M/664M [00:07&lt;00:00, 93.1MB/s]"
          }
        },
        "e5fb6aa2d10e47df83f2f607a8d1e4f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "421d3c059c31403b94d1902fc294dd38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec4bde669dc94d5e9a9fecca0f58ca44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "421f8eeadb194522b7295e47ddc06fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf9c0886588541f3a2415841f9eeeb41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21fac192c6474be999daf1c4612e3f52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26af9c1c36a844afbe28391b49cd41af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d06dea89e1d149d49105d53107f24444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b37ba72a109d493996d31a6452b3809c",
              "IPY_MODEL_efbc9bc77aca49459c4139a952b52959",
              "IPY_MODEL_c594e76632a34eaeb525e2763d42ef2d"
            ],
            "layout": "IPY_MODEL_78c4b45dd5d24cb6bbee3189b707a75e"
          }
        },
        "b37ba72a109d493996d31a6452b3809c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8968e23c0b814689b8529e1001f33f1e",
            "placeholder": "​",
            "style": "IPY_MODEL_953f1f3023134712ad6f5162cd6ff97f",
            "value": "gliner_config.json: 100%"
          }
        },
        "efbc9bc77aca49459c4139a952b52959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1bfca09a18a49b7895aaee79b742ae3",
            "max": 676,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba20bfd563e1462bb8b7eead61b7fe90",
            "value": 676
          }
        },
        "c594e76632a34eaeb525e2763d42ef2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f3c12d462064d36b13febffc6c90820",
            "placeholder": "​",
            "style": "IPY_MODEL_63446c3a4db4414bada4f79371ecf5f5",
            "value": " 676/676 [00:00&lt;00:00, 11.9kB/s]"
          }
        },
        "78c4b45dd5d24cb6bbee3189b707a75e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8968e23c0b814689b8529e1001f33f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "953f1f3023134712ad6f5162cd6ff97f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1bfca09a18a49b7895aaee79b742ae3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba20bfd563e1462bb8b7eead61b7fe90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f3c12d462064d36b13febffc6c90820": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63446c3a4db4414bada4f79371ecf5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b10bca9cfc7a493ab27fdbf4bbfca3e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b15c967508d496397d87d98d61b2b41",
              "IPY_MODEL_0571bffd33574dd1b9b89454323550cf",
              "IPY_MODEL_d913bfe73af644bdabc510880347151f"
            ],
            "layout": "IPY_MODEL_c2c9879e8e0a452681224182c18d6052"
          }
        },
        "3b15c967508d496397d87d98d61b2b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d34046c4f60439f96835804ad91b35c",
            "placeholder": "​",
            "style": "IPY_MODEL_ce47fe1904a0433c813e00513c765173",
            "value": "tokenizer.json: 100%"
          }
        },
        "0571bffd33574dd1b9b89454323550cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79d7e7a172a94fed87d07f079cf08097",
            "max": 8649232,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_622ec29160604f088baea7809d29d8dc",
            "value": 8649232
          }
        },
        "d913bfe73af644bdabc510880347151f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f434163e33b4f88a6e9caf00ccb4ace",
            "placeholder": "​",
            "style": "IPY_MODEL_e4f4d8498fee4bfa92f5a7e134028e39",
            "value": " 8.65M/8.65M [00:00&lt;00:00, 9.72MB/s]"
          }
        },
        "c2c9879e8e0a452681224182c18d6052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d34046c4f60439f96835804ad91b35c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce47fe1904a0433c813e00513c765173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79d7e7a172a94fed87d07f079cf08097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "622ec29160604f088baea7809d29d8dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f434163e33b4f88a6e9caf00ccb4ace": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4f4d8498fee4bfa92f5a7e134028e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dd1c91edc3d45b381d9224886403641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea63b020484c4893bb28e741b9190ec1",
              "IPY_MODEL_4fe9989c55a1412b92281b0a9bc3073d",
              "IPY_MODEL_1db4ad6bfd4c44ecbf649099f6ccf9ed"
            ],
            "layout": "IPY_MODEL_c8bb67eedc7048998e01f397c7603591"
          }
        },
        "ea63b020484c4893bb28e741b9190ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cc4d3b8445b48dfb1731a961024d3e2",
            "placeholder": "​",
            "style": "IPY_MODEL_d2d660e88b854d2b95d76026c537745b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4fe9989c55a1412b92281b0a9bc3073d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51f4e0fc5b8a4bb08c1c0f386f812043",
            "max": 1632,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88368945684d428cb17f1893da75d3ac",
            "value": 1632
          }
        },
        "1db4ad6bfd4c44ecbf649099f6ccf9ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33e9967bde724fdb8aa7aab0a1243de2",
            "placeholder": "​",
            "style": "IPY_MODEL_438e5715761a4e28b2c85c5bd4bc22cf",
            "value": " 1.63k/1.63k [00:00&lt;00:00, 43.4kB/s]"
          }
        },
        "c8bb67eedc7048998e01f397c7603591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cc4d3b8445b48dfb1731a961024d3e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2d660e88b854d2b95d76026c537745b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51f4e0fc5b8a4bb08c1c0f386f812043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88368945684d428cb17f1893da75d3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33e9967bde724fdb8aa7aab0a1243de2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "438e5715761a4e28b2c85c5bd4bc22cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "731b6d502b0c49768c9ea823638be10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd248a74306141f591505862f64ed07f",
              "IPY_MODEL_3187c3b4a2404185a3ab723df5edba91",
              "IPY_MODEL_30285d419a034ef2b378e48744ab96d5"
            ],
            "layout": "IPY_MODEL_dbba3d213fbc42fa951c8b098321c24c"
          }
        },
        "fd248a74306141f591505862f64ed07f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_370ab81613f14c988d1f7084c0b6485c",
            "placeholder": "​",
            "style": "IPY_MODEL_954b6b78fa09463fba19cdb1e99edce7",
            "value": "config.json: 100%"
          }
        },
        "3187c3b4a2404185a3ab723df5edba91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbacb6e9a1ad449580933f66198efe67",
            "max": 578,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba729f9d2e9a4d36845bcf039cfd7ffe",
            "value": 578
          }
        },
        "30285d419a034ef2b378e48744ab96d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1872c4d750d2462abaac6f6c69b248b6",
            "placeholder": "​",
            "style": "IPY_MODEL_4b96c516635a4e5b80f7819b15f9048a",
            "value": " 578/578 [00:00&lt;00:00, 45.4kB/s]"
          }
        },
        "dbba3d213fbc42fa951c8b098321c24c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "370ab81613f14c988d1f7084c0b6485c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "954b6b78fa09463fba19cdb1e99edce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbacb6e9a1ad449580933f66198efe67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba729f9d2e9a4d36845bcf039cfd7ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1872c4d750d2462abaac6f6c69b248b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b96c516635a4e5b80f7819b15f9048a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71d09608b9f74c28af194836e28c9fe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0595668f0620478b88a8354d98d2bc42",
              "IPY_MODEL_08fbc6dca92a4e45b6a7a66488a43dda",
              "IPY_MODEL_fdf092491e01455d99582af6cdfa465a"
            ],
            "layout": "IPY_MODEL_be34161cbadd4b6cab78771d6744d5e9"
          }
        },
        "0595668f0620478b88a8354d98d2bc42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38178e990df44562a35ee61f8639f04c",
            "placeholder": "​",
            "style": "IPY_MODEL_367ab2a540ce47928a8eaf1c142d7be5",
            "value": "Fetching 4 files: 100%"
          }
        },
        "08fbc6dca92a4e45b6a7a66488a43dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_730accd4ef774f8c9daf126af3f53574",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3df20ad8c0084f6daa5a345093f4362c",
            "value": 4
          }
        },
        "fdf092491e01455d99582af6cdfa465a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7a19cb8542b423e960d316cad7ecb73",
            "placeholder": "​",
            "style": "IPY_MODEL_d529d71ea2de440e9dc8b32aa6c613a2",
            "value": " 4/4 [00:03&lt;00:00,  1.13it/s]"
          }
        },
        "be34161cbadd4b6cab78771d6744d5e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38178e990df44562a35ee61f8639f04c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "367ab2a540ce47928a8eaf1c142d7be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "730accd4ef774f8c9daf126af3f53574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3df20ad8c0084f6daa5a345093f4362c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7a19cb8542b423e960d316cad7ecb73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d529d71ea2de440e9dc8b32aa6c613a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3ae9fb8cd7c4582b20e4148c02adbea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb314908f241479f971abe806931a7eb",
              "IPY_MODEL_c11ddc68d0cd4a45b1835563bba3edca",
              "IPY_MODEL_b47249abc0fd4f08ab285aedec884158"
            ],
            "layout": "IPY_MODEL_06d93f0c39ae4dbf8b50375c3a04c5a1"
          }
        },
        "cb314908f241479f971abe806931a7eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f078ca9a4ad445158c2ed18343217e09",
            "placeholder": "​",
            "style": "IPY_MODEL_290c8e0b14434679b180bf13b69fcdae",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "c11ddc68d0cd4a45b1835563bba3edca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0e8ba17273b48769137922e3bc2a634",
            "max": 610652234,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83e095b2298942f49db94602b0389a63",
            "value": 610652234
          }
        },
        "b47249abc0fd4f08ab285aedec884158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3e6d3c69b23427b9612b7afc78cc9c7",
            "placeholder": "​",
            "style": "IPY_MODEL_11485bfb3e484901a1d1fca519c447a5",
            "value": " 611M/611M [00:03&lt;00:00, 293MB/s]"
          }
        },
        "06d93f0c39ae4dbf8b50375c3a04c5a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f078ca9a4ad445158c2ed18343217e09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "290c8e0b14434679b180bf13b69fcdae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0e8ba17273b48769137922e3bc2a634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83e095b2298942f49db94602b0389a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3e6d3c69b23427b9612b7afc78cc9c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11485bfb3e484901a1d1fca519c447a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9332a63910c4df2860d9511224e259a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dffe9f5b3b30404ab72adb492f9c8739",
              "IPY_MODEL_77fa2799e7e44fcd9726a25192efe39e",
              "IPY_MODEL_e570d3a327614f4b9d02573881da0675"
            ],
            "layout": "IPY_MODEL_cd3196041c3f43ae8020da08e0db7c3f"
          }
        },
        "dffe9f5b3b30404ab72adb492f9c8739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfc60e96ee484ea4bfb1045033088c8d",
            "placeholder": "​",
            "style": "IPY_MODEL_ff31e15f19fe466f9deb31ead87424a1",
            "value": "gliner_config.json: 100%"
          }
        },
        "77fa2799e7e44fcd9726a25192efe39e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11b1d4c87c994e2aa10a6977ac7f3665",
            "max": 477,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fccd74014fc1429590df0f1526a7c8ce",
            "value": 477
          }
        },
        "e570d3a327614f4b9d02573881da0675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af8a84f659f145cab77deff4aa66804e",
            "placeholder": "​",
            "style": "IPY_MODEL_e50f2a1810574d4497c8f8c892604fe4",
            "value": " 477/477 [00:00&lt;00:00, 4.59kB/s]"
          }
        },
        "cd3196041c3f43ae8020da08e0db7c3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfc60e96ee484ea4bfb1045033088c8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff31e15f19fe466f9deb31ead87424a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11b1d4c87c994e2aa10a6977ac7f3665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fccd74014fc1429590df0f1526a7c8ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af8a84f659f145cab77deff4aa66804e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e50f2a1810574d4497c8f8c892604fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b73c881f4ef244b19cb2646c6f8aacf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_203ca95f620d485195757be5225707d4",
              "IPY_MODEL_16fd8aeeabcb4c8fbb4e1eee4afb2fcb",
              "IPY_MODEL_c14f7dcc9eaf4affa3d39572a2d35ccf"
            ],
            "layout": "IPY_MODEL_850aacbf29e84234a7a54d8880dcbbef"
          }
        },
        "203ca95f620d485195757be5225707d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05f2e30d4da646b2a127ebf06e88ecce",
            "placeholder": "​",
            "style": "IPY_MODEL_724c3eb7661247f2ab4dfd2ae0fd5e9f",
            "value": "README.md: 100%"
          }
        },
        "16fd8aeeabcb4c8fbb4e1eee4afb2fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e40291fae30a45efb4c11648f0f02ede",
            "max": 4756,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_218a51ee8d444e63a5433b07cb897c94",
            "value": 4756
          }
        },
        "c14f7dcc9eaf4affa3d39572a2d35ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaf360fa61314c1c9135139dba28f943",
            "placeholder": "​",
            "style": "IPY_MODEL_b24184c7a28a48328f2479321c789684",
            "value": " 4.76k/4.76k [00:00&lt;00:00, 49.0kB/s]"
          }
        },
        "850aacbf29e84234a7a54d8880dcbbef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05f2e30d4da646b2a127ebf06e88ecce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "724c3eb7661247f2ab4dfd2ae0fd5e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e40291fae30a45efb4c11648f0f02ede": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "218a51ee8d444e63a5433b07cb897c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eaf360fa61314c1c9135139dba28f943": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b24184c7a28a48328f2479321c789684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7611afdc0b44676a1d72e71997f1f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6466a51387fd49c5a84064875ba4187d",
              "IPY_MODEL_d08f586229b64ff1bcd92985d5ac5ccd",
              "IPY_MODEL_d2ccf78355d8475c99c960947e427a71"
            ],
            "layout": "IPY_MODEL_b09945c542a44c7f86dafecf787c4c7d"
          }
        },
        "6466a51387fd49c5a84064875ba4187d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7b1b1ab400547da8a637511fa539927",
            "placeholder": "​",
            "style": "IPY_MODEL_4e230b39853c432abfb931b0954f85af",
            "value": ".gitattributes: 100%"
          }
        },
        "d08f586229b64ff1bcd92985d5ac5ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a45e47148fa440409f06b505ac0f77d7",
            "max": 1519,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0db0461373c49e4ae5787aacce2fbdb",
            "value": 1519
          }
        },
        "d2ccf78355d8475c99c960947e427a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93010d60ab9142a391f22a7d543bb71a",
            "placeholder": "​",
            "style": "IPY_MODEL_f7f921ea4ba74cdfb36b88fce17f4f04",
            "value": " 1.52k/1.52k [00:00&lt;00:00, 15.0kB/s]"
          }
        },
        "b09945c542a44c7f86dafecf787c4c7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7b1b1ab400547da8a637511fa539927": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e230b39853c432abfb931b0954f85af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a45e47148fa440409f06b505ac0f77d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0db0461373c49e4ae5787aacce2fbdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93010d60ab9142a391f22a7d543bb71a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7f921ea4ba74cdfb36b88fce17f4f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9b53ab4686d4f18a0e8afe627ad64bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99a62c12179848099d7bc12562d1a165",
              "IPY_MODEL_55dbb0c358ea4786bdb5c7327175fc5f",
              "IPY_MODEL_3ce77979aecc4c0cbdbbe1e838ef3c18"
            ],
            "layout": "IPY_MODEL_d0cf01dca0104c3ebb9a2ecd50735aff"
          }
        },
        "99a62c12179848099d7bc12562d1a165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4ae2342619a4b76bea0a7b3a546a279",
            "placeholder": "​",
            "style": "IPY_MODEL_8dfa6d0dccea4109b9ed2e78da740c35",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "55dbb0c358ea4786bdb5c7327175fc5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a14cdea77114acbbd9b49f950d89bfa",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6f7440abce94959a74045f1600066df",
            "value": 52
          }
        },
        "3ce77979aecc4c0cbdbbe1e838ef3c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d37feb15fc824d19ac56b24bde386fbb",
            "placeholder": "​",
            "style": "IPY_MODEL_d2c6343f0e5d42c697ea9e8241e6af1f",
            "value": " 52.0/52.0 [00:00&lt;00:00, 4.97kB/s]"
          }
        },
        "d0cf01dca0104c3ebb9a2ecd50735aff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4ae2342619a4b76bea0a7b3a546a279": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dfa6d0dccea4109b9ed2e78da740c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a14cdea77114acbbd9b49f950d89bfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6f7440abce94959a74045f1600066df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d37feb15fc824d19ac56b24bde386fbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2c6343f0e5d42c697ea9e8241e6af1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcb106e10cc14ca889e598ef9947427a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_021a3e56c49c4784aa0f865b581521a3",
              "IPY_MODEL_1d6f91feb0b8403e9f1832191b2a0ae8",
              "IPY_MODEL_1219bcae90034662922b1997591ebf7f"
            ],
            "layout": "IPY_MODEL_975b610e8bea4400b13d8346b946bf4b"
          }
        },
        "021a3e56c49c4784aa0f865b581521a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7812fba11f004484851c6fff87993aa3",
            "placeholder": "​",
            "style": "IPY_MODEL_27b676a1c06c4d499b7292cb0693c677",
            "value": "config.json: 100%"
          }
        },
        "1d6f91feb0b8403e9f1832191b2a0ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75546e2a04d94e1a85859eba930153de",
            "max": 578,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7d2bcea68ec4c86bea25b59fb7bc387",
            "value": 578
          }
        },
        "1219bcae90034662922b1997591ebf7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae48b3d1a1144c83a2cc4a31e453ba89",
            "placeholder": "​",
            "style": "IPY_MODEL_b408c884d4da4f2e91ae14da762c0999",
            "value": " 578/578 [00:00&lt;00:00, 48.3kB/s]"
          }
        },
        "975b610e8bea4400b13d8346b946bf4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7812fba11f004484851c6fff87993aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27b676a1c06c4d499b7292cb0693c677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75546e2a04d94e1a85859eba930153de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7d2bcea68ec4c86bea25b59fb7bc387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae48b3d1a1144c83a2cc4a31e453ba89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b408c884d4da4f2e91ae14da762c0999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db13751be38c4be7b995be5f4532a774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4202da98a084422fbd44526ea9d88f6e",
              "IPY_MODEL_3b32b11d3c8743a588510b799a584b67",
              "IPY_MODEL_d053e9465e5646ab972c185690f6d949"
            ],
            "layout": "IPY_MODEL_c23bd7a3a17b458185408bf7020f593c"
          }
        },
        "4202da98a084422fbd44526ea9d88f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4878543d041748058a969b0c685ef7c9",
            "placeholder": "​",
            "style": "IPY_MODEL_187ce256ae9f45f0aa9f5a47b012cb52",
            "value": "spm.model: 100%"
          }
        },
        "3b32b11d3c8743a588510b799a584b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c6578572b2740a794419c08749e6257",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d77e93a5f6744958917b3e7d8f70f51",
            "value": 2464616
          }
        },
        "d053e9465e5646ab972c185690f6d949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87f65e87b1be4031bb43cea88c7e87c4",
            "placeholder": "​",
            "style": "IPY_MODEL_af1a00b894e64e219212e9dcd520f06c",
            "value": " 2.46M/2.46M [00:00&lt;00:00, 45.8MB/s]"
          }
        },
        "c23bd7a3a17b458185408bf7020f593c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4878543d041748058a969b0c685ef7c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "187ce256ae9f45f0aa9f5a47b012cb52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c6578572b2740a794419c08749e6257": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d77e93a5f6744958917b3e7d8f70f51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87f65e87b1be4031bb43cea88c7e87c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af1a00b894e64e219212e9dcd520f06c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed2e98fed2014e78814d04d8a35a4b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_383c14dd7b6c4d489b604ba5593bf9c5",
              "IPY_MODEL_b7dd62455b374eb4a592fb125276b9d6",
              "IPY_MODEL_90da5641662b41bf95cc24d9f18eb65b"
            ],
            "layout": "IPY_MODEL_a2a6e8a885564a5ea22271c85c69c03a"
          }
        },
        "383c14dd7b6c4d489b604ba5593bf9c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7801f966f7e4d02b5c475333eb25f87",
            "placeholder": "​",
            "style": "IPY_MODEL_46d1c2ae3bdc40879e84052fcad4ebdb",
            "value": "Fetching 4 files: 100%"
          }
        },
        "b7dd62455b374eb4a592fb125276b9d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b4b1ee7d73545438ac55d0189e9fc95",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7432601a5e5741c7b69034688651d8ac",
            "value": 4
          }
        },
        "90da5641662b41bf95cc24d9f18eb65b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90b95a8874524138809322d0619438d4",
            "placeholder": "​",
            "style": "IPY_MODEL_51dd40365fcd4173b0354b080420db58",
            "value": " 4/4 [00:00&lt;00:00, 260.14it/s]"
          }
        },
        "a2a6e8a885564a5ea22271c85c69c03a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7801f966f7e4d02b5c475333eb25f87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46d1c2ae3bdc40879e84052fcad4ebdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b4b1ee7d73545438ac55d0189e9fc95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7432601a5e5741c7b69034688651d8ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90b95a8874524138809322d0619438d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51dd40365fcd4173b0354b080420db58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17e67ab57f67417e910565f354c03bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_840ceea2592d45079d61e418f7d8a7af",
              "IPY_MODEL_2f89a0c10b8441c4afb8cd31b2b026a2",
              "IPY_MODEL_9eb1fed76e494d6b88283a04ecd37275"
            ],
            "layout": "IPY_MODEL_7aec09f474d64c4a9e0d71de3b453dad"
          }
        },
        "840ceea2592d45079d61e418f7d8a7af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1be9985e5942448da3faa1003ecfb669",
            "placeholder": "​",
            "style": "IPY_MODEL_b11909a41af24fadb90059da4826fb36",
            "value": "Fetching 4 files: 100%"
          }
        },
        "2f89a0c10b8441c4afb8cd31b2b026a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_834089aef47a45da9ca68e9732dd0d67",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0193453ed2644c1886d187a1f354a06",
            "value": 4
          }
        },
        "9eb1fed76e494d6b88283a04ecd37275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9adb04a683864875984435004ab7857e",
            "placeholder": "​",
            "style": "IPY_MODEL_069ec5b3301a4a998794071ce26f1493",
            "value": " 4/4 [00:00&lt;00:00, 368.64it/s]"
          }
        },
        "7aec09f474d64c4a9e0d71de3b453dad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1be9985e5942448da3faa1003ecfb669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b11909a41af24fadb90059da4826fb36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "834089aef47a45da9ca68e9732dd0d67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0193453ed2644c1886d187a1f354a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9adb04a683864875984435004ab7857e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "069ec5b3301a4a998794071ce26f1493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58ad7894b16f49b585519be272b7c2b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a75d11db93744f18a55fe2f7445191f",
              "IPY_MODEL_8af10283d4ca4563a40db9d9a28d9f7e",
              "IPY_MODEL_dab8b64a9d83424eac0255f4589aa27e"
            ],
            "layout": "IPY_MODEL_c2176dfaa036460790eba45f47cce6c3"
          }
        },
        "8a75d11db93744f18a55fe2f7445191f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9f60fb7c3304659a11faa15ae6a4f04",
            "placeholder": "​",
            "style": "IPY_MODEL_6b570a3fe3d44c27ba08143afd626850",
            "value": "Fetching 10 files: 100%"
          }
        },
        "8af10283d4ca4563a40db9d9a28d9f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_148c3d7ac068472fba72f69590189cde",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f0bc96ce5694abf9f790df97589a6ce",
            "value": 10
          }
        },
        "dab8b64a9d83424eac0255f4589aa27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0abae6ce4e6d4ca4ab9b9b351d0f4e14",
            "placeholder": "​",
            "style": "IPY_MODEL_b0f86ed35f5f458e8c6689430d55e1ba",
            "value": " 10/10 [00:00&lt;00:00, 263.00it/s]"
          }
        },
        "c2176dfaa036460790eba45f47cce6c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9f60fb7c3304659a11faa15ae6a4f04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b570a3fe3d44c27ba08143afd626850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "148c3d7ac068472fba72f69590189cde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f0bc96ce5694abf9f790df97589a6ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0abae6ce4e6d4ca4ab9b9b351d0f4e14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f86ed35f5f458e8c6689430d55e1ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0700a95c5a9843df80ef33c1dd94e30f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4861665f9b484d5ca4af358b4bc64332",
              "IPY_MODEL_9ea7491244844d829529a2ede96f2fb8",
              "IPY_MODEL_c35dc5f23cb04ef0a46bb96f986d4164"
            ],
            "layout": "IPY_MODEL_c6620db6e64a4542a93c558c4fcb2e38"
          }
        },
        "4861665f9b484d5ca4af358b4bc64332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9882e8e6da542edba9045f9798251da",
            "placeholder": "​",
            "style": "IPY_MODEL_ce8d51a24e174c4bb695964c6be0563f",
            "value": "Fetching 10 files: 100%"
          }
        },
        "9ea7491244844d829529a2ede96f2fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4489815bb5c44258bc9463072365dc6f",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a8bff8efa5a4b28831c1a76604e35d2",
            "value": 10
          }
        },
        "c35dc5f23cb04ef0a46bb96f986d4164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4644a20048f404495eb47795f4f12fa",
            "placeholder": "​",
            "style": "IPY_MODEL_019095bbb84f4cb9be460d3ab2da1d8a",
            "value": " 10/10 [00:00&lt;00:00, 748.84it/s]"
          }
        },
        "c6620db6e64a4542a93c558c4fcb2e38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9882e8e6da542edba9045f9798251da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce8d51a24e174c4bb695964c6be0563f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4489815bb5c44258bc9463072365dc6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a8bff8efa5a4b28831c1a76604e35d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4644a20048f404495eb47795f4f12fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "019095bbb84f4cb9be460d3ab2da1d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}